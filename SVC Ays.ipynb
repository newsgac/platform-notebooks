{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install scikit-learn --user\n",
    "# !{sys.executable} -m pip install sklearn_pandas --user\n",
    "# !{sys.executable} -m pip install lightgbm --user\n",
    "# !{sys.executable} -m pip install matplotlib --user\n",
    "# !{sys.executable} -m pip install hyperopt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from hyperopt import tpe, fmin, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Data science imports\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "# Visualisation imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File IO: Read the data file\n",
    "file = open('train_data.txt', mode = 'r')\n",
    "lines = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for completeness\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: Clean unwanted characters \n",
    "data = []\n",
    "i = 0\n",
    "while i < len(lines)-1:\n",
    "    row = {}\n",
    "    row['id'] = lines[i+1].split(\" \")[1].strip()\n",
    "    row['durationOfStay'] = lines[i+2].split(\" \")[1].strip()\n",
    "    row['gender'] = lines[i+3].split(\" \")[1].strip()\n",
    "    row['Age'] = lines[i+4].split(\" \")[1].strip()\n",
    "    row['kids'] = lines[i+5].split(\" \")[1].strip()\n",
    "    row['destinationCode'] = lines[i+6].split(\" \")[1].strip()\n",
    "    row['AcomType'] = lines[i+7].split(\" \")[1].strip()\n",
    "    data.append(row)\n",
    "    i = i + 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data\n",
    "def structure_data_to_df(data, test_data=False):\n",
    "    if test_data:\n",
    "        df = pd.DataFrame(data, columns=['id','durationOfStay','gender','Age','kids','destinationCode'])\n",
    "        df['id'] = df['id'].astype(str)\n",
    "    else:\n",
    "        df = pd.DataFrame(data, columns=['durationOfStay','gender','Age','kids','destinationCode','AcomType'])\n",
    "        df['AcomType'] = df['AcomType'].astype(str)\n",
    "        \n",
    "    df['gender'] = df['gender'].astype(str)\n",
    "    df['kids'] = df['kids'].astype(str)\n",
    "    df['destinationCode'] = df['destinationCode'].astype(str)\n",
    "    df = df.replace('<NA>', np.nan)\n",
    "    df = df.replace('NA', np.nan)\n",
    "    df = df.replace('nan', np.nan)\n",
    "    df[['durationOfStay', 'Age']] = df[['durationOfStay', 'Age']].apply(pd.to_numeric)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = structure_data_to_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility variables\n",
    "categorical_cols = ['gender']\n",
    "missing_categorical_cols = ['kids', 'destinationCode']\n",
    "numerical_cols = ['durationOfStay']\n",
    "missing_numerical_cols = ['Age']\n",
    "\n",
    "# transform utility function\n",
    "def build_imputer_and_transformer(missing_categorical_cols, categorical_cols, \n",
    "                                  missing_numerical_cols, numerical_cols, constant=True):\n",
    "    transformations = []\n",
    "    \n",
    "    for col in missing_categorical_cols:\n",
    "        if constant:\n",
    "            transformations.append(([col], [SimpleImputer(strategy='constant', fill_value='N/A'), LabelBinarizer()]))\n",
    "        else:\n",
    "            transformations.append(([col], [SimpleImputer(strategy='most_frequent'), LabelBinarizer()]))\n",
    "        \n",
    "    for col in categorical_cols:\n",
    "        transformations.append((col, LabelBinarizer()))\n",
    "        \n",
    "    transformations.append((missing_numerical_cols, [SimpleImputer(strategy='mean'), StandardScaler()]))\n",
    "    transformations.append((numerical_cols, StandardScaler()))\n",
    "   \n",
    "    transformer = DataFrameMapper(transformations)\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['AcomType'].copy()\n",
    "X = df.drop(['AcomType'], axis=1)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=0)\n",
    "    \n",
    "transformer = build_imputer_and_transformer(missing_categorical_cols, categorical_cols,\n",
    "                                             missing_numerical_cols, numerical_cols, constant=True)\n",
    "    \n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_list = ['rbf', 'poly']\n",
    "# kernel_list = ['linear']\n",
    "class_weights = ['balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(evals, trials, optimizer=tpe.suggest):\n",
    "    space = {\n",
    "        'kernel': hp.choice('kernel', kernel_list),\n",
    "        'class_weight': hp.choice('class_weight', class_weights),\n",
    "        'C': hp.uniform('C', 0, 20),\n",
    "        'gamma': hp.uniform('gamma',0.01,10)\n",
    "    }\n",
    "    best = fmin(score, space, algo=optimizer, max_evals=evals, trials=trials)\n",
    "    pbar.close()\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "     \n",
    "    c = params['C']\n",
    "    gamma = params['gamma']\n",
    "    kernel = params['kernel']\n",
    "    class_weight = params['class_weight']\n",
    "    \n",
    "    model = SVC(kernel=kernel,\n",
    "            C=c,\n",
    "            random_state=42,\n",
    "            decision_function_shape='ovr',\n",
    "            class_weight=class_weight,\n",
    "            gamma=gamma)\n",
    "\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='balanced_accuracy', n_jobs=20)  \n",
    "    \n",
    "    scores_mean = scores.mean()\n",
    "\n",
    "    \n",
    "    print('Parameters with this training score {} :'.format(scores_mean))\n",
    "    print(params)\n",
    "    pbar.update()\n",
    "#     return {'loss': test_loss, 'status': STATUS_OK}\n",
    "    return {'loss': 1-scores_mean, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "trials = Trials()\n",
    "cores = 20\n",
    "start = time.time()\n",
    "evaluations = 1000\n",
    "pbar = tqdm(total=evaluations, desc=\"Hyperopt\")\n",
    "best_param = optimize(evals=evaluations,\n",
    "                      optimizer=tpe.suggest,\n",
    "                      trials=trials)\n",
    "print(\"------------------------------------\")\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_param)\n",
    "end = time.time()\n",
    "print('Time elapsed to optimize {0} executions: {1}'.format(evaluations, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param['kernel'] = kernel_list[best_param['kernel']]\n",
    "best_param['class_weight'] = class_weights[best_param['class_weight']]\n",
    "print('\\n Best score:')\n",
    "score(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best params and train the model\n",
    "SVC_opt = SVC(kernel=best_param['kernel'],\n",
    "            C=best_param['C'],\n",
    "            random_state=42,\n",
    "            decision_function_shape='ovr',\n",
    "            class_weight=best_param['class_weight'],\n",
    "            gamma=best_param['gamma'])\n",
    "\n",
    "fitted_model = SVC_opt.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = fitted_model.predict_proba(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = accuracy_score(y_test, fitted_model.predict(X_test))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
