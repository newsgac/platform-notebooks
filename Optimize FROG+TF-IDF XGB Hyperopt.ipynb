{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install imbalanced-learn --user\n",
    "# !{sys.executable} -m pip install hyperopt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/newsgac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from hyperopt import tpe, fmin, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "from newsgac import config\n",
    "from newsgac.genres import genre_codes\n",
    "from newsgac.learners import learners, LearnerSVC, LearnerNB, LearnerXGB, LearnerGB, LearnerMLP, LearnerRF, LearnerLGBM\n",
    "from newsgac.pipelines.get_sk_pipeline import get_sk_pipeline\n",
    "from newsgac.pipelines.utils import report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from newsgac import database\n",
    "from newsgac.data_sources import DataSource\n",
    "from newsgac.pipelines import Pipeline\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "# from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'N2BGS Training',\n",
       " u'N2BGS Testing',\n",
       " u'Linked NRC (2930)',\n",
       " u'BOW + 5 features (N2BGS train)',\n",
       " u'BOW + 5 features (N2BGS test)',\n",
       " u'nrc-1950-1994-a.txt',\n",
       " u'nrc-1950-1994-b.txt',\n",
       " u'nrc-1950-1994-c.txt',\n",
       " u'nrc-1950-1994-d.txt',\n",
       " u'nrc-1950-1994-e.txt',\n",
       " u'telegraaf-1950-1994-a.txt',\n",
       " u'telegraaf-1950-1994-b.txt',\n",
       " u'telegraaf-1950-1994-c.txt',\n",
       " u'telegraaf-1950-1994-d.txt',\n",
       " u'telegraaf-1950-1994-e.txt',\n",
       " u'volkskrant-1950-1995-a.txt',\n",
       " u'volkskrant-1950-1995-b.txt',\n",
       " u'volkskrant-1950-1995-c.txt',\n",
       " u'volkskrant-1950-1995-d.txt',\n",
       " u'volkskrant-1950-1995-e.txt',\n",
       " u'nrc-1965.txt',\n",
       " u'nrc-1985.txt',\n",
       " u'BOW + 9 features (N2BGS train)',\n",
       " u'BOW + 9 features (N2BGS test)',\n",
       " u'Linked NRC (2930/9 features)',\n",
       " u'BOW Train unique (9 features)',\n",
       " u'BOW Test unique (9 features)',\n",
       " u'Linked NRC (unique/9 features)',\n",
       " u'BOW Train unique (N3BGS/9 features)',\n",
       " u'N3BGS FROG Test',\n",
       " u'N3BGS FROG Train',\n",
       " u'BOW Test unique (N3BGS/9 features)',\n",
       " u'BOW Test unique (N3BGS/9 features/collapsed)',\n",
       " u'Linked NRC (2930 articles)',\n",
       " u'Combined N3BGS/Linked NRC (3884)',\n",
       " u'2019 N3BGS Test',\n",
       " u'2019 N3BGS Train',\n",
       " u'AAOB',\n",
       " u'20190228 unbalanced train size=3443',\n",
       " u'20190228 unbalanced test size=3443']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.display_title for d in DataSource.objects.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'dummy frog',\n",
       " u'dummy bow',\n",
       " u'RF FROG',\n",
       " u'SVC FROG',\n",
       " u'XGB FROG',\n",
       " u'NB FROG',\n",
       " u'MLP FROG',\n",
       " u'RF BOW',\n",
       " u'SVC BOW',\n",
       " u'XGB BOW',\n",
       " u'NB BOW',\n",
       " u'MLP BOW',\n",
       " u'SVC LIN BOW',\n",
       " u'Erik MLP BOW (with stop-words)',\n",
       " u'Erik MLP BOW (5 features) ',\n",
       " u'Erik MLP BOW (9 features) ',\n",
       " u'Erik SVC BOW (9 features)',\n",
       " u'Erik RF BOW (9 features)',\n",
       " u'Erik XGB BOW (9 features)',\n",
       " u'Erik NB BOW (9 features)',\n",
       " u'Erik MLP unique 9 features',\n",
       " u'Erik NB unique (9 features)',\n",
       " u'Erik XGB unique (9 features)',\n",
       " u'Erik SVC unique (9 features)',\n",
       " u'Erik RF unique (9 features)',\n",
       " u'N3BGS MLP unique 9 features',\n",
       " u'N3BGS NB unique 9 features ',\n",
       " u'N3BGS SVC unique 9 features ',\n",
       " u'N3BGS RF unique 9 features',\n",
       " u'N3BGS XGB unique 9 features ',\n",
       " u'dummy n3bgs bow',\n",
       " u'dummy n3bgs frog',\n",
       " u'RF FROG N3BGS',\n",
       " u'SVC FROG N3BGS',\n",
       " u'XGB FROG N3BGS',\n",
       " u'Erik NB N3BGS Collapsed',\n",
       " u'Erik MLP N3BGS Collapsed',\n",
       " u'Erik MLP Linked NRC (2930 articles)',\n",
       " u'Erik RF Linked NRC (2930 articles) ',\n",
       " u'Erik NB Linked NRC (2930 articles) ',\n",
       " u'Erik SVC Linked NRC (2930 articles) ',\n",
       " u'Erik XGB Linked NRC (2930 articles) ',\n",
       " u'SVC BOW Combined',\n",
       " u'NB FROG N3BGS',\n",
       " u'MLP FROG N3BGS',\n",
       " u'RF BOW NBGS',\n",
       " u'SVC BOW N3BGS',\n",
       " u'XGB BOW N3BGS',\n",
       " u'NB BOW N3BGS',\n",
       " u'MLP BOW N3BGS',\n",
       " u'KIM N3BGS FROG and TF-IDF',\n",
       " u'KIM N3BGS MLP Combi features',\n",
       " u'KIM N3BGS RF COMBI',\n",
       " u'KIM N3BGS SVM COMBI (copy)',\n",
       " u'KIM N3BGS XGB COMBI',\n",
       " u'20190228 SVM',\n",
       " u'20190228 SVC no stop words',\n",
       " u'20190228 SVC no stop words, lowercased',\n",
       " u'dummy combi for opt',\n",
       " u'dummy combi for opt ugs',\n",
       " u'new dummy ugs opt',\n",
       " u'new dummy bgs opt',\n",
       " u'dummy opt frog bgs',\n",
       " u'dummy bow opt bgs']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.display_title for d in Pipeline.objects.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: dummy combi for opt ugs\n",
      "DataSource: 20190228 unbalanced train size=3443\n",
      "NLP Tool: Frog + TFIDF\n",
      "Classifier: Multi-Layer Perceptron\n",
      "Task status: Status.SUCCESS\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline.objects.all()[59]\n",
    "print 'Pipeline: ' + p.display_title\n",
    "print 'DataSource: ' + p.data_source.display_title\n",
    "print 'NLP Tool: ' + p.nlp_tool.name\n",
    "print 'Classifier: ' + p.learner.name\n",
    "print 'Task status: ' + str(p.task.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3099"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p.data_source.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data source: 20190228 unbalanced test size=3443\n"
     ]
    }
   ],
   "source": [
    "test_data_source = DataSource.objects.all()[39]\n",
    "print 'Testing data source: ' + test_data_source.display_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CleanOCR', <newsgac.nlp_tools.transformers.CleanOCR at 0x7f21aacec3d0>),\n",
       " ('StopWordRemoval',\n",
       "  <newsgac.nlp_tools.transformers.StopWordRemoval at 0x7f21aacec5d0>),\n",
       " ('FeatureExtraction', FeatureUnion(n_jobs=None,\n",
       "         transformer_list=[('frog', FeatureUnion(n_jobs=None,\n",
       "         transformer_list=[('Basic', <newsgac.nlp_tools.transformers.ExtractBasicFeatures object at 0x7f21a8396e10>), ('Quote', <newsgac.nlp_tools.transformers.ExtractQuotes object at 0x7f21a8396e50>), ('Sentiment', Pipeline(memory=None,\n",
       "       steps=...\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None))]))],\n",
       "         transformer_weights=None))],\n",
       "         transformer_weights=None)),\n",
       " ('RobustScaler',\n",
       "  RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=False,\n",
       "         with_scaling=True))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skp = p.get_sk_pipeline()\n",
    "skp_opt = deepcopy(skp)\n",
    "skp_opt.steps.pop()\n",
    "skp_opt.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = numpy.array([article.raw_text for article in p.data_source.articles])\n",
    "labels = numpy.array([article.label for article in p.data_source.articles])\n",
    "\n",
    "X = skp_opt.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test dataset for optimization accuracy\n",
    "texts_test = numpy.array([article.raw_text for article in test_data_source.articles])\n",
    "labels_test = numpy.array([article.label for article in test_data_source.articles])\n",
    "\n",
    "X_test = skp_opt.transform(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = labels\n",
    "y_test = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2479, 26984)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_type_list = ['gain', 'weight', 'cover', 'total_gain', 'total_cover']\n",
    "booster_list = ['gbtree', 'gblinear', 'dart']\n",
    "max_depth_list = np.arange(1, 10, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(evals, trials, optimizer=tpe.suggest):\n",
    "    space = {\n",
    "#         'n_estimators': hp.quniform('n_estimators', 100, 1000, 1),\n",
    "        'n_estimators': hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        'learning_rate': hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n",
    "        # A problem with max_depth casted to float instead of int with\n",
    "        # the hp.quniform method.\n",
    "        'max_depth':  hp.choice('max_depth', max_depth_list),\n",
    "#         'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        'importance_type': hp.choice('importance_type', importance_type_list),\n",
    "#         'eval_metric': 'auc',\n",
    "#         'objective': 'binary:logistic',\n",
    "        # Increase this number if you have more cores. Otherwise, remove it and it will default \n",
    "        # to the maxium number. \n",
    "#         'nthread': 48,\n",
    "        'booster': hp.choice('booster', booster_list),\n",
    "#         'tree_method': 'exact',\n",
    "#         'silent': 1,\n",
    "#         'seed': 42\n",
    "    }\n",
    "    best = fmin(score, space, algo=optimizer, max_evals=evals, trials=trials)\n",
    "    pbar.close()\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "def score(params):\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)]\n",
    "    \n",
    "    model = XGBClassifier(n_estimators = params['n_estimators'],\n",
    "                          learning_rate = params['learning_rate'],\n",
    "                            max_depth = params['max_depth'],\n",
    "                            min_child_weight = params['min_child_weight'],\n",
    "                            subsample = params['subsample'], \n",
    "                            gamma = params['gamma'],\n",
    "                            colsample_bytree = params['colsample_bytree'],\n",
    "                            importance_type = params['importance_type'],\n",
    "                            booster=params['booster'],\n",
    "                            objective = \"multi:softprob\",\n",
    "                            n_jobs=24,\n",
    "                            random_state=42,\n",
    "                            silent=False,)\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=eval_set, verbose=False)   \n",
    "\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    train_loss = log_loss(y_train, model.predict_proba(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    test_loss = log_loss(y_test, model.predict_proba(X_test))\n",
    "    \n",
    "    train_acc_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "    print('Parameters with this training accuracy {} and loss {} :'.format(train_acc, train_loss))\n",
    "    print('Parameters with this testing accuracy {} and loss {} :'.format(test_acc, test_loss))\n",
    "    print(params)\n",
    "    pbar.update()\n",
    "#     return {'loss': test_loss, 'status': STATUS_OK}\n",
    "    return {'loss': -test_acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s, best loss: ?]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993545784591 and loss 0.096155541371 :\n",
      "\n",
      "  0%|          | 0/1000 [00:39<?, ?it/s, best loss: ?]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.20372400889 :\n",
      "\n",
      "  0%|          | 0/1000 [00:39<?, ?it/s, best loss: ?]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 304, 'subsample': 0.75, 'importance_type': 'total_gain', 'max_depth': 8, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      "  0%|          | 0/1000 [00:39<?, ?it/s, best loss: ?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   0%|          | 1/1000 [00:39<11:03:36, 39.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/1000 [00:39<10:57:34, 39.49s/it, best loss: -0.633720930233]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.949173053651 and loss 0.276840678582 :\n",
      "\n",
      "  0%|          | 1/1000 [01:25<10:57:34, 39.49s/it, best loss: -0.633720930233]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.15090173582 :\n",
      "\n",
      "  0%|          | 1/1000 [01:25<10:57:34, 39.49s/it, best loss: -0.633720930233]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.1, 'min_child_weight': 6.0, 'n_estimators': 355, 'subsample': 0.75, 'importance_type': 'gain', 'max_depth': 2, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  0%|          | 1/1000 [01:25<10:57:34, 39.49s/it, best loss: -0.633720930233]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   0%|          | 2/1000 [01:25<11:31:26, 41.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 2/1000 [01:25<11:27:12, 41.32s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76767888648 :\n",
      "\n",
      "  0%|          | 2/1000 [01:32<11:27:12, 41.32s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75948645255 :\n",
      "\n",
      "  0%|          | 2/1000 [01:32<11:27:12, 41.32s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 216, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  0%|          | 2/1000 [01:32<11:27:12, 41.32s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   0%|          | 3/1000 [01:32<8:39:56, 31.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 3/1000 [01:32<8:36:57, 31.11s/it, best loss: -0.639534883721] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989915288423 and loss 0.117470282744 :\n",
      "\n",
      "  0%|          | 3/1000 [01:39<8:36:57, 31.11s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.29365630601 :\n",
      "\n",
      "  0%|          | 3/1000 [01:39<8:36:57, 31.11s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.42500000000000004, 'min_child_weight': 2.0, 'n_estimators': 59, 'subsample': 1.0, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      "  0%|          | 3/1000 [01:39<8:36:57, 31.11s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   0%|          | 4/1000 [01:40<6:40:01, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 4/1000 [01:39<6:37:56, 23.97s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.935861234369 and loss 0.324961267471 :\n",
      "\n",
      "  0%|          | 4/1000 [02:04<6:37:56, 23.97s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.11298690385 :\n",
      "\n",
      "  0%|          | 4/1000 [02:04<6:37:56, 23.97s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.07500000000000001, 'min_child_weight': 6.0, 'n_estimators': 240, 'subsample': 1.0, 'importance_type': 'weight', 'max_depth': 3, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      "  0%|          | 4/1000 [02:04<6:37:56, 23.97s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   0%|          | 5/1000 [02:04<6:41:25, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 5/1000 [02:04<6:39:59, 24.12s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76761526065 :\n",
      "\n",
      "  0%|          | 5/1000 [02:19<6:39:59, 24.12s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75937434752 :\n",
      "\n",
      "  0%|          | 5/1000 [02:19<6:39:59, 24.12s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'min_child_weight': 6.0, 'n_estimators': 481, 'subsample': 0.6000000000000001, 'importance_type': 'weight', 'max_depth': 5, 'gamma': 0.65, 'booster': 'gblinear'}\n",
      "\n",
      "  0%|          | 5/1000 [02:19<6:39:59, 24.12s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|          | 6/1000 [02:19<5:56:35, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 6/1000 [02:19<5:55:33, 21.46s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993949173054 and loss 0.0978277402738 :\n",
      "\n",
      "  1%|          | 6/1000 [02:47<5:55:33, 21.46s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.610465116279 and loss 1.3011204668 :\n",
      "\n",
      "  1%|          | 6/1000 [02:47<5:55:33, 21.46s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.47500000000000003, 'min_child_weight': 1.0, 'n_estimators': 296, 'subsample': 0.75, 'importance_type': 'weight', 'max_depth': 3, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      "  1%|          | 6/1000 [02:47<5:55:33, 21.46s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|          | 7/1000 [02:47<6:28:12, 23.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 7/1000 [02:47<6:27:31, 23.42s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.7672670793 :\n",
      "\n",
      "  1%|          | 7/1000 [02:55<6:27:31, 23.42s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75876205846 :\n",
      "\n",
      "  1%|          | 7/1000 [02:55<6:27:31, 23.42s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.5, 'min_child_weight': 1.0, 'n_estimators': 226, 'subsample': 0.55, 'importance_type': 'total_gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  1%|          | 7/1000 [02:55<6:27:31, 23.42s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|          | 8/1000 [02:55<5:09:34, 18.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 8/1000 [02:55<5:09:03, 18.69s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.985074626866 and loss 0.156408045762 :\n",
      "\n",
      "  1%|          | 8/1000 [03:16<5:09:03, 18.69s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.14046281736 :\n",
      "\n",
      "  1%|          | 8/1000 [03:16<5:09:03, 18.69s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.25, 'min_child_weight': 5.0, 'n_estimators': 161, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 8, 'gamma': 1.0, 'booster': 'gbtree'}\n",
      "\n",
      "  1%|          | 8/1000 [03:16<5:09:03, 18.69s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|          | 9/1000 [03:16<5:20:32, 19.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 9/1000 [03:16<5:20:12, 19.39s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993142396127 and loss 0.106844122472 :\n",
      "\n",
      "  1%|          | 9/1000 [04:15<5:20:12, 19.39s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.21320322969 :\n",
      "\n",
      "  1%|          | 9/1000 [04:15<5:20:12, 19.39s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.225, 'min_child_weight': 2.0, 'n_estimators': 335, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      "  1%|          | 9/1000 [04:15<5:20:12, 19.39s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|          | 10/1000 [04:15<8:38:34, 31.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1000 [04:15<8:38:21, 31.42s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76726703553 :\n",
      "\n",
      "  1%|          | 10/1000 [04:28<8:38:21, 31.42s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75876194128 :\n",
      "\n",
      "  1%|          | 10/1000 [04:28<8:38:21, 31.42s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.35000000000000003, 'min_child_weight': 3.0, 'n_estimators': 376, 'subsample': 0.5, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.9500000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  1%|          | 10/1000 [04:28<8:38:21, 31.42s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|          | 11/1000 [04:28<7:05:02, 25.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 11/1000 [04:28<7:04:50, 25.77s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989108511497 and loss 0.129592197933 :\n",
      "\n",
      "  1%|          | 11/1000 [04:59<7:04:50, 25.77s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.601744186047 and loss 1.28270558414 :\n",
      "\n",
      "  1%|          | 11/1000 [04:59<7:04:50, 25.77s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.325, 'min_child_weight': 2.0, 'n_estimators': 264, 'subsample': 0.9, 'importance_type': 'total_gain', 'max_depth': 3, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      "  1%|          | 11/1000 [04:59<7:04:50, 25.77s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|          | 12/1000 [05:00<7:33:46, 27.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 12/1000 [04:59<7:33:40, 27.55s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.912061315046 and loss 0.37978851046 :\n",
      "\n",
      "  1%|          | 12/1000 [05:08<7:33:40, 27.55s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.17302318989 :\n",
      "\n",
      "  1%|          | 12/1000 [05:08<7:33:40, 27.55s/it, best loss: -0.639534883721]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.225, 'min_child_weight': 5.0, 'n_estimators': 249, 'subsample': 0.65, 'importance_type': 'total_gain', 'max_depth': 1, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  1%|          | 12/1000 [05:08<7:33:40, 27.55s/it, best loss: -0.639534883721]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|▏         | 13/1000 [05:09<6:01:52, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 13/1000 [05:08<6:01:48, 21.99s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.951593384429 and loss 0.25665326492 :\n",
      "\n",
      "  1%|▏         | 13/1000 [05:27<6:01:48, 21.99s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.12372757193 :\n",
      "\n",
      "  1%|▏         | 13/1000 [05:27<6:01:48, 21.99s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 94, 'subsample': 0.6000000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  1%|▏         | 13/1000 [05:27<6:01:48, 21.99s/it, best loss: -0.642441860465]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   1%|▏         | 14/1000 [05:27<5:43:11, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 14/1000 [05:27<5:43:07, 20.88s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.976603469141 and loss 0.197659663128 :\n",
      "\n",
      "  1%|▏         | 14/1000 [06:26<5:43:07, 20.88s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15951212205 :\n",
      "\n",
      "  1%|▏         | 14/1000 [06:26<5:43:07, 20.88s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.07500000000000001, 'min_child_weight': 5.0, 'n_estimators': 348, 'subsample': 0.75, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 1.0, 'booster': 'dart'}\n",
      "\n",
      "  1%|▏         | 14/1000 [06:26<5:43:07, 20.88s/it, best loss: -0.642441860465]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 15/1000 [06:26<8:50:43, 32.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 15/1000 [06:26<8:50:41, 32.33s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76726765285 :\n",
      "\n",
      "  2%|▏         | 15/1000 [06:36<8:50:41, 32.33s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75876309677 :\n",
      "\n",
      "  2%|▏         | 15/1000 [06:36<8:50:41, 32.33s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.30000000000000004, 'min_child_weight': 6.0, 'n_estimators': 367, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.75, 'booster': 'gblinear'}\n",
      "\n",
      "  2%|▏         | 15/1000 [06:36<8:50:41, 32.33s/it, best loss: -0.642441860465]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 16/1000 [06:37<7:03:19, 25.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 16/1000 [06:36<7:03:16, 25.81s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76727880219 :\n",
      "\n",
      "  2%|▏         | 16/1000 [06:50<7:03:16, 25.81s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.7587832238 :\n",
      "\n",
      "  2%|▏         | 16/1000 [06:50<7:03:16, 25.81s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 420, 'subsample': 0.9, 'importance_type': 'total_gain', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  2%|▏         | 16/1000 [06:50<7:03:16, 25.81s/it, best loss: -0.642441860465]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 17/1000 [06:50<6:01:30, 22.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 17/1000 [06:50<6:01:28, 22.06s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.821702299314 and loss 0.660666488691 :\n",
      "\n",
      "  2%|▏         | 17/1000 [06:52<6:01:28, 22.06s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.20491124882 :\n",
      "\n",
      "  2%|▏         | 17/1000 [06:52<6:01:28, 22.06s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.225, 'min_child_weight': 2.0, 'n_estimators': 19, 'subsample': 0.75, 'importance_type': 'weight', 'max_depth': 3, 'gamma': 0.9, 'booster': 'dart'}\n",
      "\n",
      "  2%|▏         | 17/1000 [06:52<6:01:28, 22.06s/it, best loss: -0.642441860465]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 18/1000 [06:52<4:24:18, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 18/1000 [06:52<4:24:16, 16.15s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.982654296087 and loss 0.163526806672 :\n",
      "\n",
      "  2%|▏         | 18/1000 [07:32<4:24:16, 16.15s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.15372568006 :\n",
      "\n",
      "  2%|▏         | 18/1000 [07:32<4:24:16, 16.15s/it, best loss: -0.642441860465]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 231, 'subsample': 1.0, 'importance_type': 'total_gain', 'max_depth': 7, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      "  2%|▏         | 18/1000 [07:32<4:24:16, 16.15s/it, best loss: -0.642441860465]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 19/1000 [07:32<6:21:32, 23.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 19/1000 [07:32<6:21:33, 23.34s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.113096689058 :\n",
      "\n",
      "  2%|▏         | 19/1000 [07:45<6:21:33, 23.34s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.22658649202 :\n",
      "\n",
      "  2%|▏         | 19/1000 [07:45<6:21:33, 23.34s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.30000000000000004, 'min_child_weight': 5.0, 'n_estimators': 114, 'subsample': 0.75, 'importance_type': 'weight', 'max_depth': 5, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      "  2%|▏         | 19/1000 [07:45<6:21:33, 23.34s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 20/1000 [07:46<5:32:38, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 20/1000 [07:46<5:32:37, 20.37s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995159338443 and loss 0.0750734034381 :\n",
      "\n",
      "  2%|▏         | 20/1000 [08:09<5:32:37, 20.37s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.37634076999 :\n",
      "\n",
      "  2%|▏         | 20/1000 [08:09<5:32:37, 20.37s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.375, 'min_child_weight': 4.0, 'n_estimators': 206, 'subsample': 0.65, 'importance_type': 'total_cover', 'max_depth': 6, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      "  2%|▏         | 20/1000 [08:09<5:32:37, 20.37s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 21/1000 [08:10<5:49:45, 21.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 21/1000 [08:09<5:49:45, 21.44s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992739007664 and loss 0.106739537022 :\n",
      "\n",
      "  2%|▏         | 21/1000 [09:46<5:49:45, 21.44s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.21520370188 :\n",
      "\n",
      "  2%|▏         | 21/1000 [09:46<5:49:45, 21.44s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 468, 'subsample': 0.65, 'importance_type': 'gain', 'max_depth': 9, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      "  2%|▏         | 21/1000 [09:46<5:49:45, 21.44s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 22/1000 [09:47<11:57:49, 44.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 22/1000 [09:46<11:57:51, 44.04s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.117865797561 :\n",
      "\n",
      "  2%|▏         | 22/1000 [10:25<11:57:51, 44.04s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.20777294239 :\n",
      "\n",
      "  2%|▏         | 22/1000 [10:25<11:57:51, 44.04s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 190, 'subsample': 0.65, 'importance_type': 'gain', 'max_depth': 9, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      "  2%|▏         | 22/1000 [10:25<11:57:51, 44.04s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 23/1000 [10:25<11:31:41, 42.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 23/1000 [10:25<11:31:40, 42.48s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992335619201 and loss 0.117725302316 :\n",
      "\n",
      "  2%|▏         | 23/1000 [11:26<11:31:40, 42.48s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.23278905137 :\n",
      "\n",
      "  2%|▏         | 23/1000 [11:26<11:31:40, 42.48s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.30000000000000004, 'min_child_weight': 4.0, 'n_estimators': 495, 'subsample': 0.8, 'importance_type': 'total_cover', 'max_depth': 5, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      "  2%|▏         | 23/1000 [11:26<11:31:40, 42.48s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▏         | 24/1000 [11:26<12:58:54, 47.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 24/1000 [11:26<12:58:57, 47.89s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.115189518316 :\n",
      "\n",
      "  2%|▏         | 24/1000 [12:16<12:58:57, 47.89s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.2572157351 :\n",
      "\n",
      "  2%|▏         | 24/1000 [12:16<12:58:57, 47.89s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.42500000000000004, 'min_child_weight': 4.0, 'n_estimators': 408, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 5, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      "  2%|▏         | 24/1000 [12:16<12:58:57, 47.89s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   2%|▎         | 25/1000 [12:16<13:08:49, 48.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 25/1000 [12:16<13:08:50, 48.54s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.919322307382 and loss 0.356113832444 :\n",
      "\n",
      "  2%|▎         | 25/1000 [12:28<13:08:50, 48.54s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.16833311701 :\n",
      "\n",
      "  2%|▎         | 25/1000 [12:28<13:08:50, 48.54s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.17500000000000002, 'min_child_weight': 5.0, 'n_estimators': 349, 'subsample': 0.7000000000000001, 'importance_type': 'total_gain', 'max_depth': 1, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  2%|▎         | 25/1000 [12:28<13:08:50, 48.54s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 26/1000 [12:29<10:13:11, 37.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 26/1000 [12:28<10:13:10, 37.77s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.914885034288 and loss 0.368610853995 :\n",
      "\n",
      "  3%|▎         | 26/1000 [12:37<10:13:10, 37.77s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.24698654198 :\n",
      "\n",
      "  3%|▎         | 26/1000 [12:38<10:13:10, 37.77s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.25, 'min_child_weight': 5.0, 'n_estimators': 267, 'subsample': 0.5, 'importance_type': 'total_gain', 'max_depth': 1, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  3%|▎         | 26/1000 [12:38<10:13:10, 37.77s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 27/1000 [12:38<7:53:48, 29.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 27/1000 [12:38<7:53:46, 29.22s/it, best loss: -0.645348837209] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.949979830577 and loss 0.277151257918 :\n",
      "\n",
      "  3%|▎         | 27/1000 [13:02<7:53:46, 29.22s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.14302227809 :\n",
      "\n",
      "  3%|▎         | 27/1000 [13:02<7:53:46, 29.22s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.05, 'min_child_weight': 1.0, 'n_estimators': 115, 'subsample': 0.55, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 27/1000 [13:02<7:53:46, 29.22s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 28/1000 [13:02<7:29:38, 27.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 28/1000 [13:02<7:29:37, 27.75s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993142396127 and loss 0.103685434466 :\n",
      "\n",
      "  3%|▎         | 28/1000 [13:51<7:29:37, 27.75s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.18331431165 :\n",
      "\n",
      "  3%|▎         | 28/1000 [13:51<7:29:37, 27.75s/it, best loss: -0.645348837209]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 271, 'subsample': 0.6000000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 28/1000 [13:51<7:29:37, 27.75s/it, best loss: -0.645348837209]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 29/1000 [13:51<9:10:43, 34.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 29/1000 [13:51<9:10:44, 34.03s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.871722468737 and loss 0.532909705006 :\n",
      "\n",
      "  3%|▎         | 29/1000 [13:56<9:10:44, 34.03s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.19406092391 :\n",
      "\n",
      "  3%|▎         | 29/1000 [13:56<9:10:44, 34.03s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 29, 'subsample': 0.55, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 29/1000 [13:56<9:10:44, 34.03s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 30/1000 [13:56<6:49:57, 25.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 30/1000 [13:56<6:49:55, 25.36s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.758773699072 and loss 0.843956104007 :\n",
      "\n",
      "  3%|▎         | 30/1000 [14:13<6:49:55, 25.36s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.19737247282 :\n",
      "\n",
      "  3%|▎         | 30/1000 [14:13<6:49:55, 25.36s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.025, 'min_child_weight': 4.0, 'n_estimators': 196, 'subsample': 0.7000000000000001, 'importance_type': 'gain', 'max_depth': 2, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 30/1000 [14:13<6:49:55, 25.36s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 31/1000 [14:14<6:11:37, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 31/1000 [14:13<6:11:37, 23.01s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993949173054 and loss 0.0882242921454 :\n",
      "\n",
      "  3%|▎         | 31/1000 [14:58<6:11:37, 23.01s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.21494531891 :\n",
      "\n",
      "  3%|▎         | 31/1000 [14:58<6:11:37, 23.01s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 236, 'subsample': 0.8, 'importance_type': 'cover', 'max_depth': 6, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 31/1000 [14:58<6:11:37, 23.01s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 32/1000 [14:58<7:54:40, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 32/1000 [14:58<7:54:41, 29.42s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.978620411456 and loss 0.187627876824 :\n",
      "\n",
      "  3%|▎         | 32/1000 [17:11<7:54:41, 29.42s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.10695965676 :\n",
      "\n",
      "  3%|▎         | 32/1000 [17:11<7:54:41, 29.42s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.025, 'min_child_weight': 4.0, 'n_estimators': 488, 'subsample': 0.7000000000000001, 'importance_type': 'gain', 'max_depth': 8, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 32/1000 [17:11<7:54:41, 29.42s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 33/1000 [17:11<16:16:16, 60.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 33/1000 [17:11<16:16:18, 60.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993545784591 and loss 0.0964033980385 :\n",
      "\n",
      "  3%|▎         | 33/1000 [18:07<16:16:18, 60.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.18749191298 :\n",
      "\n",
      "  3%|▎         | 33/1000 [18:07<16:16:18, 60.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 320, 'subsample': 0.6000000000000001, 'importance_type': 'total_gain', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 33/1000 [18:07<16:16:18, 60.58s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 34/1000 [18:07<15:52:11, 59.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 34/1000 [18:07<15:52:11, 59.14s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.985074626866 and loss 0.158964135491 :\n",
      "\n",
      "  3%|▎         | 34/1000 [18:53<15:52:11, 59.14s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.178994399 :\n",
      "\n",
      "  3%|▎         | 34/1000 [18:53<15:52:11, 59.14s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.17500000000000002, 'min_child_weight': 2.0, 'n_estimators': 396, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 2, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      "  3%|▎         | 34/1000 [18:53<15:52:11, 59.14s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▎         | 35/1000 [18:53<14:50:02, 55.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 35/1000 [18:53<14:50:03, 55.34s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.977006857604 and loss 0.183941774535 :\n",
      "\n",
      "  4%|▎         | 35/1000 [19:30<14:50:03, 55.34s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.13828038357 :\n",
      "\n",
      "  4%|▎         | 35/1000 [19:30<14:50:03, 55.34s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 231, 'subsample': 0.6000000000000001, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      "  4%|▎         | 35/1000 [19:30<14:50:03, 55.34s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▎         | 36/1000 [19:30<13:19:07, 49.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 36/1000 [19:30<13:19:06, 49.74s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76802161749 :\n",
      "\n",
      "  4%|▎         | 36/1000 [19:42<13:19:06, 49.74s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.76007151151 :\n",
      "\n",
      "  4%|▎         | 36/1000 [19:42<13:19:06, 49.74s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 390, 'subsample': 0.5, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  4%|▎         | 36/1000 [19:42<13:19:06, 49.74s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▎         | 37/1000 [19:43<10:19:23, 38.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 37/1000 [19:42<10:19:21, 38.59s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990318676886 and loss 0.130008695302 :\n",
      "\n",
      "  4%|▎         | 37/1000 [21:08<10:19:21, 38.59s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.17984780344 :\n",
      "\n",
      "  4%|▎         | 37/1000 [21:08<10:19:21, 38.59s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 490, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  4%|▎         | 37/1000 [21:08<10:19:21, 38.59s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 38/1000 [21:08<14:03:04, 52.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 38/1000 [21:08<14:03:06, 52.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995966115369 and loss 0.0762852113624 :\n",
      "\n",
      "  4%|▍         | 38/1000 [21:34<14:03:06, 52.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.28938679906 :\n",
      "\n",
      "  4%|▍         | 38/1000 [21:34<14:03:06, 52.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.275, 'min_child_weight': 1.0, 'n_estimators': 139, 'subsample': 0.8, 'importance_type': 'total_gain', 'max_depth': 8, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      "  4%|▍         | 38/1000 [21:34<14:03:06, 52.58s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 39/1000 [21:34<11:55:28, 44.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 39/1000 [21:34<11:55:28, 44.67s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473174667205 and loss 1.77814166097 :\n",
      "\n",
      "  4%|▍         | 39/1000 [21:42<11:55:28, 44.67s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.77461973942 :\n",
      "\n",
      "  4%|▍         | 39/1000 [21:42<11:55:28, 44.67s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.05, 'min_child_weight': 3.0, 'n_estimators': 238, 'subsample': 0.6000000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'gblinear'}\n",
      "\n",
      "  4%|▍         | 39/1000 [21:42<11:55:28, 44.67s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 40/1000 [21:43<9:00:34, 33.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 40/1000 [21:42<9:00:32, 33.78s/it, best loss: -0.648255813953] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993545784591 and loss 0.112333469389 :\n",
      "\n",
      "  4%|▍         | 40/1000 [23:29<9:00:32, 33.78s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.616279069767 and loss 1.1915993066 :\n",
      "\n",
      "  4%|▍         | 40/1000 [23:29<9:00:32, 33.78s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.125, 'min_child_weight': 1.0, 'n_estimators': 466, 'subsample': 0.9, 'importance_type': 'total_gain', 'max_depth': 7, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      "  4%|▍         | 40/1000 [23:29<9:00:32, 33.78s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 41/1000 [23:29<14:49:28, 55.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 41/1000 [23:29<14:49:30, 55.65s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.846308995563 and loss 0.583536502788 :\n",
      "\n",
      "  4%|▍         | 41/1000 [23:38<14:49:30, 55.65s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.15493063038 :\n",
      "\n",
      "  4%|▍         | 41/1000 [23:38<14:49:30, 55.65s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 56, 'subsample': 0.55, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      "  4%|▍         | 41/1000 [23:38<14:49:30, 55.65s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 42/1000 [23:38<11:04:14, 41.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 42/1000 [23:38<11:04:12, 41.60s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76730168932 :\n",
      "\n",
      "  4%|▍         | 42/1000 [23:51<11:04:12, 41.60s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75882425421 :\n",
      "\n",
      "  4%|▍         | 42/1000 [23:51<11:04:12, 41.60s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.17500000000000002, 'min_child_weight': 2.0, 'n_estimators': 415, 'subsample': 0.7000000000000001, 'importance_type': 'gain', 'max_depth': 9, 'gamma': 0.75, 'booster': 'gblinear'}\n",
      "\n",
      "  4%|▍         | 42/1000 [23:51<11:04:12, 41.60s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 43/1000 [23:51<8:48:22, 33.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 43/1000 [23:51<8:48:20, 33.12s/it, best loss: -0.648255813953] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.985478015329 and loss 0.151533154196 :\n",
      "\n",
      "  4%|▍         | 43/1000 [24:07<8:48:20, 33.12s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.21628088639 :\n",
      "\n",
      "  4%|▍         | 43/1000 [24:07<8:48:20, 33.12s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.375, 'min_child_weight': 6.0, 'n_estimators': 109, 'subsample': 1.0, 'importance_type': 'total_gain', 'max_depth': 7, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      "  4%|▍         | 43/1000 [24:07<8:48:20, 33.12s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 44/1000 [24:08<7:27:23, 28.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 44/1000 [24:07<7:27:22, 28.08s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.941105284389 and loss 0.300043089569 :\n",
      "\n",
      "  4%|▍         | 44/1000 [24:47<7:27:22, 28.08s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.12591957788 :\n",
      "\n",
      "  4%|▍         | 44/1000 [24:47<7:27:22, 28.08s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 239, 'subsample': 0.6000000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  4%|▍         | 44/1000 [24:47<7:27:22, 28.08s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   4%|▍         | 45/1000 [24:48<8:24:19, 31.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 45/1000 [24:47<8:24:20, 31.69s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.893102057281 and loss 0.476700577011 :\n",
      "\n",
      "  4%|▍         | 45/1000 [24:58<8:24:20, 31.69s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.14120657319 :\n",
      "\n",
      "  4%|▍         | 45/1000 [24:58<8:24:20, 31.69s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 71, 'subsample': 0.55, 'importance_type': 'gain', 'max_depth': 6, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  4%|▍         | 45/1000 [24:58<8:24:20, 31.69s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▍         | 46/1000 [24:58<6:41:34, 25.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 46/1000 [24:58<6:41:33, 25.26s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.475594997983 and loss 1.78349869869 :\n",
      "\n",
      "  5%|▍         | 46/1000 [25:10<6:41:33, 25.26s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.78110548824 :\n",
      "\n",
      "  5%|▍         | 46/1000 [25:10<6:41:33, 25.26s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.025, 'min_child_weight': 2.0, 'n_estimators': 360, 'subsample': 0.5, 'importance_type': 'weight', 'max_depth': 4, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  5%|▍         | 46/1000 [25:10<6:41:33, 25.26s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▍         | 47/1000 [25:10<5:37:56, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 47/1000 [25:10<5:37:55, 21.28s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.959661153691 and loss 0.234112683631 :\n",
      "\n",
      "  5%|▍         | 47/1000 [25:23<5:37:55, 21.28s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.17079573386 :\n",
      "\n",
      "  5%|▍         | 47/1000 [25:23<5:37:55, 21.28s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.25, 'min_child_weight': 5.0, 'n_estimators': 182, 'subsample': 0.65, 'importance_type': 'total_gain', 'max_depth': 2, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      "  5%|▍         | 47/1000 [25:23<5:37:55, 21.28s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▍         | 48/1000 [25:24<5:01:57, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 48/1000 [25:23<5:01:58, 19.03s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987898346107 and loss 0.134415200057 :\n",
      "\n",
      "  5%|▍         | 48/1000 [25:44<5:01:58, 19.03s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.33059620227 :\n",
      "\n",
      "  5%|▍         | 48/1000 [25:44<5:01:58, 19.03s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.45, 'min_child_weight': 5.0, 'n_estimators': 256, 'subsample': 0.65, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      "  5%|▍         | 48/1000 [25:44<5:01:58, 19.03s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▍         | 49/1000 [25:44<5:07:53, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 49/1000 [25:44<5:07:53, 19.43s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76728663016 :\n",
      "\n",
      "  5%|▍         | 49/1000 [25:53<5:07:53, 19.43s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75879749327 :\n",
      "\n",
      "  5%|▍         | 49/1000 [25:53<5:07:53, 19.43s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.275, 'min_child_weight': 2.0, 'n_estimators': 271, 'subsample': 0.9500000000000001, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 1.0, 'booster': 'gblinear'}\n",
      "\n",
      "  5%|▍         | 49/1000 [25:53<5:07:53, 19.43s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▌         | 50/1000 [25:53<4:18:31, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 50/1000 [25:53<4:18:30, 16.33s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987494957644 and loss 0.119141509276 :\n",
      "\n",
      "  5%|▌         | 50/1000 [26:07<4:18:30, 16.33s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.30573388097 :\n",
      "\n",
      "  5%|▌         | 50/1000 [26:07<4:18:30, 16.33s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.35000000000000003, 'min_child_weight': 5.0, 'n_estimators': 269, 'subsample': 0.7000000000000001, 'importance_type': 'total_gain', 'max_depth': 2, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      "  5%|▌         | 50/1000 [26:07<4:18:30, 16.33s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▌         | 51/1000 [26:07<4:06:45, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 51/1000 [26:07<4:06:47, 15.60s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.901573215006 and loss 0.397537630198 :\n",
      "\n",
      "  5%|▌         | 51/1000 [26:13<4:06:47, 15.60s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.13328387229 :\n",
      "\n",
      "  5%|▌         | 51/1000 [26:13<4:06:47, 15.60s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.25, 'min_child_weight': 5.0, 'n_estimators': 85, 'subsample': 0.65, 'importance_type': 'gain', 'max_depth': 2, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      "  5%|▌         | 51/1000 [26:13<4:06:47, 15.60s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▌         | 52/1000 [26:13<3:21:14, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 52/1000 [26:13<3:21:14, 12.74s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.940298507463 and loss 0.290862217386 :\n",
      "\n",
      "  5%|▌         | 52/1000 [26:20<3:21:14, 12.74s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.616279069767 and loss 1.29561422579 :\n",
      "\n",
      "  5%|▌         | 52/1000 [26:20<3:21:14, 12.74s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.4, 'min_child_weight': 6.0, 'n_estimators': 107, 'subsample': 0.55, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  5%|▌         | 52/1000 [26:20<3:21:14, 12.74s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▌         | 53/1000 [26:21<2:56:18, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 53/1000 [26:20<2:56:17, 11.17s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986688180718 and loss 0.142588735992 :\n",
      "\n",
      "  5%|▌         | 53/1000 [26:55<2:56:17, 11.17s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.1994630282 :\n",
      "\n",
      "  5%|▌         | 53/1000 [26:55<2:56:17, 11.17s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.325, 'min_child_weight': 3.0, 'n_estimators': 482, 'subsample': 0.9500000000000001, 'importance_type': 'total_gain', 'max_depth': 3, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      "  5%|▌         | 53/1000 [26:55<2:56:17, 11.17s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▌         | 54/1000 [26:55<4:47:04, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 54/1000 [26:55<4:47:07, 18.21s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.76970735908 :\n",
      "\n",
      "  5%|▌         | 54/1000 [26:59<4:47:07, 18.21s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.76283161879 :\n",
      "\n",
      "  5%|▌         | 54/1000 [26:59<4:47:07, 18.21s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.225, 'min_child_weight': 3.0, 'n_estimators': 104, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.8500000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  5%|▌         | 54/1000 [26:59<4:47:07, 18.21s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 55/1000 [26:59<3:39:31, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 55/1000 [26:59<3:39:30, 13.94s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.722468737394 and loss 0.923688409241 :\n",
      "\n",
      "  6%|▌         | 55/1000 [27:02<3:39:30, 13.94s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.610465116279 and loss 1.2071771367 :\n",
      "\n",
      "  6%|▌         | 55/1000 [27:02<3:39:30, 13.94s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.2, 'min_child_weight': 2.0, 'n_estimators': 40, 'subsample': 0.8, 'importance_type': 'total_cover', 'max_depth': 1, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      "  6%|▌         | 55/1000 [27:02<3:39:30, 13.94s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 56/1000 [27:02<2:45:36, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 56/1000 [27:02<2:45:35, 10.52s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995159338443 and loss 0.0937707037931 :\n",
      "\n",
      "  6%|▌         | 56/1000 [27:59<2:45:35, 10.52s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.17088613232 :\n",
      "\n",
      "  6%|▌         | 56/1000 [27:59<2:45:35, 10.52s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 1.0, 'n_estimators': 290, 'subsample': 0.75, 'importance_type': 'gain', 'max_depth': 8, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  6%|▌         | 56/1000 [27:59<2:45:35, 10.52s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 57/1000 [28:00<6:27:25, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 57/1000 [27:59<6:27:27, 24.65s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.988705123033 and loss 0.147431967026 :\n",
      "\n",
      "  6%|▌         | 57/1000 [28:35<6:27:27, 24.65s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.17200030662 :\n",
      "\n",
      "  6%|▌         | 57/1000 [28:35<6:27:27, 24.65s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.225, 'min_child_weight': 6.0, 'n_estimators': 246, 'subsample': 0.9, 'importance_type': 'total_gain', 'max_depth': 9, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  6%|▌         | 57/1000 [28:35<6:27:27, 24.65s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 58/1000 [28:36<7:20:30, 28.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 58/1000 [28:35<7:20:30, 28.06s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98830173457 and loss 0.135765419253 :\n",
      "\n",
      "  6%|▌         | 58/1000 [28:54<7:20:30, 28.06s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.17897522499 :\n",
      "\n",
      "  6%|▌         | 58/1000 [28:54<7:20:30, 28.06s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.2, 'min_child_weight': 3.0, 'n_estimators': 119, 'subsample': 0.75, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.9, 'booster': 'dart'}\n",
      "\n",
      "  6%|▌         | 58/1000 [28:54<7:20:30, 28.06s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 59/1000 [28:55<6:38:42, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 59/1000 [28:54<6:38:41, 25.42s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.935457845906 and loss 0.355028007492 :\n",
      "\n",
      "  6%|▌         | 59/1000 [29:06<6:38:41, 25.42s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.14338697897 :\n",
      "\n",
      "  6%|▌         | 59/1000 [29:06<6:38:41, 25.42s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 65, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 1.0, 'booster': 'dart'}\n",
      "\n",
      "  6%|▌         | 59/1000 [29:06<6:38:41, 25.42s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 60/1000 [29:06<5:33:04, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 60/1000 [29:06<5:33:03, 21.26s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.77532732731 :\n",
      "\n",
      "  6%|▌         | 60/1000 [29:08<5:33:03, 21.26s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.77082250551 :\n",
      "\n",
      "  6%|▌         | 60/1000 [29:08<5:33:03, 21.26s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.325, 'min_child_weight': 4.0, 'n_estimators': 34, 'subsample': 0.8, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.8, 'booster': 'gblinear'}\n",
      "\n",
      "  6%|▌         | 60/1000 [29:08<5:33:03, 21.26s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 61/1000 [29:08<4:01:47, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 61/1000 [29:08<4:01:46, 15.45s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.962888261396 and loss 0.230335669495 :\n",
      "\n",
      "  6%|▌         | 61/1000 [29:27<4:01:46, 15.45s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.14114582351 :\n",
      "\n",
      "  6%|▌         | 61/1000 [29:27<4:01:46, 15.45s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 162, 'subsample': 0.6000000000000001, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      "  6%|▌         | 61/1000 [29:27<4:01:46, 15.45s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▌         | 62/1000 [29:27<4:18:46, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 62/1000 [29:27<4:18:46, 16.55s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992335619201 and loss 0.099066683735 :\n",
      "\n",
      "  6%|▌         | 62/1000 [30:14<4:18:46, 16.55s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.20827469003 :\n",
      "\n",
      "  6%|▌         | 62/1000 [30:14<4:18:46, 16.55s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 3.0, 'n_estimators': 257, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      "  6%|▌         | 62/1000 [30:14<4:18:46, 16.55s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▋         | 63/1000 [30:15<6:43:24, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▋         | 63/1000 [30:14<6:43:25, 25.83s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993545784591 and loss 0.110205474988 :\n",
      "\n",
      "  6%|▋         | 63/1000 [30:46<6:43:25, 25.83s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.27033927487 :\n",
      "\n",
      "  6%|▋         | 63/1000 [30:46<6:43:25, 25.83s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.275, 'min_child_weight': 2.0, 'n_estimators': 183, 'subsample': 0.7000000000000001, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      "  6%|▋         | 63/1000 [30:46<6:43:25, 25.83s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▋         | 64/1000 [30:47<7:10:18, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▋         | 64/1000 [30:46<7:10:18, 27.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989915288423 and loss 0.128897380994 :\n",
      "\n",
      "  6%|▋         | 64/1000 [31:16<7:10:18, 27.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.654069767442 and loss 1.13847723222 :\n",
      "\n",
      "  6%|▋         | 64/1000 [31:16<7:10:18, 27.58s/it, best loss: -0.648255813953]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.125, 'min_child_weight': 5.0, 'n_estimators': 271, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  6%|▋         | 64/1000 [31:16<7:10:18, 27.58s/it, best loss: -0.648255813953]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   6%|▋         | 65/1000 [31:16<7:18:48, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▋         | 65/1000 [31:16<7:18:48, 28.16s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.803549818475 and loss 0.683660969176 :\n",
      "\n",
      "  6%|▋         | 65/1000 [31:20<7:18:48, 28.16s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.14985618097 :\n",
      "\n",
      "  6%|▋         | 65/1000 [31:20<7:18:48, 28.16s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.125, 'min_child_weight': 5.0, 'n_estimators': 68, 'subsample': 0.65, 'importance_type': 'gain', 'max_depth': 2, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      "  6%|▋         | 65/1000 [31:20<7:18:48, 28.16s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 66/1000 [31:20<5:27:25, 21.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 66/1000 [31:20<5:27:24, 21.03s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.930213795885 and loss 0.320359439429 :\n",
      "\n",
      "  7%|▋         | 66/1000 [31:43<5:27:24, 21.03s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.1390502908 :\n",
      "\n",
      "  7%|▋         | 66/1000 [31:43<5:27:24, 21.03s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 271, 'subsample': 0.5, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 66/1000 [31:43<5:27:24, 21.03s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 67/1000 [31:44<5:37:22, 21.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 67/1000 [31:43<5:37:23, 21.70s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989915288423 and loss 0.129367165194 :\n",
      "\n",
      "  7%|▋         | 67/1000 [32:34<5:37:23, 21.70s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.18335428633 :\n",
      "\n",
      "  7%|▋         | 67/1000 [32:34<5:37:23, 21.70s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.125, 'min_child_weight': 6.0, 'n_estimators': 498, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 67/1000 [32:34<5:37:23, 21.70s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 68/1000 [32:34<7:50:59, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 68/1000 [32:34<7:51:01, 30.32s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.964098426785 and loss 0.242332824608 :\n",
      "\n",
      "  7%|▋         | 68/1000 [32:43<7:51:01, 30.32s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.15116946862 :\n",
      "\n",
      "  7%|▋         | 68/1000 [32:43<7:51:01, 30.32s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 66, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 68/1000 [32:43<7:51:01, 30.32s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 69/1000 [32:43<6:11:29, 23.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 69/1000 [32:43<6:11:28, 23.94s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991932230738 and loss 0.106666157429 :\n",
      "\n",
      "  7%|▋         | 69/1000 [33:27<6:11:28, 23.94s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.20714075749 :\n",
      "\n",
      "  7%|▋         | 69/1000 [33:27<6:11:28, 23.94s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 472, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 69/1000 [33:28<6:11:28, 23.94s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 70/1000 [33:28<7:47:38, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 70/1000 [33:28<7:47:40, 30.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.890681726503 and loss 0.443206593601 :\n",
      "\n",
      "  7%|▋         | 70/1000 [33:42<7:47:40, 30.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.1471999566 :\n",
      "\n",
      "  7%|▋         | 70/1000 [33:42<7:47:40, 30.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 409, 'subsample': 0.55, 'importance_type': 'gain', 'max_depth': 1, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 70/1000 [33:42<7:47:40, 30.17s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 71/1000 [33:43<6:36:00, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 71/1000 [33:42<6:36:01, 25.58s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98830173457 and loss 0.135609842692 :\n",
      "\n",
      "  7%|▋         | 71/1000 [34:22<6:36:01, 25.58s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15229389184 :\n",
      "\n",
      "  7%|▋         | 71/1000 [34:22<6:36:01, 25.58s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.07500000000000001, 'min_child_weight': 5.0, 'n_estimators': 432, 'subsample': 0.6000000000000001, 'importance_type': 'total_gain', 'max_depth': 8, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 71/1000 [34:22<6:36:01, 25.58s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 72/1000 [34:23<7:41:45, 29.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 72/1000 [34:22<7:41:45, 29.86s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.893102057281 and loss 0.503840002578 :\n",
      "\n",
      "  7%|▋         | 72/1000 [34:47<7:41:45, 29.86s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.619186046512 and loss 1.13945733075 :\n",
      "\n",
      "  7%|▋         | 72/1000 [34:47<7:41:45, 29.86s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.025, 'min_child_weight': 4.0, 'n_estimators': 193, 'subsample': 0.6000000000000001, 'importance_type': 'gain', 'max_depth': 9, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 72/1000 [34:47<7:41:45, 29.86s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 73/1000 [34:47<7:18:00, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 73/1000 [34:47<7:17:59, 28.35s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.955223880597 and loss 0.251313711032 :\n",
      "\n",
      "  7%|▋         | 73/1000 [34:56<7:17:59, 28.35s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.19043483602 :\n",
      "\n",
      "  7%|▋         | 73/1000 [34:56<7:17:59, 28.35s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.225, 'min_child_weight': 5.0, 'n_estimators': 182, 'subsample': 0.65, 'importance_type': 'total_gain', 'max_depth': 2, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      "  7%|▋         | 73/1000 [34:56<7:17:59, 28.35s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 74/1000 [34:56<5:46:44, 22.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 74/1000 [34:56<5:46:43, 22.47s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.93344090359 and loss 0.34239358567 :\n",
      "\n",
      "  7%|▋         | 74/1000 [35:02<5:46:43, 22.47s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.12948995119 :\n",
      "\n",
      "  7%|▋         | 74/1000 [35:02<5:46:43, 22.47s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 42, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  7%|▋         | 74/1000 [35:02<5:46:43, 22.47s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 75/1000 [35:02<4:30:53, 17.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 75/1000 [35:02<4:30:51, 17.57s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.907624041952 and loss 0.38792939004 :\n",
      "\n",
      "  8%|▊         | 75/1000 [35:19<4:30:51, 17.57s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.11896459173 :\n",
      "\n",
      "  8%|▊         | 75/1000 [35:19<4:30:51, 17.57s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 4.0, 'n_estimators': 133, 'subsample': 0.55, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  8%|▊         | 75/1000 [35:19<4:30:51, 17.57s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 76/1000 [35:19<4:26:46, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 76/1000 [35:19<4:26:45, 17.32s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.7672673811 :\n",
      "\n",
      "  8%|▊         | 76/1000 [35:26<4:26:45, 17.32s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75876261014 :\n",
      "\n",
      "  8%|▊         | 76/1000 [35:26<4:26:45, 17.32s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.5, 'min_child_weight': 4.0, 'n_estimators': 201, 'subsample': 0.55, 'importance_type': 'cover', 'max_depth': 6, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  8%|▊         | 76/1000 [35:26<4:26:45, 17.32s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 77/1000 [35:26<3:38:45, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 77/1000 [35:26<3:38:43, 14.22s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.983461073013 and loss 0.157489553168 :\n",
      "\n",
      "  8%|▊         | 77/1000 [36:43<3:38:43, 14.22s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.20860300288 :\n",
      "\n",
      "  8%|▊         | 77/1000 [36:43<3:38:43, 14.22s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.07500000000000001, 'min_child_weight': 5.0, 'n_estimators': 435, 'subsample': 0.5, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  8%|▊         | 77/1000 [36:43<3:38:43, 14.22s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 78/1000 [36:43<8:30:01, 33.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 78/1000 [36:43<8:30:03, 33.19s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.929810407422 and loss 0.315524187166 :\n",
      "\n",
      "  8%|▊         | 78/1000 [37:06<8:30:03, 33.19s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.12245657476 :\n",
      "\n",
      "  8%|▊         | 78/1000 [37:06<8:30:03, 33.19s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.05, 'min_child_weight': 3.0, 'n_estimators': 303, 'subsample': 0.5, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      "  8%|▊         | 78/1000 [37:06<8:30:03, 33.19s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 79/1000 [37:06<7:41:15, 30.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 79/1000 [37:06<7:41:16, 30.05s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.791851553046 and loss 0.780132067867 :\n",
      "\n",
      "  8%|▊         | 79/1000 [37:10<7:41:16, 30.05s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.21542103283 :\n",
      "\n",
      "  8%|▊         | 79/1000 [37:10<7:41:16, 30.05s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 30, 'subsample': 0.55, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  8%|▊         | 79/1000 [37:10<7:41:16, 30.05s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 80/1000 [37:10<5:42:07, 22.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 80/1000 [37:10<5:42:06, 22.31s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.891891891892 and loss 0.426675176898 :\n",
      "\n",
      "  8%|▊         | 80/1000 [37:42<5:42:06, 22.31s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.16191918861 :\n",
      "\n",
      "  8%|▊         | 80/1000 [37:42<5:42:06, 22.31s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.125, 'min_child_weight': 5.0, 'n_estimators': 395, 'subsample': 0.5, 'importance_type': 'cover', 'max_depth': 1, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      "  8%|▊         | 80/1000 [37:42<5:42:06, 22.31s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 81/1000 [37:42<6:25:31, 25.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 81/1000 [37:42<6:25:31, 25.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.840661557079 and loss 0.652037101519 :\n",
      "\n",
      "  8%|▊         | 81/1000 [37:46<6:25:31, 25.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.619186046512 and loss 1.16027631084 :\n",
      "\n",
      "  8%|▊         | 81/1000 [37:46<6:25:31, 25.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 44, 'subsample': 0.7000000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      "  8%|▊         | 81/1000 [37:46<6:25:31, 25.17s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 82/1000 [37:47<4:50:04, 18.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 82/1000 [37:46<4:50:03, 18.96s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.471561113352 and loss 1.84675294726 :\n",
      "\n",
      "  8%|▊         | 82/1000 [37:50<4:50:03, 18.96s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.482558139535 and loss 1.84347154122 :\n",
      "\n",
      "  8%|▊         | 82/1000 [37:50<4:50:03, 18.96s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.025, 'min_child_weight': 3.0, 'n_estimators': 86, 'subsample': 0.55, 'importance_type': 'cover', 'max_depth': 8, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  8%|▊         | 82/1000 [37:50<4:50:03, 18.96s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 83/1000 [37:50<3:39:01, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 83/1000 [37:50<3:39:01, 14.33s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.820895522388 and loss 0.750384963878 :\n",
      "\n",
      "  8%|▊         | 83/1000 [38:02<3:39:01, 14.33s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.610465116279 and loss 1.22538880287 :\n",
      "\n",
      "  8%|▊         | 83/1000 [38:02<3:39:01, 14.33s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.05, 'min_child_weight': 5.0, 'n_estimators': 74, 'subsample': 0.5, 'importance_type': 'total_cover', 'max_depth': 9, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  8%|▊         | 83/1000 [38:02<3:39:01, 14.33s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 84/1000 [38:03<3:29:21, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 84/1000 [38:02<3:29:21, 13.71s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.118668875084 :\n",
      "\n",
      "  8%|▊         | 84/1000 [38:22<3:29:21, 13.71s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.15692706449 :\n",
      "\n",
      "  8%|▊         | 84/1000 [38:22<3:29:21, 13.71s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 133, 'subsample': 0.6000000000000001, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      "  8%|▊         | 84/1000 [38:22<3:29:21, 13.71s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 85/1000 [38:23<3:58:41, 15.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 85/1000 [38:22<3:58:42, 15.65s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991932230738 and loss 0.106412264891 :\n",
      "\n",
      "  8%|▊         | 85/1000 [38:55<3:58:42, 15.65s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.21768669247 :\n",
      "\n",
      "  8%|▊         | 85/1000 [38:55<3:58:42, 15.65s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.17500000000000002, 'min_child_weight': 4.0, 'n_estimators': 302, 'subsample': 0.8, 'importance_type': 'gain', 'max_depth': 5, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      "  8%|▊         | 85/1000 [38:55<3:58:42, 15.65s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▊         | 86/1000 [38:56<5:16:34, 20.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▊         | 86/1000 [38:55<5:16:35, 20.78s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.957644211376 and loss 0.252975604683 :\n",
      "\n",
      "  9%|▊         | 86/1000 [39:06<5:16:35, 20.78s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.13554942839 :\n",
      "\n",
      "  9%|▊         | 86/1000 [39:06<5:16:35, 20.78s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 87, 'subsample': 0.65, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      "  9%|▊         | 86/1000 [39:06<5:16:35, 20.78s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▊         | 87/1000 [39:07<4:32:18, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▊         | 87/1000 [39:06<4:32:17, 17.89s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.465106897943 and loss 1.87586786122 :\n",
      "\n",
      "  9%|▊         | 87/1000 [39:09<4:32:17, 17.89s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.482558139535 and loss 1.87033174776 :\n",
      "\n",
      "  9%|▊         | 87/1000 [39:09<4:32:17, 17.89s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.025, 'min_child_weight': 5.0, 'n_estimators': 62, 'subsample': 0.75, 'importance_type': 'gain', 'max_depth': 6, 'gamma': 0.5, 'booster': 'gblinear'}\n",
      "\n",
      "  9%|▊         | 87/1000 [39:09<4:32:17, 17.89s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▉         | 88/1000 [39:09<3:21:35, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 88/1000 [39:09<3:21:34, 13.26s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.126157145714 :\n",
      "\n",
      "  9%|▉         | 88/1000 [40:18<3:21:34, 13.26s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.16714065226 :\n",
      "\n",
      "  9%|▉         | 88/1000 [40:18<3:21:34, 13.26s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 4.0, 'n_estimators': 366, 'subsample': 0.7000000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  9%|▉         | 88/1000 [40:18<3:21:34, 13.26s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▉         | 89/1000 [40:18<7:34:33, 29.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 89/1000 [40:18<7:34:35, 29.94s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.967728922953 and loss 0.217226353271 :\n",
      "\n",
      "  9%|▉         | 89/1000 [40:42<7:34:35, 29.94s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.13656164318 :\n",
      "\n",
      "  9%|▉         | 89/1000 [40:42<7:34:35, 29.94s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 5.0, 'n_estimators': 366, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      "  9%|▉         | 89/1000 [40:42<7:34:35, 29.94s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▉         | 90/1000 [40:42<7:08:08, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 90/1000 [40:42<7:08:10, 28.23s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.985881403792 and loss 0.150812979498 :\n",
      "\n",
      "  9%|▉         | 90/1000 [41:51<7:08:10, 28.23s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.14392347512 :\n",
      "\n",
      "  9%|▉         | 90/1000 [41:51<7:08:10, 28.23s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 373, 'subsample': 0.7000000000000001, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  9%|▉         | 90/1000 [41:51<7:08:10, 28.23s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▉         | 91/1000 [41:51<10:11:40, 40.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 91/1000 [41:51<10:11:40, 40.38s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.659136748689 and loss 1.14990995708 :\n",
      "\n",
      "  9%|▉         | 91/1000 [41:55<10:11:40, 40.38s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.581395348837 and loss 1.3063652301 :\n",
      "\n",
      "  9%|▉         | 91/1000 [41:55<10:11:40, 40.38s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 90, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 1, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      "  9%|▉         | 91/1000 [41:55<10:11:40, 40.38s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▉         | 92/1000 [41:56<7:28:41, 29.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 92/1000 [41:55<7:28:39, 29.65s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.936668011295 and loss 0.322070481627 :\n",
      "\n",
      "  9%|▉         | 92/1000 [42:15<7:28:39, 29.65s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.10606743703 :\n",
      "\n",
      "  9%|▉         | 92/1000 [42:15<7:28:39, 29.65s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.05, 'min_child_weight': 5.0, 'n_estimators': 242, 'subsample': 0.75, 'importance_type': 'weight', 'max_depth': 4, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      "  9%|▉         | 92/1000 [42:15<7:28:39, 29.65s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▉         | 93/1000 [42:15<6:43:51, 26.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 93/1000 [42:15<6:43:51, 26.72s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.126435713388 :\n",
      "\n",
      "  9%|▉         | 93/1000 [43:24<6:43:51, 26.72s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.15767278414 :\n",
      "\n",
      "  9%|▉         | 93/1000 [43:24<6:43:51, 26.72s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 5.0, 'n_estimators': 397, 'subsample': 0.8, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      "  9%|▉         | 93/1000 [43:24<6:43:51, 26.72s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   9%|▉         | 94/1000 [43:24<9:54:51, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 94/1000 [43:24<9:54:52, 39.40s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.47519160952 and loss 1.79659119757 :\n",
      "\n",
      "  9%|▉         | 94/1000 [43:31<9:54:52, 39.40s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.79524791262 :\n",
      "\n",
      "  9%|▉         | 94/1000 [43:31<9:54:52, 39.40s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.025, 'min_child_weight': 4.0, 'n_estimators': 217, 'subsample': 0.7000000000000001, 'importance_type': 'weight', 'max_depth': 8, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      "  9%|▉         | 94/1000 [43:31<9:54:52, 39.40s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|▉         | 95/1000 [43:32<7:29:23, 29.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 95/1000 [43:31<7:29:22, 29.79s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992335619201 and loss 0.103555397145 :\n",
      "\n",
      " 10%|▉         | 95/1000 [44:27<7:29:22, 29.79s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.22835456807 :\n",
      "\n",
      " 10%|▉         | 95/1000 [44:27<7:29:22, 29.79s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.30000000000000004, 'min_child_weight': 4.0, 'n_estimators': 356, 'subsample': 0.9500000000000001, 'importance_type': 'weight', 'max_depth': 9, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 10%|▉         | 95/1000 [44:27<7:29:22, 29.79s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|▉         | 96/1000 [44:27<9:25:35, 37.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 96/1000 [44:27<9:25:36, 37.54s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.840661557079 and loss 0.68440908226 :\n",
      "\n",
      " 10%|▉         | 96/1000 [44:33<9:25:36, 37.54s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.19575732498 :\n",
      "\n",
      " 10%|▉         | 96/1000 [44:33<9:25:36, 37.54s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.07500000000000001, 'min_child_weight': 5.0, 'n_estimators': 50, 'subsample': 0.8, 'importance_type': 'weight', 'max_depth': 5, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 10%|▉         | 96/1000 [44:33<9:25:36, 37.54s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|▉         | 97/1000 [44:33<7:02:33, 28.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 97/1000 [44:33<7:02:32, 28.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.977410246067 and loss 0.180581659337 :\n",
      "\n",
      " 10%|▉         | 97/1000 [44:38<7:02:32, 28.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.607558139535 and loss 1.25309428777 :\n",
      "\n",
      " 10%|▉         | 97/1000 [44:38<7:02:32, 28.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.45, 'min_child_weight': 6.0, 'n_estimators': 32, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 10%|▉         | 97/1000 [44:38<7:02:32, 28.08s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|▉         | 98/1000 [44:38<5:17:04, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 98/1000 [44:38<5:17:03, 21.09s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987898346107 and loss 0.134479190833 :\n",
      "\n",
      " 10%|▉         | 98/1000 [45:16<5:17:03, 21.09s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.654069767442 and loss 1.16395926484 :\n",
      "\n",
      " 10%|▉         | 98/1000 [45:16<5:17:03, 21.09s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 260, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 10%|▉         | 98/1000 [45:16<5:17:03, 21.09s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|▉         | 99/1000 [45:16<6:32:29, 26.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 99/1000 [45:16<6:32:30, 26.14s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76726792175 :\n",
      "\n",
      " 10%|▉         | 99/1000 [45:30<6:32:30, 26.14s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75876357032 :\n",
      "\n",
      " 10%|▉         | 99/1000 [45:30<6:32:30, 26.14s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.25, 'min_child_weight': 5.0, 'n_estimators': 440, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 6, 'gamma': 0.65, 'booster': 'gblinear'}\n",
      "\n",
      " 10%|▉         | 99/1000 [45:30<6:32:30, 26.14s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|█         | 100/1000 [45:30<5:38:17, 22.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 100/1000 [45:30<5:38:15, 22.55s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.142179839068 :\n",
      "\n",
      " 10%|█         | 100/1000 [45:56<5:38:15, 22.55s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.18595703401 :\n",
      "\n",
      " 10%|█         | 100/1000 [45:56<5:38:15, 22.55s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 313, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 10%|█         | 100/1000 [45:56<5:38:15, 22.55s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|█         | 101/1000 [45:57<5:55:15, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 101/1000 [45:56<5:55:17, 23.71s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.988705123033 and loss 0.136846753258 :\n",
      "\n",
      " 10%|█         | 101/1000 [46:25<5:55:17, 23.71s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.1790870021 :\n",
      "\n",
      " 10%|█         | 101/1000 [46:25<5:55:17, 23.71s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.2, 'min_child_weight': 4.0, 'n_estimators': 210, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 6, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      " 10%|█         | 101/1000 [46:25<5:55:17, 23.71s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|█         | 102/1000 [46:25<6:15:19, 25.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 102/1000 [46:25<6:15:19, 25.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987494957644 and loss 0.143704440212 :\n",
      "\n",
      " 10%|█         | 102/1000 [47:19<6:15:19, 25.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.17087599085 :\n",
      "\n",
      " 10%|█         | 102/1000 [47:19<6:15:19, 25.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.17500000000000002, 'min_child_weight': 5.0, 'n_estimators': 374, 'subsample': 0.9500000000000001, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      " 10%|█         | 102/1000 [47:19<6:15:19, 25.08s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|█         | 103/1000 [47:20<8:27:13, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 103/1000 [47:19<8:27:14, 33.93s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987494957644 and loss 0.135737594438 :\n",
      "\n",
      " 10%|█         | 103/1000 [47:41<8:27:14, 33.93s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.17325259851 :\n",
      "\n",
      " 10%|█         | 103/1000 [47:41<8:27:14, 33.93s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 243, 'subsample': 1.0, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 10%|█         | 103/1000 [47:41<8:27:14, 33.93s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|█         | 104/1000 [47:42<7:33:07, 30.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 104/1000 [47:41<7:33:06, 30.34s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.139913155914 :\n",
      "\n",
      " 10%|█         | 104/1000 [48:39<7:33:06, 30.34s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.17950897603 :\n",
      "\n",
      " 10%|█         | 104/1000 [48:39<7:33:06, 30.34s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'min_child_weight': 5.0, 'n_estimators': 373, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 10%|█         | 104/1000 [48:39<7:33:06, 30.34s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  10%|█         | 105/1000 [48:39<9:35:19, 38.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 105/1000 [48:39<9:35:20, 38.57s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.994352561517 and loss 0.0872393790142 :\n",
      "\n",
      " 10%|█         | 105/1000 [49:03<9:35:20, 38.57s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.24992944607 :\n",
      "\n",
      " 10%|█         | 105/1000 [49:03<9:35:20, 38.57s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.35000000000000003, 'min_child_weight': 3.0, 'n_estimators': 275, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 10%|█         | 105/1000 [49:03<9:35:20, 38.57s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 106/1000 [49:04<8:31:42, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 106/1000 [49:03<8:31:44, 34.34s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.140289755508 :\n",
      "\n",
      " 11%|█         | 106/1000 [50:20<8:31:44, 34.34s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.15893785092 :\n",
      "\n",
      " 11%|█         | 106/1000 [50:20<8:31:44, 34.34s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 412, 'subsample': 0.8, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 11%|█         | 106/1000 [50:20<8:31:44, 34.34s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 107/1000 [50:21<11:42:01, 47.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 107/1000 [50:21<11:42:02, 47.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76729902003 :\n",
      "\n",
      " 11%|█         | 107/1000 [50:31<11:42:02, 47.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75881967206 :\n",
      "\n",
      " 11%|█         | 107/1000 [50:31<11:42:02, 47.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.225, 'min_child_weight': 5.0, 'n_estimators': 317, 'subsample': 0.75, 'importance_type': 'weight', 'max_depth': 1, 'gamma': 0.75, 'booster': 'gblinear'}\n",
      "\n",
      " 11%|█         | 107/1000 [50:31<11:42:02, 47.17s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 108/1000 [50:31<8:57:17, 36.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 108/1000 [50:31<8:57:14, 36.14s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.969745865268 and loss 0.215201850992 :\n",
      "\n",
      " 11%|█         | 108/1000 [50:53<8:57:14, 36.14s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15904440283 :\n",
      "\n",
      " 11%|█         | 108/1000 [50:53<8:57:14, 36.14s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'min_child_weight': 6.0, 'n_estimators': 358, 'subsample': 0.9500000000000001, 'importance_type': 'weight', 'max_depth': 3, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 11%|█         | 108/1000 [50:53<8:57:14, 36.14s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 109/1000 [50:54<7:56:09, 32.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 109/1000 [50:53<7:56:09, 32.06s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990318676886 and loss 0.125971505002 :\n",
      "\n",
      " 11%|█         | 109/1000 [51:56<7:56:09, 32.06s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.21979287809 :\n",
      "\n",
      " 11%|█         | 109/1000 [51:56<7:56:09, 32.06s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 436, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 11%|█         | 109/1000 [51:56<7:56:09, 32.06s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 110/1000 [51:56<10:09:41, 41.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 110/1000 [51:56<10:09:42, 41.10s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.974586526825 and loss 0.192239955036 :\n",
      "\n",
      " 11%|█         | 110/1000 [53:38<10:09:42, 41.10s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.1081348436 :\n",
      "\n",
      " 11%|█         | 110/1000 [53:38<10:09:42, 41.10s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.025, 'min_child_weight': 3.0, 'n_estimators': 454, 'subsample': 0.75, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 11%|█         | 110/1000 [53:38<10:09:42, 41.10s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 111/1000 [53:38<14:41:45, 59.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 111/1000 [53:38<14:41:47, 59.51s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.951996772892 and loss 0.318048522195 :\n",
      "\n",
      " 11%|█         | 111/1000 [54:04<14:41:47, 59.51s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.15374817781 :\n",
      "\n",
      " 11%|█         | 111/1000 [54:04<14:41:47, 59.51s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.025, 'min_child_weight': 1.0, 'n_estimators': 184, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 11%|█         | 111/1000 [54:04<14:41:47, 59.51s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 112/1000 [54:04<12:09:49, 49.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 112/1000 [54:04<12:09:48, 49.31s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.47519160952 and loss 1.79904064445 :\n",
      "\n",
      " 11%|█         | 112/1000 [54:11<12:09:48, 49.31s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.79774488344 :\n",
      "\n",
      " 11%|█         | 112/1000 [54:11<12:09:48, 49.31s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.025, 'min_child_weight': 2.0, 'n_estimators': 202, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 6, 'gamma': 0.8500000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 11%|█         | 112/1000 [54:11<12:09:48, 49.31s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█▏        | 113/1000 [54:11<9:01:59, 36.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█▏        | 113/1000 [54:11<9:01:57, 36.66s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993949173054 and loss 0.107154647452 :\n",
      "\n",
      " 11%|█▏        | 113/1000 [55:30<9:01:57, 36.66s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.2544969584 :\n",
      "\n",
      " 11%|█▏        | 113/1000 [55:30<9:01:57, 36.66s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.275, 'min_child_weight': 2.0, 'n_estimators': 497, 'subsample': 0.8, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      " 11%|█▏        | 113/1000 [55:30<9:01:57, 36.66s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█▏        | 114/1000 [55:30<12:10:02, 49.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█▏        | 114/1000 [55:30<12:10:04, 49.44s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990318676886 and loss 0.131114374703 :\n",
      "\n",
      " 11%|█▏        | 114/1000 [56:20<12:10:04, 49.44s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.14540381912 :\n",
      "\n",
      " 11%|█▏        | 114/1000 [56:20<12:10:04, 49.44s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 404, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 11%|█▏        | 114/1000 [56:20<12:10:04, 49.44s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 115/1000 [56:20<12:10:51, 49.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 115/1000 [56:20<12:10:52, 49.55s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987494957644 and loss 0.139027376878 :\n",
      "\n",
      " 12%|█▏        | 115/1000 [56:58<12:10:52, 49.55s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.18380157759 :\n",
      "\n",
      " 12%|█▏        | 115/1000 [56:58<12:10:52, 49.55s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 279, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 12%|█▏        | 115/1000 [56:58<12:10:52, 49.55s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 116/1000 [56:59<11:21:20, 46.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 116/1000 [56:58<11:21:20, 46.24s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.974586526825 and loss 0.188651422594 :\n",
      "\n",
      " 12%|█▏        | 116/1000 [57:04<11:21:20, 46.24s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.21309923085 :\n",
      "\n",
      " 12%|█▏        | 116/1000 [57:04<11:21:20, 46.24s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.325, 'min_child_weight': 3.0, 'n_estimators': 39, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 6, 'gamma': 1.0, 'booster': 'gbtree'}\n",
      "\n",
      " 12%|█▏        | 116/1000 [57:04<11:21:20, 46.24s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 117/1000 [57:05<8:22:54, 34.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 117/1000 [57:04<8:22:52, 34.17s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993545784591 and loss 0.104512926757 :\n",
      "\n",
      " 12%|█▏        | 117/1000 [58:17<8:22:52, 34.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.23869693167 :\n",
      "\n",
      " 12%|█▏        | 117/1000 [58:17<8:22:52, 34.17s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.4, 'min_child_weight': 4.0, 'n_estimators': 487, 'subsample': 1.0, 'importance_type': 'weight', 'max_depth': 8, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 12%|█▏        | 117/1000 [58:18<8:22:52, 34.17s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 118/1000 [58:18<11:14:11, 45.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 118/1000 [58:18<11:14:12, 45.86s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.980637353772 and loss 0.17093695785 :\n",
      "\n",
      " 12%|█▏        | 118/1000 [59:07<11:14:12, 45.86s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.14943290913 :\n",
      "\n",
      " 12%|█▏        | 118/1000 [59:07<11:14:12, 45.86s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 5.0, 'n_estimators': 338, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 12%|█▏        | 118/1000 [59:07<11:14:12, 45.86s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 119/1000 [59:08<11:30:48, 47.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 119/1000 [59:07<11:30:48, 47.05s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.7697736671 :\n",
      "\n",
      " 12%|█▏        | 119/1000 [59:12<11:30:48, 47.05s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.76293678211 :\n",
      "\n",
      " 12%|█▏        | 119/1000 [59:12<11:30:48, 47.05s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.2, 'min_child_weight': 4.0, 'n_estimators': 118, 'subsample': 0.8, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 12%|█▏        | 119/1000 [59:12<11:30:48, 47.05s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 120/1000 [59:12<8:22:26, 34.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 120/1000 [59:12<8:22:24, 34.26s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993545784591 and loss 0.0896459499959 :\n",
      "\n",
      " 12%|█▏        | 120/1000 [59:34<8:22:24, 34.26s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.31899956278 :\n",
      "\n",
      " 12%|█▏        | 120/1000 [59:34<8:22:24, 34.26s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.47500000000000003, 'min_child_weight': 6.0, 'n_estimators': 153, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 12%|█▏        | 120/1000 [59:34<8:22:24, 34.26s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 121/1000 [59:35<7:30:28, 30.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 121/1000 [59:34<7:30:27, 30.75s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989108511497 and loss 0.137428302522 :\n",
      "\n",
      " 12%|█▏        | 121/1000 [1:00:39<7:30:27, 30.75s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.16511298365 :\n",
      "\n",
      " 12%|█▏        | 121/1000 [1:00:39<7:30:27, 30.75s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 413, 'subsample': 0.7000000000000001, 'importance_type': 'gain', 'max_depth': 5, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      " 12%|█▏        | 121/1000 [1:00:39<7:30:27, 30.75s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 122/1000 [1:00:39<9:57:02, 40.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 122/1000 [1:00:39<9:57:03, 40.80s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.969342476805 and loss 0.209923307028 :\n",
      "\n",
      " 12%|█▏        | 122/1000 [1:01:20<9:57:03, 40.80s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.11634279211 :\n",
      "\n",
      " 12%|█▏        | 122/1000 [1:01:20<9:57:03, 40.80s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.05, 'min_child_weight': 5.0, 'n_estimators': 260, 'subsample': 0.75, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 12%|█▏        | 122/1000 [1:01:20<9:57:03, 40.80s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 123/1000 [1:01:20<9:59:18, 41.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 123/1000 [1:01:20<9:59:18, 41.00s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.121025825119 :\n",
      "\n",
      " 12%|█▏        | 123/1000 [1:02:09<9:59:18, 41.00s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.20509612862 :\n",
      "\n",
      " 12%|█▏        | 123/1000 [1:02:09<9:59:18, 41.00s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.25, 'min_child_weight': 2.0, 'n_estimators': 386, 'subsample': 0.8500000000000001, 'importance_type': 'total_gain', 'max_depth': 6, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 12%|█▏        | 123/1000 [1:02:09<9:59:18, 41.00s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▏        | 124/1000 [1:02:09<10:33:31, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 124/1000 [1:02:09<10:33:31, 43.39s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76795072192 :\n",
      "\n",
      " 12%|█▏        | 124/1000 [1:02:18<10:33:31, 43.39s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75995276151 :\n",
      "\n",
      " 12%|█▏        | 124/1000 [1:02:18<10:33:31, 43.39s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 259, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.55, 'booster': 'gblinear'}\n",
      "\n",
      " 12%|█▏        | 124/1000 [1:02:18<10:33:31, 43.39s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  12%|█▎        | 125/1000 [1:02:18<8:01:14, 33.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 125/1000 [1:02:18<8:01:12, 33.00s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.947559499798 and loss 0.282126955236 :\n",
      "\n",
      " 12%|█▎        | 125/1000 [1:02:32<8:01:12, 33.00s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.15357080638 :\n",
      "\n",
      " 12%|█▎        | 125/1000 [1:02:32<8:01:12, 33.00s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 133, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 12%|█▎        | 125/1000 [1:02:32<8:01:12, 33.00s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 126/1000 [1:02:32<6:38:02, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 126/1000 [1:02:32<6:38:02, 27.33s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.962484872933 and loss 0.237172773678 :\n",
      "\n",
      " 13%|█▎        | 126/1000 [1:02:45<6:38:02, 27.33s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.15637708294 :\n",
      "\n",
      " 13%|█▎        | 126/1000 [1:02:45<6:38:02, 27.33s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.225, 'min_child_weight': 6.0, 'n_estimators': 244, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 13%|█▎        | 126/1000 [1:02:45<6:38:02, 27.33s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 127/1000 [1:02:46<5:36:31, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 127/1000 [1:02:45<5:36:30, 23.13s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.876563130294 and loss 0.487125680815 :\n",
      "\n",
      " 13%|█▎        | 127/1000 [1:03:27<5:36:30, 23.13s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.12418844333 :\n",
      "\n",
      " 13%|█▎        | 127/1000 [1:03:27<5:36:30, 23.13s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.07500000000000001, 'min_child_weight': 4.0, 'n_estimators': 478, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 1, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 13%|█▎        | 127/1000 [1:03:27<5:36:30, 23.13s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 128/1000 [1:03:27<6:56:50, 28.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 128/1000 [1:03:27<6:56:52, 28.68s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.980637353772 and loss 0.179348446398 :\n",
      "\n",
      " 13%|█▎        | 128/1000 [1:04:43<6:56:52, 28.68s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.1309647256 :\n",
      "\n",
      " 13%|█▎        | 128/1000 [1:04:43<6:56:52, 28.68s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.025, 'min_child_weight': 1.0, 'n_estimators': 350, 'subsample': 0.75, 'importance_type': 'total_cover', 'max_depth': 6, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 13%|█▎        | 128/1000 [1:04:43<6:56:52, 28.68s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 129/1000 [1:04:44<10:25:04, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 129/1000 [1:04:43<10:25:05, 43.06s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.969342476805 and loss 0.209876045773 :\n",
      "\n",
      " 13%|█▎        | 129/1000 [1:04:54<10:25:05, 43.06s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.1491458128 :\n",
      "\n",
      " 13%|█▎        | 129/1000 [1:04:54<10:25:05, 43.06s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 5.0, 'n_estimators': 97, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 13%|█▎        | 129/1000 [1:04:54<10:25:05, 43.06s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 130/1000 [1:04:55<8:04:51, 33.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 130/1000 [1:04:54<8:04:50, 33.44s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.76849013191 :\n",
      "\n",
      " 13%|█▎        | 130/1000 [1:05:03<8:04:50, 33.44s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.76085994159 :\n",
      "\n",
      " 13%|█▎        | 130/1000 [1:05:03<8:04:50, 33.44s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 263, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 8, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 13%|█▎        | 130/1000 [1:05:03<8:04:50, 33.44s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 131/1000 [1:05:04<6:16:57, 26.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 131/1000 [1:05:03<6:16:56, 26.03s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991932230738 and loss 0.111196875998 :\n",
      "\n",
      " 13%|█▎        | 131/1000 [1:05:53<6:16:56, 26.03s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.619186046512 and loss 1.24008103849 :\n",
      "\n",
      " 13%|█▎        | 131/1000 [1:05:53<6:16:56, 26.03s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.30000000000000004, 'min_child_weight': 3.0, 'n_estimators': 328, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 9, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 13%|█▎        | 131/1000 [1:05:53<6:16:56, 26.03s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 132/1000 [1:05:53<7:59:40, 33.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 132/1000 [1:05:53<7:59:41, 33.16s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.114221692221 :\n",
      "\n",
      " 13%|█▎        | 132/1000 [1:06:37<7:59:41, 33.16s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.22063416229 :\n",
      "\n",
      " 13%|█▎        | 132/1000 [1:06:37<7:59:41, 33.16s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.225, 'min_child_weight': 3.0, 'n_estimators': 294, 'subsample': 0.8, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      " 13%|█▎        | 132/1000 [1:06:37<7:59:41, 33.16s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 133/1000 [1:06:37<8:46:01, 36.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 133/1000 [1:06:37<8:46:02, 36.40s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.985881403792 and loss 0.147483602488 :\n",
      "\n",
      " 13%|█▎        | 133/1000 [1:07:31<8:46:02, 36.40s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.654069767442 and loss 1.17449095727 :\n",
      "\n",
      " 13%|█▎        | 133/1000 [1:07:31<8:46:02, 36.40s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'min_child_weight': 5.0, 'n_estimators': 347, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 13%|█▎        | 133/1000 [1:07:31<8:46:02, 36.40s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  13%|█▎        | 134/1000 [1:07:32<10:02:34, 41.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 134/1000 [1:07:31<10:02:35, 41.75s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987494957644 and loss 0.146105165236 :\n",
      "\n",
      " 13%|█▎        | 134/1000 [1:08:16<10:02:35, 41.75s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.18236741983 :\n",
      "\n",
      " 13%|█▎        | 134/1000 [1:08:16<10:02:35, 41.75s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 305, 'subsample': 1.0, 'importance_type': 'total_gain', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 13%|█▎        | 134/1000 [1:08:16<10:02:35, 41.75s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▎        | 135/1000 [1:08:16<10:14:09, 42.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▎        | 135/1000 [1:08:16<10:14:09, 42.60s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.984671238403 and loss 0.161165995325 :\n",
      "\n",
      " 14%|█▎        | 135/1000 [1:08:40<10:14:09, 42.60s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.16553699891 :\n",
      "\n",
      " 14%|█▎        | 135/1000 [1:08:40<10:14:09, 42.60s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 253, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 5, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 14%|█▎        | 135/1000 [1:08:40<10:14:09, 42.60s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▎        | 136/1000 [1:08:41<8:56:13, 37.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▎        | 136/1000 [1:08:40<8:56:13, 37.24s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.116065633234 :\n",
      "\n",
      " 14%|█▎        | 136/1000 [1:09:23<8:56:13, 37.24s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.23257625414 :\n",
      "\n",
      " 14%|█▎        | 136/1000 [1:09:23<8:56:13, 37.24s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.375, 'min_child_weight': 5.0, 'n_estimators': 292, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 14%|█▎        | 136/1000 [1:09:23<8:56:13, 37.24s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▎        | 137/1000 [1:09:23<9:18:21, 38.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▎        | 137/1000 [1:09:23<9:18:22, 38.82s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.77273904681 :\n",
      "\n",
      " 14%|█▎        | 137/1000 [1:09:29<9:18:22, 38.82s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.76737537168 :\n",
      "\n",
      " 14%|█▎        | 137/1000 [1:09:29<9:18:22, 38.82s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 5.0, 'n_estimators': 175, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 14%|█▎        | 137/1000 [1:09:29<9:18:22, 38.82s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 138/1000 [1:09:30<6:57:45, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 138/1000 [1:09:29<6:57:43, 29.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987898346107 and loss 0.135651422149 :\n",
      "\n",
      " 14%|█▍        | 138/1000 [1:10:51<6:57:43, 29.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.20431730451 :\n",
      "\n",
      " 14%|█▍        | 138/1000 [1:10:51<6:57:43, 29.08s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.25, 'min_child_weight': 6.0, 'n_estimators': 485, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 5, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      " 14%|█▍        | 138/1000 [1:10:51<6:57:43, 29.08s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 139/1000 [1:10:52<10:44:38, 44.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 139/1000 [1:10:51<10:44:40, 44.92s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986688180718 and loss 0.141765992439 :\n",
      "\n",
      " 14%|█▍        | 139/1000 [1:11:29<10:44:40, 44.92s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.16389752572 :\n",
      "\n",
      " 14%|█▍        | 139/1000 [1:11:29<10:44:40, 44.92s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 459, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 14%|█▍        | 139/1000 [1:11:29<10:44:40, 44.92s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 140/1000 [1:11:29<10:12:01, 42.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 140/1000 [1:11:29<10:12:02, 42.70s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.988705123033 and loss 0.135106161915 :\n",
      "\n",
      " 14%|█▍        | 140/1000 [1:12:15<10:12:02, 42.70s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.19043517294 :\n",
      "\n",
      " 14%|█▍        | 140/1000 [1:12:15<10:12:02, 42.70s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'min_child_weight': 5.0, 'n_estimators': 300, 'subsample': 0.9, 'importance_type': 'total_gain', 'max_depth': 5, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 14%|█▍        | 140/1000 [1:12:15<10:12:02, 42.70s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 141/1000 [1:12:15<10:26:10, 43.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 141/1000 [1:12:15<10:26:10, 43.74s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.820492133925 and loss 0.628676772809 :\n",
      "\n",
      " 14%|█▍        | 141/1000 [1:12:17<10:26:10, 43.74s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.619186046512 and loss 1.17859790677 :\n",
      "\n",
      " 14%|█▍        | 141/1000 [1:12:17<10:26:10, 43.74s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.275, 'min_child_weight': 6.0, 'n_estimators': 21, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 3, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 14%|█▍        | 141/1000 [1:12:17<10:26:10, 43.74s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 142/1000 [1:12:18<7:28:36, 31.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 142/1000 [1:12:17<7:28:34, 31.37s/it, best loss: -0.654069767442] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.965711980637 and loss 0.21801089504 :\n",
      "\n",
      " 14%|█▍        | 142/1000 [1:12:41<7:28:34, 31.37s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15894000623 :\n",
      "\n",
      " 14%|█▍        | 142/1000 [1:12:41<7:28:34, 31.37s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.2, 'min_child_weight': 5.0, 'n_estimators': 282, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 14%|█▍        | 142/1000 [1:12:41<7:28:34, 31.37s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 143/1000 [1:12:42<6:56:43, 29.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 143/1000 [1:12:41<6:56:43, 29.18s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473578055668 and loss 1.76920317188 :\n",
      "\n",
      " 14%|█▍        | 143/1000 [1:12:54<6:56:43, 29.18s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.76202425722 :\n",
      "\n",
      " 14%|█▍        | 143/1000 [1:12:54<6:56:43, 29.18s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.07500000000000001, 'min_child_weight': 5.0, 'n_estimators': 384, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 1, 'gamma': 0.8, 'booster': 'gblinear'}\n",
      "\n",
      " 14%|█▍        | 143/1000 [1:12:54<6:56:43, 29.18s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 144/1000 [1:12:54<5:44:32, 24.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 144/1000 [1:12:54<5:44:30, 24.15s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.115636707904 :\n",
      "\n",
      " 14%|█▍        | 144/1000 [1:13:28<5:44:30, 24.15s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.2765605737 :\n",
      "\n",
      " 14%|█▍        | 144/1000 [1:13:28<5:44:30, 24.15s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.35000000000000003, 'min_child_weight': 5.0, 'n_estimators': 247, 'subsample': 0.8500000000000001, 'importance_type': 'gain', 'max_depth': 5, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 14%|█▍        | 144/1000 [1:13:28<5:44:30, 24.15s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▍        | 145/1000 [1:13:29<6:27:58, 27.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 145/1000 [1:13:28<6:27:59, 27.23s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98830173457 and loss 0.136845381308 :\n",
      "\n",
      " 14%|█▍        | 145/1000 [1:14:47<6:27:59, 27.23s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.1566043294 :\n",
      "\n",
      " 14%|█▍        | 145/1000 [1:14:47<6:27:59, 27.23s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.05, 'min_child_weight': 3.0, 'n_estimators': 400, 'subsample': 0.8, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 14%|█▍        | 145/1000 [1:14:47<6:27:59, 27.23s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▍        | 146/1000 [1:14:48<10:09:15, 42.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▍        | 146/1000 [1:14:47<10:09:16, 42.81s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.980637353772 and loss 0.172825709369 :\n",
      "\n",
      " 15%|█▍        | 146/1000 [1:15:45<10:09:16, 42.81s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.12054921375 :\n",
      "\n",
      " 15%|█▍        | 146/1000 [1:15:45<10:09:16, 42.81s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 323, 'subsample': 0.65, 'importance_type': 'weight', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▍        | 146/1000 [1:15:45<10:09:16, 42.81s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▍        | 147/1000 [1:15:45<11:09:35, 47.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▍        | 147/1000 [1:15:45<11:09:35, 47.10s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986284792255 and loss 0.129085080633 :\n",
      "\n",
      " 15%|█▍        | 147/1000 [1:16:30<11:09:35, 47.10s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.656976744186 and loss 1.1721668892 :\n",
      "\n",
      " 15%|█▍        | 147/1000 [1:16:30<11:09:35, 47.10s/it, best loss: -0.654069767442]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 321, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▍        | 147/1000 [1:16:30<11:09:35, 47.10s/it, best loss: -0.654069767442]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▍        | 148/1000 [1:16:31<11:03:33, 46.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▍        | 148/1000 [1:16:30<11:03:33, 46.73s/it, best loss: -0.656976744186]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989108511497 and loss 0.123603187416 :\n",
      "\n",
      " 15%|█▍        | 148/1000 [1:17:07<11:03:33, 46.73s/it, best loss: -0.656976744186]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.662790697674 and loss 1.17136370404 :\n",
      "\n",
      " 15%|█▍        | 148/1000 [1:17:07<11:03:33, 46.73s/it, best loss: -0.656976744186]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 4.0, 'n_estimators': 273, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▍        | 148/1000 [1:17:07<11:03:33, 46.73s/it, best loss: -0.656976744186]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▍        | 149/1000 [1:17:08<10:21:36, 43.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▍        | 149/1000 [1:17:07<10:21:36, 43.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987898346107 and loss 0.13367103843 :\n",
      "\n",
      " 15%|█▍        | 149/1000 [1:17:47<10:21:36, 43.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.17125293905 :\n",
      "\n",
      " 15%|█▍        | 149/1000 [1:17:47<10:21:36, 43.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 273, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▍        | 149/1000 [1:17:47<10:21:36, 43.83s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▌        | 150/1000 [1:17:47<10:02:34, 42.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 150/1000 [1:17:47<10:02:34, 42.54s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987898346107 and loss 0.123133000245 :\n",
      "\n",
      " 15%|█▌        | 150/1000 [1:18:36<10:02:34, 42.54s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.18031281918 :\n",
      "\n",
      " 15%|█▌        | 150/1000 [1:18:36<10:02:34, 42.54s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 347, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▌        | 150/1000 [1:18:36<10:02:34, 42.54s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▌        | 151/1000 [1:18:36<10:29:31, 44.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 151/1000 [1:18:36<10:29:32, 44.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.988705123033 and loss 0.124420558785 :\n",
      "\n",
      " 15%|█▌        | 151/1000 [1:19:14<10:29:32, 44.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.19435155868 :\n",
      "\n",
      " 15%|█▌        | 151/1000 [1:19:14<10:29:32, 44.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 260, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▌        | 151/1000 [1:19:14<10:29:32, 44.49s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▌        | 152/1000 [1:19:14<9:59:55, 42.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 152/1000 [1:19:14<9:59:54, 42.45s/it, best loss: -0.662790697674] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989915288423 and loss 0.114741163141 :\n",
      "\n",
      " 15%|█▌        | 152/1000 [1:20:06<9:59:54, 42.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.194814394 :\n",
      "\n",
      " 15%|█▌        | 152/1000 [1:20:06<9:59:54, 42.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 4.0, 'n_estimators': 370, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▌        | 152/1000 [1:20:06<9:59:54, 42.45s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▌        | 153/1000 [1:20:06<10:39:07, 45.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 153/1000 [1:20:06<10:39:07, 45.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.137465439948 :\n",
      "\n",
      " 15%|█▌        | 153/1000 [1:21:15<10:39:07, 45.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.20546382557 :\n",
      "\n",
      " 15%|█▌        | 153/1000 [1:21:15<10:39:07, 45.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 5.0, 'n_estimators': 471, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▌        | 153/1000 [1:21:15<10:39:07, 45.27s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  15%|█▌        | 154/1000 [1:21:15<12:20:07, 52.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 154/1000 [1:21:15<12:20:07, 52.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987898346107 and loss 0.130213138444 :\n",
      "\n",
      " 15%|█▌        | 154/1000 [1:22:08<12:20:07, 52.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.19715531873 :\n",
      "\n",
      " 15%|█▌        | 154/1000 [1:22:08<12:20:07, 52.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 387, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 15%|█▌        | 154/1000 [1:22:08<12:20:07, 52.49s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 155/1000 [1:22:08<12:20:33, 52.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 155/1000 [1:22:08<12:20:33, 52.58s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.858410649455 and loss 0.594080230274 :\n",
      "\n",
      " 16%|█▌        | 155/1000 [1:22:13<12:20:33, 52.58s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.17119623224 :\n",
      "\n",
      " 16%|█▌        | 155/1000 [1:22:13<12:20:33, 52.58s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 35, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▌        | 155/1000 [1:22:13<12:20:33, 52.58s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 156/1000 [1:22:13<8:58:08, 38.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 156/1000 [1:22:13<8:58:06, 38.25s/it, best loss: -0.662790697674] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992739007664 and loss 0.0951057025408 :\n",
      "\n",
      " 16%|█▌        | 156/1000 [1:22:56<8:58:06, 38.25s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.19597798834 :\n",
      "\n",
      " 16%|█▌        | 156/1000 [1:22:56<8:58:06, 38.25s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.225, 'min_child_weight': 4.0, 'n_estimators': 261, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 8, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▌        | 156/1000 [1:22:56<8:58:06, 38.25s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 157/1000 [1:22:57<9:20:00, 39.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 157/1000 [1:22:56<9:20:01, 39.86s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.958450988302 and loss 0.242096046006 :\n",
      "\n",
      " 16%|█▌        | 157/1000 [1:23:16<9:20:01, 39.86s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.1291991832 :\n",
      "\n",
      " 16%|█▌        | 157/1000 [1:23:16<9:20:01, 39.86s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 159, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▌        | 157/1000 [1:23:16<9:20:01, 39.86s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 158/1000 [1:23:17<7:57:01, 33.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 158/1000 [1:23:16<7:57:00, 33.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993949173054 and loss 0.0922513278998 :\n",
      "\n",
      " 16%|█▌        | 158/1000 [1:23:49<7:57:00, 33.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.20168431254 :\n",
      "\n",
      " 16%|█▌        | 158/1000 [1:23:49<7:57:00, 33.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.2, 'min_child_weight': 4.0, 'n_estimators': 197, 'subsample': 0.8500000000000001, 'importance_type': 'total_gain', 'max_depth': 9, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▌        | 158/1000 [1:23:49<7:57:00, 33.99s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 159/1000 [1:23:50<7:52:08, 33.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 159/1000 [1:23:49<7:52:08, 33.68s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.966518757564 and loss 0.218050453775 :\n",
      "\n",
      " 16%|█▌        | 159/1000 [1:24:01<7:52:08, 33.68s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.15722169696 :\n",
      "\n",
      " 16%|█▌        | 159/1000 [1:24:01<7:52:08, 33.68s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 117, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 16%|█▌        | 159/1000 [1:24:01<7:52:08, 33.68s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 160/1000 [1:24:01<6:18:31, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 160/1000 [1:24:01<6:18:31, 27.04s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986688180718 and loss 0.136299071963 :\n",
      "\n",
      " 16%|█▌        | 160/1000 [1:24:49<6:18:31, 27.04s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.18136536337 :\n",
      "\n",
      " 16%|█▌        | 160/1000 [1:24:49<6:18:31, 27.04s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 5.0, 'n_estimators': 310, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▌        | 160/1000 [1:24:49<6:18:31, 27.04s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 161/1000 [1:24:49<7:44:27, 33.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 161/1000 [1:24:49<7:44:28, 33.22s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.973779749899 and loss 0.184957338077 :\n",
      "\n",
      " 16%|█▌        | 161/1000 [1:25:15<7:44:28, 33.22s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.15779726401 :\n",
      "\n",
      " 16%|█▌        | 161/1000 [1:25:15<7:44:28, 33.22s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 230, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▌        | 161/1000 [1:25:15<7:44:28, 33.22s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 162/1000 [1:25:15<7:15:47, 31.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 162/1000 [1:25:15<7:15:47, 31.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.758773699072 and loss 0.808892652976 :\n",
      "\n",
      " 16%|█▌        | 162/1000 [1:25:19<7:15:47, 31.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.607558139535 and loss 1.15687356729 :\n",
      "\n",
      " 16%|█▌        | 162/1000 [1:25:19<7:15:47, 31.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 82, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 1, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 16%|█▌        | 162/1000 [1:25:19<7:15:47, 31.20s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▋        | 163/1000 [1:25:19<5:20:17, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▋        | 163/1000 [1:25:19<5:20:16, 22.96s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.926179911255 and loss 0.360325384007 :\n",
      "\n",
      " 16%|█▋        | 163/1000 [1:25:31<5:20:16, 22.96s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.14598858797 :\n",
      "\n",
      " 16%|█▋        | 163/1000 [1:25:31<5:20:16, 22.96s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 80, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▋        | 163/1000 [1:25:31<5:20:16, 22.96s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▋        | 164/1000 [1:25:31<4:35:22, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▋        | 164/1000 [1:25:31<4:35:21, 19.76s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76825661152 :\n",
      "\n",
      " 16%|█▋        | 164/1000 [1:25:36<4:35:21, 19.76s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.76047610444 :\n",
      "\n",
      " 16%|█▋        | 164/1000 [1:25:36<4:35:21, 19.76s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.25, 'min_child_weight': 5.0, 'n_estimators': 129, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.65, 'booster': 'gblinear'}\n",
      "\n",
      " 16%|█▋        | 164/1000 [1:25:36<4:35:21, 19.76s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▋        | 165/1000 [1:25:36<3:32:38, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▋        | 165/1000 [1:25:36<3:32:37, 15.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.11636198942 :\n",
      "\n",
      " 16%|█▋        | 165/1000 [1:26:24<3:32:37, 15.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.17295962565 :\n",
      "\n",
      " 16%|█▋        | 165/1000 [1:26:24<3:32:37, 15.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.07500000000000001, 'min_child_weight': 4.0, 'n_estimators': 227, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 16%|█▋        | 165/1000 [1:26:24<3:32:37, 15.28s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 166/1000 [1:26:24<5:47:21, 24.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 166/1000 [1:26:24<5:47:22, 24.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992335619201 and loss 0.105990281027 :\n",
      "\n",
      " 17%|█▋        | 166/1000 [1:27:35<5:47:22, 24.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.19462813448 :\n",
      "\n",
      " 17%|█▋        | 166/1000 [1:27:35<5:47:22, 24.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.1, 'min_child_weight': 3.0, 'n_estimators': 334, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 8, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 17%|█▋        | 166/1000 [1:27:35<5:47:22, 24.99s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 167/1000 [1:27:35<9:00:20, 38.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 167/1000 [1:27:35<9:00:22, 38.92s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987494957644 and loss 0.13251369183 :\n",
      "\n",
      " 17%|█▋        | 167/1000 [1:28:05<9:00:22, 38.92s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.18853189304 :\n",
      "\n",
      " 17%|█▋        | 167/1000 [1:28:05<9:00:22, 38.92s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.125, 'min_child_weight': 5.0, 'n_estimators': 330, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 17%|█▋        | 167/1000 [1:28:05<9:00:22, 38.92s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 168/1000 [1:28:06<8:23:22, 36.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 168/1000 [1:28:05<8:23:22, 36.30s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.975393303752 and loss 0.190355907663 :\n",
      "\n",
      " 17%|█▋        | 168/1000 [1:28:54<8:23:22, 36.30s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.13826259582 :\n",
      "\n",
      " 17%|█▋        | 168/1000 [1:28:54<8:23:22, 36.30s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 268, 'subsample': 0.8, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 17%|█▋        | 168/1000 [1:28:54<8:23:22, 36.30s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 169/1000 [1:28:54<9:13:38, 39.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 169/1000 [1:28:54<9:13:38, 39.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989915288423 and loss 0.124866618903 :\n",
      "\n",
      " 17%|█▋        | 169/1000 [1:29:19<9:13:38, 39.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.15068212618 :\n",
      "\n",
      " 17%|█▋        | 169/1000 [1:29:19<9:13:38, 39.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.2, 'min_child_weight': 3.0, 'n_estimators': 336, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 17%|█▋        | 169/1000 [1:29:19<9:13:38, 39.97s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 170/1000 [1:29:19<8:11:18, 35.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 170/1000 [1:29:19<8:11:18, 35.52s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.976200080678 and loss 0.175863343894 :\n",
      "\n",
      " 17%|█▋        | 170/1000 [1:30:02<8:11:18, 35.52s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.17998225785 :\n",
      "\n",
      " 17%|█▋        | 170/1000 [1:30:02<8:11:18, 35.52s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 306, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 17%|█▋        | 170/1000 [1:30:02<8:11:18, 35.52s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 171/1000 [1:30:02<8:41:29, 37.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 171/1000 [1:30:02<8:41:30, 37.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76751718245 :\n",
      "\n",
      " 17%|█▋        | 171/1000 [1:30:15<8:41:30, 37.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75920417459 :\n",
      "\n",
      " 17%|█▋        | 171/1000 [1:30:15<8:41:30, 37.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 410, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 17%|█▋        | 171/1000 [1:30:15<8:41:30, 37.74s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 172/1000 [1:30:15<6:59:14, 30.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 172/1000 [1:30:15<6:59:12, 30.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.955223880597 and loss 0.262841337129 :\n",
      "\n",
      " 17%|█▋        | 172/1000 [1:30:30<6:59:12, 30.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.15939431069 :\n",
      "\n",
      " 17%|█▋        | 172/1000 [1:30:30<6:59:12, 30.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.225, 'min_child_weight': 3.0, 'n_estimators': 419, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 1, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 17%|█▋        | 172/1000 [1:30:30<6:59:12, 30.38s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 173/1000 [1:30:30<5:54:13, 25.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 173/1000 [1:30:30<5:54:14, 25.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.889874949576 and loss 0.437960546189 :\n",
      "\n",
      " 17%|█▋        | 173/1000 [1:30:47<5:54:14, 25.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.12742316278 :\n",
      "\n",
      " 17%|█▋        | 173/1000 [1:30:47<5:54:14, 25.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 4.0, 'n_estimators': 209, 'subsample': 0.8500000000000001, 'importance_type': 'total_gain', 'max_depth': 2, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 17%|█▋        | 173/1000 [1:30:47<5:54:14, 25.70s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  17%|█▋        | 174/1000 [1:30:48<5:20:20, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 174/1000 [1:30:47<5:20:19, 23.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989108511497 and loss 0.118438042895 :\n",
      "\n",
      " 17%|█▋        | 174/1000 [1:31:31<5:20:19, 23.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.18540381172 :\n",
      "\n",
      " 17%|█▋        | 174/1000 [1:31:31<5:20:19, 23.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.2, 'min_child_weight': 4.0, 'n_estimators': 324, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 17%|█▋        | 174/1000 [1:31:31<5:20:19, 23.27s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 175/1000 [1:31:31<6:42:33, 29.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 175/1000 [1:31:31<6:42:33, 29.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990318676886 and loss 0.122466572276 :\n",
      "\n",
      " 18%|█▊        | 175/1000 [1:32:13<6:42:33, 29.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.656976744186 and loss 1.18879104781 :\n",
      "\n",
      " 18%|█▊        | 175/1000 [1:32:13<6:42:33, 29.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 458, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 18%|█▊        | 175/1000 [1:32:13<6:42:33, 29.28s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 176/1000 [1:32:13<7:34:19, 33.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 176/1000 [1:32:13<7:34:20, 33.08s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995966115369 and loss 0.0671338169651 :\n",
      "\n",
      " 18%|█▊        | 176/1000 [1:33:51<7:34:20, 33.08s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.26022026684 :\n",
      "\n",
      " 18%|█▊        | 176/1000 [1:33:51<7:34:20, 33.08s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.17500000000000002, 'min_child_weight': 1.0, 'n_estimators': 458, 'subsample': 0.8, 'importance_type': 'cover', 'max_depth': 8, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 18%|█▊        | 176/1000 [1:33:51<7:34:20, 33.08s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 177/1000 [1:33:52<12:03:13, 52.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 177/1000 [1:33:51<12:03:14, 52.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.968939088342 and loss 0.214319019778 :\n",
      "\n",
      " 18%|█▊        | 177/1000 [1:33:57<12:03:14, 52.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.2061504357 :\n",
      "\n",
      " 18%|█▊        | 177/1000 [1:33:57<12:03:14, 52.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.275, 'min_child_weight': 6.0, 'n_estimators': 51, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      " 18%|█▊        | 177/1000 [1:33:57<12:03:14, 52.73s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 178/1000 [1:33:58<8:50:08, 38.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 178/1000 [1:33:57<8:50:06, 38.69s/it, best loss: -0.662790697674] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76726794761 :\n",
      "\n",
      " 18%|█▊        | 178/1000 [1:34:08<8:50:06, 38.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75876362581 :\n",
      "\n",
      " 18%|█▊        | 178/1000 [1:34:08<8:50:06, 38.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.325, 'min_child_weight': 2.0, 'n_estimators': 322, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.55, 'booster': 'gblinear'}\n",
      "\n",
      " 18%|█▊        | 178/1000 [1:34:08<8:50:06, 38.69s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 179/1000 [1:34:08<6:53:24, 30.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 179/1000 [1:34:08<6:53:23, 30.21s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995159338443 and loss 0.0808208295426 :\n",
      "\n",
      " 18%|█▊        | 179/1000 [1:35:10<6:53:23, 30.21s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.20190511357 :\n",
      "\n",
      " 18%|█▊        | 179/1000 [1:35:10<6:53:23, 30.21s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 2.0, 'n_estimators': 287, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 18%|█▊        | 179/1000 [1:35:10<6:53:23, 30.21s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 180/1000 [1:35:10<9:03:47, 39.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 180/1000 [1:35:10<9:03:48, 39.79s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.984267849939 and loss 0.148427525088 :\n",
      "\n",
      " 18%|█▊        | 180/1000 [1:35:21<9:03:48, 39.79s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.22535106858 :\n",
      "\n",
      " 18%|█▊        | 180/1000 [1:35:21<9:03:48, 39.79s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.30000000000000004, 'min_child_weight': 3.0, 'n_estimators': 100, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 18%|█▊        | 180/1000 [1:35:21<9:03:48, 39.79s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 181/1000 [1:35:21<7:05:46, 31.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 181/1000 [1:35:21<7:05:45, 31.19s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989108511497 and loss 0.122607504201 :\n",
      "\n",
      " 18%|█▊        | 181/1000 [1:35:41<7:05:45, 31.19s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.22528061537 :\n",
      "\n",
      " 18%|█▊        | 181/1000 [1:35:41<7:05:45, 31.19s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.225, 'min_child_weight': 3.0, 'n_estimators': 332, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      " 18%|█▊        | 181/1000 [1:35:41<7:05:45, 31.19s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 182/1000 [1:35:41<6:19:33, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 182/1000 [1:35:41<6:19:34, 27.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990318676886 and loss 0.1268864008 :\n",
      "\n",
      " 18%|█▊        | 182/1000 [1:35:56<6:19:34, 27.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.21755382565 :\n",
      "\n",
      " 18%|█▊        | 182/1000 [1:35:56<6:19:34, 27.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.2, 'min_child_weight': 1.0, 'n_estimators': 92, 'subsample': 0.9500000000000001, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 18%|█▊        | 182/1000 [1:35:56<6:19:34, 27.84s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 183/1000 [1:35:56<5:26:27, 23.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 183/1000 [1:35:56<5:26:27, 23.98s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995562726906 and loss 0.0868134084365 :\n",
      "\n",
      " 18%|█▊        | 183/1000 [1:36:36<5:26:27, 23.98s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.25405760751 :\n",
      "\n",
      " 18%|█▊        | 183/1000 [1:36:36<5:26:27, 23.98s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.17500000000000002, 'min_child_weight': 2.0, 'n_estimators': 321, 'subsample': 0.8, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 18%|█▊        | 183/1000 [1:36:36<5:26:27, 23.98s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 184/1000 [1:36:37<6:33:59, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 184/1000 [1:36:36<6:34:00, 28.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.99475594998 and loss 0.0859173770763 :\n",
      "\n",
      " 18%|█▊        | 184/1000 [1:37:00<6:34:00, 28.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.28040493933 :\n",
      "\n",
      " 18%|█▊        | 184/1000 [1:37:00<6:34:00, 28.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.30000000000000004, 'min_child_weight': 3.0, 'n_estimators': 164, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 6, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 18%|█▊        | 184/1000 [1:37:00<6:34:00, 28.97s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  18%|█▊        | 185/1000 [1:37:00<6:10:21, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 185/1000 [1:37:00<6:10:20, 27.26s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76787541959 :\n",
      "\n",
      " 18%|█▊        | 185/1000 [1:37:05<6:10:20, 27.26s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75982698096 :\n",
      "\n",
      " 18%|█▊        | 185/1000 [1:37:05<6:10:20, 27.26s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.25, 'min_child_weight': 3.0, 'n_estimators': 150, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 1, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 18%|█▊        | 185/1000 [1:37:05<6:10:20, 27.26s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▊        | 186/1000 [1:37:06<4:41:05, 20.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▊        | 186/1000 [1:37:05<4:41:04, 20.72s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.117930354171 :\n",
      "\n",
      " 19%|█▊        | 186/1000 [1:37:33<4:41:04, 20.72s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.17155053397 :\n",
      "\n",
      " 19%|█▊        | 186/1000 [1:37:33<4:41:04, 20.72s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.125, 'min_child_weight': 6.0, 'n_estimators': 273, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 19%|█▊        | 186/1000 [1:37:33<4:41:04, 20.72s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▊        | 187/1000 [1:37:34<5:10:24, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▊        | 187/1000 [1:37:33<5:10:24, 22.91s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.124863865299 :\n",
      "\n",
      " 19%|█▊        | 187/1000 [1:38:05<5:10:24, 22.91s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.18030974343 :\n",
      "\n",
      " 19%|█▊        | 187/1000 [1:38:05<5:10:24, 22.91s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 283, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 19%|█▊        | 187/1000 [1:38:05<5:10:24, 22.91s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▉        | 188/1000 [1:38:06<5:47:18, 25.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 188/1000 [1:38:05<5:47:18, 25.66s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991528842275 and loss 0.112332779905 :\n",
      "\n",
      " 19%|█▉        | 188/1000 [1:38:50<5:47:18, 25.66s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.20069889669 :\n",
      "\n",
      " 19%|█▉        | 188/1000 [1:38:50<5:47:18, 25.66s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 457, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 19%|█▉        | 188/1000 [1:38:50<5:47:18, 25.66s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▉        | 189/1000 [1:38:51<7:05:43, 31.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 189/1000 [1:38:50<7:05:43, 31.50s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.99475594998 and loss 0.0862689105308 :\n",
      "\n",
      " 19%|█▉        | 189/1000 [1:39:45<7:05:43, 31.50s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.28739964104 :\n",
      "\n",
      " 19%|█▉        | 189/1000 [1:39:45<7:05:43, 31.50s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.225, 'min_child_weight': 4.0, 'n_estimators': 411, 'subsample': 0.8, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 19%|█▉        | 189/1000 [1:39:45<7:05:43, 31.50s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▉        | 190/1000 [1:39:45<8:37:46, 38.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 190/1000 [1:39:45<8:37:47, 38.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992739007664 and loss 0.101114999211 :\n",
      "\n",
      " 19%|█▉        | 190/1000 [1:41:06<8:37:47, 38.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.19758496923 :\n",
      "\n",
      " 19%|█▉        | 190/1000 [1:41:06<8:37:47, 38.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.15000000000000002, 'min_child_weight': 4.0, 'n_estimators': 417, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 8, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 19%|█▉        | 190/1000 [1:41:06<8:37:47, 38.36s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▉        | 191/1000 [1:41:07<11:31:35, 51.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 191/1000 [1:41:06<11:31:36, 51.29s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.145316860847 :\n",
      "\n",
      " 19%|█▉        | 191/1000 [1:41:44<11:31:36, 51.29s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.18073881869 :\n",
      "\n",
      " 19%|█▉        | 191/1000 [1:41:44<11:31:36, 51.29s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.125, 'min_child_weight': 6.0, 'n_estimators': 251, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 19%|█▉        | 191/1000 [1:41:44<11:31:36, 51.29s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▉        | 192/1000 [1:41:45<10:36:58, 47.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 192/1000 [1:41:44<10:36:57, 47.30s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991932230738 and loss 0.112236442345 :\n",
      "\n",
      " 19%|█▉        | 192/1000 [1:42:21<10:36:57, 47.30s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.21083466127 :\n",
      "\n",
      " 19%|█▉        | 192/1000 [1:42:21<10:36:57, 47.30s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.275, 'min_child_weight': 4.0, 'n_estimators': 280, 'subsample': 0.9500000000000001, 'importance_type': 'total_gain', 'max_depth': 6, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 19%|█▉        | 192/1000 [1:42:22<10:36:57, 47.30s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▉        | 193/1000 [1:42:22<9:55:57, 44.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 193/1000 [1:42:22<9:55:56, 44.31s/it, best loss: -0.662790697674] \u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76728309686 :\n",
      "\n",
      " 19%|█▉        | 193/1000 [1:42:34<9:55:56, 44.31s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75879096563 :\n",
      "\n",
      " 19%|█▉        | 193/1000 [1:42:34<9:55:56, 44.31s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.2, 'min_child_weight': 3.0, 'n_estimators': 402, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.65, 'booster': 'gblinear'}\n",
      "\n",
      " 19%|█▉        | 193/1000 [1:42:34<9:55:56, 44.31s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▉        | 194/1000 [1:42:35<7:48:35, 34.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 194/1000 [1:42:34<7:48:34, 34.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993545784591 and loss 0.090548968134 :\n",
      "\n",
      " 19%|█▉        | 194/1000 [1:43:17<7:48:34, 34.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.24095653815 :\n",
      "\n",
      " 19%|█▉        | 194/1000 [1:43:17<7:48:34, 34.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.25, 'min_child_weight': 3.0, 'n_estimators': 297, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 4, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 19%|█▉        | 194/1000 [1:43:17<7:48:34, 34.88s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|█▉        | 195/1000 [1:43:17<8:18:49, 37.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 195/1000 [1:43:17<8:18:50, 37.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.845502218637 and loss 0.57991733825 :\n",
      "\n",
      " 20%|█▉        | 195/1000 [1:43:24<8:18:50, 37.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.15753347466 :\n",
      "\n",
      " 20%|█▉        | 195/1000 [1:43:24<8:18:50, 37.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 61, 'subsample': 0.75, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 20%|█▉        | 195/1000 [1:43:24<8:18:50, 37.18s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|█▉        | 196/1000 [1:43:25<6:18:13, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 196/1000 [1:43:24<6:18:12, 28.22s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98951189996 and loss 0.12329652122 :\n",
      "\n",
      " 20%|█▉        | 196/1000 [1:43:40<6:18:12, 28.22s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.17223025943 :\n",
      "\n",
      " 20%|█▉        | 196/1000 [1:43:40<6:18:12, 28.22s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.17500000000000002, 'min_child_weight': 4.0, 'n_estimators': 108, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 6, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 20%|█▉        | 196/1000 [1:43:40<6:18:12, 28.22s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|█▉        | 197/1000 [1:43:40<5:26:25, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 197/1000 [1:43:40<5:26:25, 24.39s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.87858007261 and loss 0.554880407758 :\n",
      "\n",
      " 20%|█▉        | 197/1000 [1:43:53<5:26:25, 24.39s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.18227005824 :\n",
      "\n",
      " 20%|█▉        | 197/1000 [1:43:53<5:26:25, 24.39s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 1.0, 'learning_rate': 0.05, 'min_child_weight': 2.0, 'n_estimators': 78, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 20%|█▉        | 197/1000 [1:43:53<5:26:25, 24.39s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|█▉        | 198/1000 [1:43:53<4:39:41, 20.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 198/1000 [1:43:53<4:39:41, 20.92s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986688180718 and loss 0.141914009256 :\n",
      "\n",
      " 20%|█▉        | 198/1000 [1:44:12<4:39:41, 20.92s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.18719902793 :\n",
      "\n",
      " 20%|█▉        | 198/1000 [1:44:12<4:39:41, 20.92s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 155, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 20%|█▉        | 198/1000 [1:44:12<4:39:41, 20.92s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|█▉        | 199/1000 [1:44:13<4:35:11, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 199/1000 [1:44:12<4:35:11, 20.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.773327604 :\n",
      "\n",
      " 20%|█▉        | 199/1000 [1:44:20<4:35:11, 20.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.76820597029 :\n",
      "\n",
      " 20%|█▉        | 199/1000 [1:44:20<4:35:11, 20.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 225, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 1, 'gamma': 0.8, 'booster': 'gblinear'}\n",
      "\n",
      " 20%|█▉        | 199/1000 [1:44:20<4:35:11, 20.61s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|██        | 200/1000 [1:44:20<3:42:30, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 200/1000 [1:44:20<3:42:29, 16.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.874142799516 and loss 0.537268292493 :\n",
      "\n",
      " 20%|██        | 200/1000 [1:44:23<3:42:29, 16.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.1674813589 :\n",
      "\n",
      " 20%|██        | 200/1000 [1:44:23<3:42:29, 16.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.225, 'min_child_weight': 6.0, 'n_estimators': 23, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 5, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 20%|██        | 200/1000 [1:44:23<3:42:29, 16.69s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|██        | 201/1000 [1:44:24<2:48:12, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 201/1000 [1:44:23<2:48:12, 12.63s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.133460001478 :\n",
      "\n",
      " 20%|██        | 201/1000 [1:44:55<2:48:12, 12.63s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.19340589377 :\n",
      "\n",
      " 20%|██        | 201/1000 [1:44:55<2:48:12, 12.63s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.2, 'min_child_weight': 5.0, 'n_estimators': 214, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 20%|██        | 201/1000 [1:44:55<2:48:12, 12.63s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|██        | 202/1000 [1:44:55<4:03:46, 18.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 202/1000 [1:44:55<4:03:48, 18.33s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.954013715208 and loss 0.269561948201 :\n",
      "\n",
      " 20%|██        | 202/1000 [1:46:25<4:03:48, 18.33s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.12908243788 :\n",
      "\n",
      " 20%|██        | 202/1000 [1:46:25<4:03:48, 18.33s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.025, 'min_child_weight': 6.0, 'n_estimators': 450, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 20%|██        | 202/1000 [1:46:25<4:03:48, 18.33s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|██        | 203/1000 [1:46:25<8:49:31, 39.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 203/1000 [1:46:25<8:49:33, 39.87s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.981444130698 and loss 0.155759178115 :\n",
      "\n",
      " 20%|██        | 203/1000 [1:47:19<8:49:33, 39.87s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.19302587239 :\n",
      "\n",
      " 20%|██        | 203/1000 [1:47:19<8:49:33, 39.87s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 458, 'subsample': 0.8, 'importance_type': 'total_gain', 'max_depth': 2, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 20%|██        | 203/1000 [1:47:19<8:49:33, 39.87s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|██        | 204/1000 [1:47:20<9:46:31, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 204/1000 [1:47:19<9:46:32, 44.21s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.978620411456 and loss 0.187092259316 :\n",
      "\n",
      " 20%|██        | 204/1000 [1:47:44<9:46:32, 44.21s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.16308918927 :\n",
      "\n",
      " 20%|██        | 204/1000 [1:47:44<9:46:32, 44.21s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 208, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 4, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 20%|██        | 204/1000 [1:47:44<9:46:32, 44.21s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  20%|██        | 205/1000 [1:47:45<8:29:37, 38.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 205/1000 [1:47:44<8:29:37, 38.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.121528380062 :\n",
      "\n",
      " 20%|██        | 205/1000 [1:48:34<8:29:37, 38.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.17363394577 :\n",
      "\n",
      " 20%|██        | 205/1000 [1:48:34<8:29:37, 38.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 474, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 6, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 20%|██        | 205/1000 [1:48:34<8:29:37, 38.46s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 206/1000 [1:48:34<9:12:53, 41.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 206/1000 [1:48:34<9:12:54, 41.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76755710435 :\n",
      "\n",
      " 21%|██        | 206/1000 [1:48:43<9:12:54, 41.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75927503721 :\n",
      "\n",
      " 21%|██        | 206/1000 [1:48:43<9:12:54, 41.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 2.0, 'n_estimators': 274, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 8, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 21%|██        | 206/1000 [1:48:43<9:12:54, 41.78s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 207/1000 [1:48:43<7:03:01, 32.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 207/1000 [1:48:43<7:03:00, 32.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.117410595467 :\n",
      "\n",
      " 21%|██        | 207/1000 [1:49:06<7:03:00, 32.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.16284198421 :\n",
      "\n",
      " 21%|██        | 207/1000 [1:49:06<7:03:00, 32.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.15000000000000002, 'min_child_weight': 4.0, 'n_estimators': 125, 'subsample': 0.9500000000000001, 'importance_type': 'weight', 'max_depth': 9, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 21%|██        | 207/1000 [1:49:06<7:03:00, 32.01s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 208/1000 [1:49:06<6:26:26, 29.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 208/1000 [1:49:06<6:26:25, 29.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98305768455 and loss 0.16260901813 :\n",
      "\n",
      " 21%|██        | 208/1000 [1:49:25<6:26:25, 29.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.19996777738 :\n",
      "\n",
      " 21%|██        | 208/1000 [1:49:25<6:26:25, 29.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.25, 'min_child_weight': 5.0, 'n_estimators': 142, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      " 21%|██        | 208/1000 [1:49:25<6:26:25, 29.27s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 209/1000 [1:49:25<5:44:53, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 209/1000 [1:49:25<5:44:53, 26.16s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.979023799919 and loss 0.172818047801 :\n",
      "\n",
      " 21%|██        | 209/1000 [1:50:00<5:44:53, 26.16s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.14556649599 :\n",
      "\n",
      " 21%|██        | 209/1000 [1:50:00<5:44:53, 26.16s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 405, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 21%|██        | 209/1000 [1:50:00<5:44:53, 26.16s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 210/1000 [1:50:00<6:20:25, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 210/1000 [1:50:00<6:20:26, 28.89s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986688180718 and loss 0.136140489922 :\n",
      "\n",
      " 21%|██        | 210/1000 [1:50:12<6:20:26, 28.89s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.23091554998 :\n",
      "\n",
      " 21%|██        | 210/1000 [1:50:12<6:20:26, 28.89s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.4, 'min_child_weight': 5.0, 'n_estimators': 98, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 21%|██        | 210/1000 [1:50:12<6:20:26, 28.89s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 211/1000 [1:50:12<5:12:14, 23.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 211/1000 [1:50:12<5:12:13, 23.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.949979830577 and loss 0.283887401951 :\n",
      "\n",
      " 21%|██        | 211/1000 [1:51:12<5:12:13, 23.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.11389630634 :\n",
      "\n",
      " 21%|██        | 211/1000 [1:51:12<5:12:13, 23.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.025, 'min_child_weight': 4.0, 'n_estimators': 321, 'subsample': 0.8, 'importance_type': 'total_gain', 'max_depth': 6, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 21%|██        | 211/1000 [1:51:12<5:12:13, 23.74s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 212/1000 [1:51:12<7:35:44, 34.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 212/1000 [1:51:12<7:35:45, 34.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987494957644 and loss 0.144248963932 :\n",
      "\n",
      " 21%|██        | 212/1000 [1:51:27<7:35:45, 34.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.18105700706 :\n",
      "\n",
      " 21%|██        | 212/1000 [1:51:27<7:35:45, 34.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.225, 'min_child_weight': 6.0, 'n_estimators': 131, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 21%|██        | 212/1000 [1:51:27<7:35:45, 34.70s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██▏       | 213/1000 [1:51:27<6:17:29, 28.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██▏       | 213/1000 [1:51:27<6:17:28, 28.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.7676182869 :\n",
      "\n",
      " 21%|██▏       | 213/1000 [1:51:39<6:17:28, 28.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75938031413 :\n",
      "\n",
      " 21%|██▏       | 213/1000 [1:51:39<6:17:28, 28.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 378, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 3, 'gamma': 0.6000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 21%|██▏       | 213/1000 [1:51:39<6:17:28, 28.78s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██▏       | 214/1000 [1:51:40<5:12:04, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██▏       | 214/1000 [1:51:39<5:12:03, 23.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.984671238403 and loss 0.149386998015 :\n",
      "\n",
      " 21%|██▏       | 214/1000 [1:52:31<5:12:03, 23.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.20295978989 :\n",
      "\n",
      " 21%|██▏       | 214/1000 [1:52:31<5:12:03, 23.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.2, 'min_child_weight': 5.0, 'n_estimators': 347, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.8, 'booster': 'dart'}\n",
      "\n",
      " 21%|██▏       | 214/1000 [1:52:31<5:12:03, 23.82s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 215/1000 [1:52:31<6:59:50, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 215/1000 [1:52:31<6:59:51, 32.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.908027430415 and loss 0.398169576745 :\n",
      "\n",
      " 22%|██▏       | 215/1000 [1:52:35<6:59:51, 32.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.16291600167 :\n",
      "\n",
      " 22%|██▏       | 215/1000 [1:52:35<6:59:51, 32.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.15000000000000002, 'min_child_weight': 1.0, 'n_estimators': 38, 'subsample': 0.75, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 22%|██▏       | 215/1000 [1:52:35<6:59:51, 32.09s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 216/1000 [1:52:35<5:10:14, 23.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 216/1000 [1:52:35<5:10:13, 23.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.144682345537 :\n",
      "\n",
      " 22%|██▏       | 216/1000 [1:53:26<5:10:13, 23.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.17007597041 :\n",
      "\n",
      " 22%|██▏       | 216/1000 [1:53:26<5:10:13, 23.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.07500000000000001, 'min_child_weight': 6.0, 'n_estimators': 499, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 22%|██▏       | 216/1000 [1:53:26<5:10:13, 23.74s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 217/1000 [1:53:26<6:56:51, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 217/1000 [1:53:26<6:56:53, 31.95s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.985881403792 and loss 0.147266752008 :\n",
      "\n",
      " 22%|██▏       | 217/1000 [1:54:09<6:56:53, 31.95s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.17893994117 :\n",
      "\n",
      " 22%|██▏       | 217/1000 [1:54:09<6:56:53, 31.95s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'min_child_weight': 5.0, 'n_estimators': 284, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 22%|██▏       | 217/1000 [1:54:09<6:56:53, 31.95s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 218/1000 [1:54:10<7:40:49, 35.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 218/1000 [1:54:09<7:40:49, 35.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.981847519161 and loss 0.162123148579 :\n",
      "\n",
      " 22%|██▏       | 218/1000 [1:54:29<7:40:49, 35.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.18192224061 :\n",
      "\n",
      " 22%|██▏       | 218/1000 [1:54:29<7:40:49, 35.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.17500000000000002, 'min_child_weight': 3.0, 'n_estimators': 314, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 2, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 22%|██▏       | 218/1000 [1:54:29<7:40:49, 35.36s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 219/1000 [1:54:29<6:38:25, 30.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 219/1000 [1:54:29<6:38:26, 30.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98830173457 and loss 0.135726744357 :\n",
      "\n",
      " 22%|██▏       | 219/1000 [1:55:27<6:38:26, 30.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.20934369319 :\n",
      "\n",
      " 22%|██▏       | 219/1000 [1:55:27<6:38:26, 30.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.275, 'min_child_weight': 6.0, 'n_estimators': 393, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 22%|██▏       | 219/1000 [1:55:27<6:38:26, 30.61s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 220/1000 [1:55:27<8:23:32, 38.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 220/1000 [1:55:27<8:23:32, 38.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.77285018596 :\n",
      "\n",
      " 22%|██▏       | 220/1000 [1:55:33<8:23:32, 38.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.76752985106 :\n",
      "\n",
      " 22%|██▏       | 220/1000 [1:55:33<8:23:32, 38.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 173, 'subsample': 0.8, 'importance_type': 'total_gain', 'max_depth': 1, 'gamma': 0.75, 'booster': 'gblinear'}\n",
      "\n",
      " 22%|██▏       | 220/1000 [1:55:33<8:23:32, 38.73s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 221/1000 [1:55:33<6:16:09, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 221/1000 [1:55:33<6:16:07, 28.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.948769665188 and loss 0.284697626594 :\n",
      "\n",
      " 22%|██▏       | 221/1000 [1:56:02<6:16:07, 28.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.11935088867 :\n",
      "\n",
      " 22%|██▏       | 221/1000 [1:56:02<6:16:07, 28.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.05, 'min_child_weight': 4.0, 'n_estimators': 224, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 4, 'gamma': 0.5, 'booster': 'dart'}\n",
      "\n",
      " 22%|██▏       | 221/1000 [1:56:02<6:16:07, 28.97s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 222/1000 [1:56:03<6:18:19, 29.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 222/1000 [1:56:02<6:18:19, 29.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989108511497 and loss 0.12493898162 :\n",
      "\n",
      " 22%|██▏       | 222/1000 [1:56:10<6:18:19, 29.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.24647583599 :\n",
      "\n",
      " 22%|██▏       | 222/1000 [1:56:10<6:18:19, 29.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.47500000000000003, 'min_child_weight': 5.0, 'n_estimators': 54, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 22%|██▏       | 222/1000 [1:56:10<6:18:19, 29.18s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 223/1000 [1:56:10<4:52:51, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 223/1000 [1:56:10<4:52:50, 22.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993142396127 and loss 0.101070400662 :\n",
      "\n",
      " 22%|██▏       | 223/1000 [1:57:07<4:52:50, 22.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.19172630762 :\n",
      "\n",
      " 22%|██▏       | 223/1000 [1:57:07<4:52:50, 22.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 430, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 6, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 22%|██▏       | 223/1000 [1:57:07<4:52:50, 22.61s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 224/1000 [1:57:07<7:05:27, 32.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 224/1000 [1:57:07<7:05:29, 32.90s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.988705123033 and loss 0.123168955673 :\n",
      "\n",
      " 22%|██▏       | 224/1000 [1:58:17<7:05:29, 32.90s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.18756220795 :\n",
      "\n",
      " 22%|██▏       | 224/1000 [1:58:17<7:05:29, 32.90s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 443, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 22%|██▏       | 224/1000 [1:58:17<7:05:29, 32.90s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▎       | 225/1000 [1:58:18<9:31:18, 44.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▎       | 225/1000 [1:58:17<9:31:19, 44.23s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992335619201 and loss 0.104701499018 :\n",
      "\n",
      " 22%|██▎       | 225/1000 [1:58:53<9:31:19, 44.23s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.21036665835 :\n",
      "\n",
      " 22%|██▎       | 225/1000 [1:58:53<9:31:19, 44.23s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 368, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 22%|██▎       | 225/1000 [1:58:53<9:31:19, 44.23s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 226/1000 [1:58:53<8:56:51, 41.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 226/1000 [1:58:53<8:56:51, 41.62s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991528842275 and loss 0.115165337633 :\n",
      "\n",
      " 23%|██▎       | 226/1000 [1:59:27<8:56:51, 41.62s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.19180816107 :\n",
      "\n",
      " 23%|██▎       | 226/1000 [1:59:27<8:56:51, 41.62s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 343, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 23%|██▎       | 226/1000 [1:59:27<8:56:51, 41.62s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 227/1000 [1:59:27<8:25:56, 39.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 227/1000 [1:59:27<8:25:57, 39.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.117742485692 :\n",
      "\n",
      " 23%|██▎       | 227/1000 [1:59:47<8:25:57, 39.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.19913717145 :\n",
      "\n",
      " 23%|██▎       | 227/1000 [1:59:47<8:25:57, 39.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.225, 'min_child_weight': 4.0, 'n_estimators': 156, 'subsample': 0.8500000000000001, 'importance_type': 'weight', 'max_depth': 8, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 23%|██▎       | 227/1000 [1:59:47<8:25:57, 39.27s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 228/1000 [1:59:47<7:12:57, 33.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 228/1000 [1:59:47<7:12:56, 33.65s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.77361964575 :\n",
      "\n",
      " 23%|██▎       | 228/1000 [1:59:55<7:12:56, 33.65s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.76861833716 :\n",
      "\n",
      " 23%|██▎       | 228/1000 [1:59:55<7:12:56, 33.65s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 4.0, 'n_estimators': 219, 'subsample': 0.8, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.8, 'booster': 'gblinear'}\n",
      "\n",
      " 23%|██▎       | 228/1000 [1:59:55<7:12:56, 33.65s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 229/1000 [1:59:55<5:31:50, 25.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 229/1000 [1:59:55<5:31:48, 25.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.964098426785 and loss 0.216369580469 :\n",
      "\n",
      " 23%|██▎       | 229/1000 [2:00:09<5:31:48, 25.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15263277452 :\n",
      "\n",
      " 23%|██▎       | 229/1000 [2:00:09<5:31:48, 25.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 111, 'subsample': 0.75, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 23%|██▎       | 229/1000 [2:00:09<5:31:48, 25.82s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 230/1000 [2:00:10<4:48:37, 22.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 230/1000 [2:00:09<4:48:37, 22.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991528842275 and loss 0.121181946489 :\n",
      "\n",
      " 23%|██▎       | 230/1000 [2:01:00<4:48:37, 22.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.20339987428 :\n",
      "\n",
      " 23%|██▎       | 230/1000 [2:01:01<4:48:37, 22.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.25, 'min_child_weight': 4.0, 'n_estimators': 365, 'subsample': 0.7000000000000001, 'importance_type': 'weight', 'max_depth': 6, 'gamma': 0.8500000000000001, 'booster': 'dart'}\n",
      "\n",
      " 23%|██▎       | 230/1000 [2:01:01<4:48:37, 22.49s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 231/1000 [2:01:01<6:38:22, 31.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 231/1000 [2:01:01<6:38:23, 31.08s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986688180718 and loss 0.146528867062 :\n",
      "\n",
      " 23%|██▎       | 231/1000 [2:01:57<6:38:23, 31.08s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.17575944402 :\n",
      "\n",
      " 23%|██▎       | 231/1000 [2:01:57<6:38:23, 31.08s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 354, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 23%|██▎       | 231/1000 [2:01:57<6:38:23, 31.08s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 232/1000 [2:01:58<8:16:24, 38.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 232/1000 [2:01:57<8:16:25, 38.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.935861234369 and loss 0.31597158489 :\n",
      "\n",
      " 23%|██▎       | 232/1000 [2:02:08<8:16:25, 38.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.12724195492 :\n",
      "\n",
      " 23%|██▎       | 232/1000 [2:02:09<8:16:25, 38.78s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 158, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 23%|██▎       | 232/1000 [2:02:09<8:16:25, 38.78s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 233/1000 [2:02:09<6:30:10, 30.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 233/1000 [2:02:09<6:30:09, 30.52s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989915288423 and loss 0.118740066529 :\n",
      "\n",
      " 23%|██▎       | 233/1000 [2:02:33<6:30:09, 30.52s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.17379840487 :\n",
      "\n",
      " 23%|██▎       | 233/1000 [2:02:33<6:30:09, 30.52s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.30000000000000004, 'min_child_weight': 5.0, 'n_estimators': 185, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 5, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 23%|██▎       | 233/1000 [2:02:33<6:30:09, 30.52s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  23%|██▎       | 234/1000 [2:02:33<6:06:00, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 234/1000 [2:02:33<6:05:59, 28.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76751386168 :\n",
      "\n",
      " 23%|██▎       | 234/1000 [2:02:41<6:05:59, 28.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75919985665 :\n",
      "\n",
      " 23%|██▎       | 234/1000 [2:02:41<6:05:59, 28.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.2, 'min_child_weight': 1.0, 'n_estimators': 245, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.5, 'booster': 'gblinear'}\n",
      "\n",
      " 23%|██▎       | 234/1000 [2:02:41<6:05:59, 28.67s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▎       | 235/1000 [2:02:42<4:48:15, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 235/1000 [2:02:41<4:48:14, 22.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991125453812 and loss 0.115380613289 :\n",
      "\n",
      " 24%|██▎       | 235/1000 [2:03:02<4:48:14, 22.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.17760558355 :\n",
      "\n",
      " 24%|██▎       | 235/1000 [2:03:02<4:48:14, 22.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.17500000000000002, 'min_child_weight': 5.0, 'n_estimators': 186, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 7, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▎       | 235/1000 [2:03:02<4:48:14, 22.61s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▎       | 236/1000 [2:03:02<4:39:44, 21.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 236/1000 [2:03:02<4:39:45, 21.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.975393303752 and loss 0.177845964135 :\n",
      "\n",
      " 24%|██▎       | 236/1000 [2:03:28<4:39:45, 21.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.616279069767 and loss 1.2841822 :\n",
      "\n",
      " 24%|██▎       | 236/1000 [2:03:28<4:39:45, 21.97s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.42500000000000004, 'min_child_weight': 4.0, 'n_estimators': 333, 'subsample': 0.9, 'importance_type': 'weight', 'max_depth': 1, 'gamma': 0.55, 'booster': 'dart'}\n",
      "\n",
      " 24%|██▎       | 236/1000 [2:03:28<4:39:45, 21.97s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▎       | 237/1000 [2:03:29<4:57:06, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 237/1000 [2:03:28<4:57:07, 23.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.932634126664 and loss 0.330039150905 :\n",
      "\n",
      " 24%|██▎       | 237/1000 [2:03:46<4:57:07, 23.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.13180038138 :\n",
      "\n",
      " 24%|██▎       | 237/1000 [2:03:46<4:57:07, 23.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'min_child_weight': 3.0, 'n_estimators': 222, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 24%|██▎       | 237/1000 [2:03:46<4:57:07, 23.36s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 238/1000 [2:03:47<4:35:48, 21.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 238/1000 [2:03:46<4:35:48, 21.72s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.972972972973 and loss 0.194933110569 :\n",
      "\n",
      " 24%|██▍       | 238/1000 [2:04:04<4:35:48, 21.72s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.65988372093 and loss 1.15011743226 :\n",
      "\n",
      " 24%|██▍       | 238/1000 [2:04:04<4:35:48, 21.72s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.125, 'min_child_weight': 6.0, 'n_estimators': 207, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 238/1000 [2:04:04<4:35:48, 21.72s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 239/1000 [2:04:05<4:21:48, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 239/1000 [2:04:04<4:21:48, 20.64s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.984267849939 and loss 0.159734884443 :\n",
      "\n",
      " 24%|██▍       | 239/1000 [2:04:28<4:21:48, 20.64s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.17960903009 :\n",
      "\n",
      " 24%|██▍       | 239/1000 [2:04:28<4:21:48, 20.64s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.225, 'min_child_weight': 6.0, 'n_estimators': 291, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 239/1000 [2:04:28<4:21:48, 20.64s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 240/1000 [2:04:28<4:31:45, 21.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 240/1000 [2:04:28<4:31:45, 21.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.970956030658 and loss 0.205515684459 :\n",
      "\n",
      " 24%|██▍       | 240/1000 [2:04:40<4:31:45, 21.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.16269807384 :\n",
      "\n",
      " 24%|██▍       | 240/1000 [2:04:40<4:31:45, 21.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.2, 'min_child_weight': 6.0, 'n_estimators': 126, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 240/1000 [2:04:40<4:31:45, 21.45s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 241/1000 [2:04:40<3:54:34, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 241/1000 [2:04:40<3:54:33, 18.54s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.979830576846 and loss 0.174137859931 :\n",
      "\n",
      " 24%|██▍       | 241/1000 [2:05:04<3:54:33, 18.54s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.15525217749 :\n",
      "\n",
      " 24%|██▍       | 241/1000 [2:05:04<3:54:33, 18.54s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.125, 'min_child_weight': 6.0, 'n_estimators': 298, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 241/1000 [2:05:04<3:54:33, 18.54s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 242/1000 [2:05:04<4:14:55, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 242/1000 [2:05:04<4:14:55, 20.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.983461073013 and loss 0.160460419613 :\n",
      "\n",
      " 24%|██▍       | 242/1000 [2:05:41<4:14:55, 20.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.17680867978 :\n",
      "\n",
      " 24%|██▍       | 242/1000 [2:05:41<4:14:55, 20.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 484, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 242/1000 [2:05:41<4:14:55, 20.18s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 243/1000 [2:05:41<5:18:50, 25.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 243/1000 [2:05:41<5:18:51, 25.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.986688180718 and loss 0.138510577762 :\n",
      "\n",
      " 24%|██▍       | 243/1000 [2:06:20<5:18:51, 25.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.619186046512 and loss 1.22818205426 :\n",
      "\n",
      " 24%|██▍       | 243/1000 [2:06:20<5:18:51, 25.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.325, 'min_child_weight': 6.0, 'n_estimators': 462, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 243/1000 [2:06:20<5:18:51, 25.27s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 244/1000 [2:06:20<6:10:14, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 244/1000 [2:06:20<6:10:15, 29.39s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.976200080678 and loss 0.191900078068 :\n",
      "\n",
      " 24%|██▍       | 244/1000 [2:06:34<6:10:15, 29.39s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.18467897525 :\n",
      "\n",
      " 24%|██▍       | 244/1000 [2:06:34<6:10:15, 29.39s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.275, 'min_child_weight': 6.0, 'n_estimators': 171, 'subsample': 1.0, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 244/1000 [2:06:34<6:10:15, 29.39s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  24%|██▍       | 245/1000 [2:06:34<5:12:16, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 245/1000 [2:06:34<5:12:15, 24.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.983864461476 and loss 0.163719345272 :\n",
      "\n",
      " 24%|██▍       | 245/1000 [2:07:03<5:12:15, 24.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.15985606057 :\n",
      "\n",
      " 24%|██▍       | 245/1000 [2:07:03<5:12:15, 24.82s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 361, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 24%|██▍       | 245/1000 [2:07:03<5:12:15, 24.82s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▍       | 246/1000 [2:07:04<5:29:15, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▍       | 246/1000 [2:07:03<5:29:16, 26.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.984671238403 and loss 0.155072119945 :\n",
      "\n",
      " 25%|██▍       | 246/1000 [2:07:39<5:29:16, 26.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.21558143567 :\n",
      "\n",
      " 25%|██▍       | 246/1000 [2:07:39<5:29:16, 26.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.325, 'min_child_weight': 6.0, 'n_estimators': 423, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▍       | 246/1000 [2:07:39<5:29:16, 26.20s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▍       | 247/1000 [2:07:39<6:03:00, 28.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▍       | 247/1000 [2:07:39<6:03:00, 28.93s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.891891891892 and loss 0.475608409259 :\n",
      "\n",
      " 25%|██▍       | 247/1000 [2:07:53<6:03:00, 28.93s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.14207687638 :\n",
      "\n",
      " 25%|██▍       | 247/1000 [2:07:53<6:03:00, 28.93s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.05, 'min_child_weight': 6.0, 'n_estimators': 138, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▍       | 247/1000 [2:07:53<6:03:00, 28.93s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▍       | 248/1000 [2:07:54<5:09:46, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▍       | 248/1000 [2:07:53<5:09:45, 24.71s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.946752722872 and loss 0.286096298785 :\n",
      "\n",
      " 25%|██▍       | 248/1000 [2:08:24<5:09:45, 24.71s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.15012430619 :\n",
      "\n",
      " 25%|██▍       | 248/1000 [2:08:24<5:09:45, 24.71s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.025, 'min_child_weight': 2.0, 'n_estimators': 352, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▍       | 248/1000 [2:08:24<5:09:45, 24.71s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▍       | 249/1000 [2:08:24<5:30:00, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▍       | 249/1000 [2:08:24<5:30:00, 26.37s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990722065349 and loss 0.123729509332 :\n",
      "\n",
      " 25%|██▍       | 249/1000 [2:09:10<5:30:00, 26.37s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.15874871313 :\n",
      "\n",
      " 25%|██▍       | 249/1000 [2:09:10<5:30:00, 26.37s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.125, 'min_child_weight': 5.0, 'n_estimators': 403, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▍       | 249/1000 [2:09:10<5:30:00, 26.37s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▌       | 250/1000 [2:09:10<6:43:25, 32.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 250/1000 [2:09:10<6:43:25, 32.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.990318676886 and loss 0.128411028425 :\n",
      "\n",
      " 25%|██▌       | 250/1000 [2:10:01<6:43:25, 32.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.1680630355 :\n",
      "\n",
      " 25%|██▌       | 250/1000 [2:10:01<6:43:25, 32.27s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.25, 'min_child_weight': 6.0, 'n_estimators': 475, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 8, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▌       | 250/1000 [2:10:01<6:43:25, 32.27s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▌       | 251/1000 [2:10:01<7:53:27, 37.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 251/1000 [2:10:01<7:53:28, 37.93s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.985074626866 and loss 0.148945500156 :\n",
      "\n",
      " 25%|██▌       | 251/1000 [2:10:26<7:53:28, 37.93s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.18489081446 :\n",
      "\n",
      " 25%|██▌       | 251/1000 [2:10:26<7:53:28, 37.93s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 5.0, 'n_estimators': 315, 'subsample': 0.9500000000000001, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▌       | 251/1000 [2:10:26<7:53:28, 37.93s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▌       | 252/1000 [2:10:26<7:03:41, 33.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 252/1000 [2:10:26<7:03:41, 33.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.146774319898 :\n",
      "\n",
      " 25%|██▌       | 252/1000 [2:10:55<7:03:41, 33.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.22213212667 :\n",
      "\n",
      " 25%|██▌       | 252/1000 [2:10:55<7:03:41, 33.99s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 369, 'subsample': 0.65, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▌       | 252/1000 [2:10:55<7:03:41, 33.99s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▌       | 253/1000 [2:10:55<6:44:17, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 253/1000 [2:10:55<6:44:17, 32.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.980233965309 and loss 0.163876461817 :\n",
      "\n",
      " 25%|██▌       | 253/1000 [2:11:10<6:44:17, 32.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.21435932227 :\n",
      "\n",
      " 25%|██▌       | 253/1000 [2:11:10<6:44:17, 32.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.225, 'min_child_weight': 6.0, 'n_estimators': 211, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▌       | 253/1000 [2:11:10<6:44:17, 32.47s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▌       | 254/1000 [2:11:11<5:41:01, 27.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 254/1000 [2:11:10<5:41:00, 27.43s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.974183138362 and loss 0.195040906476 :\n",
      "\n",
      " 25%|██▌       | 254/1000 [2:11:23<5:41:00, 27.43s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.16228431435 :\n",
      "\n",
      " 25%|██▌       | 254/1000 [2:11:23<5:41:00, 27.43s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.2, 'min_child_weight': 5.0, 'n_estimators': 143, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 25%|██▌       | 254/1000 [2:11:23<5:41:00, 27.43s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 255/1000 [2:11:23<4:45:49, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 255/1000 [2:11:23<4:45:49, 23.02s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.96208148447 and loss 0.237305641601 :\n",
      "\n",
      " 26%|██▌       | 255/1000 [2:11:43<4:45:49, 23.02s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.656976744186 and loss 1.15411404785 :\n",
      "\n",
      " 26%|██▌       | 255/1000 [2:11:43<4:45:49, 23.02s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 2.0, 'n_estimators': 371, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 255/1000 [2:11:43<4:45:49, 23.02s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 256/1000 [2:11:43<4:34:46, 22.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 256/1000 [2:11:43<4:34:47, 22.16s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.840258168616 and loss 0.578827206402 :\n",
      "\n",
      " 26%|██▌       | 256/1000 [2:11:49<4:34:47, 22.16s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.14360894286 :\n",
      "\n",
      " 26%|██▌       | 256/1000 [2:11:49<4:34:47, 22.16s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'min_child_weight': 2.0, 'n_estimators': 91, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 1.0, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 256/1000 [2:11:49<4:34:47, 22.16s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 257/1000 [2:11:49<3:32:58, 17.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 257/1000 [2:11:49<3:32:58, 17.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.899959661154 and loss 0.415214615519 :\n",
      "\n",
      " 26%|██▌       | 257/1000 [2:12:00<3:32:58, 17.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.13648814201 :\n",
      "\n",
      " 26%|██▌       | 257/1000 [2:12:00<3:32:58, 17.20s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.07500000000000001, 'min_child_weight': 1.0, 'n_estimators': 194, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 257/1000 [2:12:00<3:32:58, 17.20s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 258/1000 [2:12:00<3:10:30, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 258/1000 [2:12:00<3:10:30, 15.40s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.954820492134 and loss 0.271221871564 :\n",
      "\n",
      " 26%|██▌       | 258/1000 [2:12:20<3:10:30, 15.40s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.1483686809 :\n",
      "\n",
      " 26%|██▌       | 258/1000 [2:12:20<3:10:30, 15.40s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 1.0, 'n_estimators': 371, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 258/1000 [2:12:20<3:10:30, 15.40s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 259/1000 [2:12:20<3:26:11, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 259/1000 [2:12:20<3:26:11, 16.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.959257765228 and loss 0.24297582859 :\n",
      "\n",
      " 26%|██▌       | 259/1000 [2:12:35<3:26:11, 16.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15436247859 :\n",
      "\n",
      " 26%|██▌       | 259/1000 [2:12:35<3:26:11, 16.70s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.125, 'min_child_weight': 1.0, 'n_estimators': 266, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 259/1000 [2:12:35<3:26:11, 16.70s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 260/1000 [2:12:35<3:21:07, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 260/1000 [2:12:35<3:21:07, 16.31s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.768051633723 and loss 0.834608333541 :\n",
      "\n",
      " 26%|██▌       | 260/1000 [2:12:45<3:21:07, 16.31s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.607558139535 and loss 1.21004968258 :\n",
      "\n",
      " 26%|██▌       | 260/1000 [2:12:45<3:21:07, 16.31s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.025, 'min_child_weight': 2.0, 'n_estimators': 181, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 260/1000 [2:12:45<3:21:07, 16.31s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 261/1000 [2:12:46<2:58:21, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 261/1000 [2:12:45<2:58:20, 14.48s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.897942718838 and loss 0.433700768374 :\n",
      "\n",
      " 26%|██▌       | 261/1000 [2:12:53<2:58:20, 14.48s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.14708797598 :\n",
      "\n",
      " 26%|██▌       | 261/1000 [2:12:53<2:58:20, 14.48s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.125, 'min_child_weight': 2.0, 'n_estimators': 124, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 261/1000 [2:12:53<2:58:20, 14.48s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▌       | 262/1000 [2:12:53<2:33:06, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 262/1000 [2:12:53<2:33:06, 12.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.938281565147 and loss 0.311666857785 :\n",
      "\n",
      " 26%|██▌       | 262/1000 [2:13:02<2:33:06, 12.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.1383414651 :\n",
      "\n",
      " 26%|██▌       | 262/1000 [2:13:02<2:33:06, 12.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 2.0, 'n_estimators': 160, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▌       | 262/1000 [2:13:02<2:33:06, 12.45s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▋       | 263/1000 [2:13:02<2:20:38, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▋       | 263/1000 [2:13:02<2:20:37, 11.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.94392900363 and loss 0.302273108988 :\n",
      "\n",
      " 26%|██▋       | 263/1000 [2:13:26<2:20:37, 11.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.13240890654 :\n",
      "\n",
      " 26%|██▋       | 263/1000 [2:13:26<2:20:37, 11.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.05, 'min_child_weight': 1.0, 'n_estimators': 453, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▋       | 263/1000 [2:13:26<2:20:37, 11.45s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▋       | 264/1000 [2:13:26<3:05:22, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▋       | 264/1000 [2:13:26<3:05:23, 15.11s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.948769665188 and loss 0.288559308156 :\n",
      "\n",
      " 26%|██▋       | 264/1000 [2:13:49<3:05:23, 15.11s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.14788429711 :\n",
      "\n",
      " 26%|██▋       | 264/1000 [2:13:49<3:05:23, 15.11s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 1.0, 'n_estimators': 407, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▋       | 264/1000 [2:13:49<3:05:23, 15.11s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  26%|██▋       | 265/1000 [2:13:49<3:33:49, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▋       | 265/1000 [2:13:49<3:33:49, 17.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.96208148447 and loss 0.24186065181 :\n",
      "\n",
      " 26%|██▋       | 265/1000 [2:14:07<3:33:49, 17.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.14936906472 :\n",
      "\n",
      " 26%|██▋       | 265/1000 [2:14:07<3:33:49, 17.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 1.0, 'n_estimators': 331, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 26%|██▋       | 265/1000 [2:14:07<3:33:49, 17.46s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 266/1000 [2:14:07<3:36:11, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 266/1000 [2:14:07<3:36:11, 17.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.883017345704 and loss 0.464933465796 :\n",
      "\n",
      " 27%|██▋       | 266/1000 [2:14:16<3:36:11, 17.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.13972481571 :\n",
      "\n",
      " 27%|██▋       | 266/1000 [2:14:16<3:36:11, 17.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.17500000000000002, 'min_child_weight': 2.0, 'n_estimators': 229, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 1, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 266/1000 [2:14:16<3:36:11, 17.67s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 267/1000 [2:14:16<3:03:38, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 267/1000 [2:14:16<3:03:38, 15.03s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98305768455 and loss 0.160354990247 :\n",
      "\n",
      " 27%|██▋       | 267/1000 [2:14:34<3:03:38, 15.03s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.16567844704 :\n",
      "\n",
      " 27%|██▋       | 267/1000 [2:14:34<3:03:38, 15.03s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 207, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 267/1000 [2:14:34<3:03:38, 15.03s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 268/1000 [2:14:35<3:16:18, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 268/1000 [2:14:34<3:16:17, 16.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98830173457 and loss 0.138532976571 :\n",
      "\n",
      " 27%|██▋       | 268/1000 [2:15:30<3:16:17, 16.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.17047353381 :\n",
      "\n",
      " 27%|██▋       | 268/1000 [2:15:30<3:16:17, 16.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.125, 'min_child_weight': 2.0, 'n_estimators': 363, 'subsample': 0.9500000000000001, 'importance_type': 'total_cover', 'max_depth': 8, 'gamma': 1.0, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 268/1000 [2:15:30<3:16:17, 16.09s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 269/1000 [2:15:30<5:39:18, 27.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 269/1000 [2:15:30<5:39:19, 27.85s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.994352561517 and loss 0.117781212368 :\n",
      "\n",
      " 27%|██▋       | 269/1000 [2:16:37<5:39:19, 27.85s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.15075907749 :\n",
      "\n",
      " 27%|██▋       | 269/1000 [2:16:37<5:39:19, 27.85s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.1, 'min_child_weight': 1.0, 'n_estimators': 438, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 9, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 269/1000 [2:16:37<5:39:19, 27.85s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 270/1000 [2:16:37<8:03:25, 39.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 270/1000 [2:16:37<8:03:26, 39.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.855990318677 and loss 0.544748290674 :\n",
      "\n",
      " 27%|██▋       | 270/1000 [2:16:46<8:03:26, 39.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.14207398171 :\n",
      "\n",
      " 27%|██▋       | 270/1000 [2:16:46<8:03:26, 39.73s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 140, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 270/1000 [2:16:46<8:03:26, 39.73s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 271/1000 [2:16:46<6:09:48, 30.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 271/1000 [2:16:46<6:09:47, 30.44s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.947559499798 and loss 0.281171003852 :\n",
      "\n",
      " 27%|██▋       | 271/1000 [2:17:05<6:09:47, 30.44s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.11954311018 :\n",
      "\n",
      " 27%|██▋       | 271/1000 [2:17:05<6:09:47, 30.44s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.05, 'min_child_weight': 3.0, 'n_estimators': 207, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.8, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 271/1000 [2:17:05<6:09:47, 30.44s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 272/1000 [2:17:06<5:28:55, 27.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 272/1000 [2:17:05<5:28:55, 27.11s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.882210568778 and loss 0.476271569171 :\n",
      "\n",
      " 27%|██▋       | 272/1000 [2:17:10<5:28:55, 27.11s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15997631384 :\n",
      "\n",
      " 27%|██▋       | 272/1000 [2:17:10<5:28:55, 27.11s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.125, 'min_child_weight': 1.0, 'n_estimators': 49, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 272/1000 [2:17:10<5:28:55, 27.11s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 273/1000 [2:17:10<4:07:26, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 273/1000 [2:17:10<4:07:25, 20.42s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.963291649859 and loss 0.231889599555 :\n",
      "\n",
      " 27%|██▋       | 273/1000 [2:17:28<4:07:25, 20.42s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.14084631437 :\n",
      "\n",
      " 27%|██▋       | 273/1000 [2:17:28<4:07:25, 20.42s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 191, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.9500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 273/1000 [2:17:28<4:07:25, 20.42s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 274/1000 [2:17:29<4:00:03, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 274/1000 [2:17:28<4:00:03, 19.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.721661960468 and loss 1.0919719857 :\n",
      "\n",
      " 27%|██▋       | 274/1000 [2:17:35<4:00:03, 19.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.601744186047 and loss 1.34156769315 :\n",
      "\n",
      " 27%|██▋       | 274/1000 [2:17:35<4:00:03, 19.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.025, 'min_child_weight': 2.0, 'n_estimators': 101, 'subsample': 0.9500000000000001, 'importance_type': 'total_gain', 'max_depth': 2, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 27%|██▋       | 274/1000 [2:17:35<4:00:03, 19.84s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 275/1000 [2:17:35<3:11:00, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 275/1000 [2:17:35<3:11:00, 15.81s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.47519160952 and loss 1.79265598275 :\n",
      "\n",
      " 28%|██▊       | 275/1000 [2:17:37<3:11:00, 15.81s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.79087569591 :\n",
      "\n",
      " 28%|██▊       | 275/1000 [2:17:37<3:11:00, 15.81s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 36, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 1, 'gamma': 0.8500000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 28%|██▊       | 275/1000 [2:17:37<3:11:00, 15.81s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 276/1000 [2:17:37<2:21:47, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 276/1000 [2:17:37<2:21:46, 11.75s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.982250907624 and loss 0.166409639336 :\n",
      "\n",
      " 28%|██▊       | 276/1000 [2:18:11<2:21:46, 11.75s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.15263405897 :\n",
      "\n",
      " 28%|██▊       | 276/1000 [2:18:11<2:21:46, 11.75s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.125, 'min_child_weight': 6.0, 'n_estimators': 448, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 276/1000 [2:18:11<2:21:46, 11.75s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 277/1000 [2:18:11<3:41:25, 18.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 277/1000 [2:18:11<3:41:27, 18.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.968535699879 and loss 0.211050299401 :\n",
      "\n",
      " 28%|██▊       | 277/1000 [2:18:18<3:41:27, 18.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.15717424664 :\n",
      "\n",
      " 28%|██▊       | 277/1000 [2:18:18<3:41:27, 18.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 2.0, 'n_estimators': 67, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 277/1000 [2:18:18<3:41:27, 18.38s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 278/1000 [2:18:18<2:59:46, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 278/1000 [2:18:18<2:59:45, 14.94s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.989915288423 and loss 0.123754992441 :\n",
      "\n",
      " 28%|██▊       | 278/1000 [2:18:58<2:59:45, 14.94s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.15907648579 :\n",
      "\n",
      " 28%|██▊       | 278/1000 [2:18:58<2:59:45, 14.94s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 293, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 8, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 278/1000 [2:18:58<2:59:45, 14.94s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 279/1000 [2:18:58<4:29:49, 22.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 279/1000 [2:18:58<4:29:50, 22.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.993142396127 and loss 0.0929406176861 :\n",
      "\n",
      " 28%|██▊       | 279/1000 [2:19:37<4:29:50, 22.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.18432662581 :\n",
      "\n",
      " 28%|██▊       | 279/1000 [2:19:37<4:29:50, 22.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 5.0, 'n_estimators': 340, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 279/1000 [2:19:37<4:29:50, 22.46s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 280/1000 [2:19:37<5:29:27, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 280/1000 [2:19:37<5:29:28, 27.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.473981444131 and loss 1.76853570019 :\n",
      "\n",
      " 28%|██▊       | 280/1000 [2:19:43<5:29:28, 27.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.76093785421 :\n",
      "\n",
      " 28%|██▊       | 280/1000 [2:19:43<5:29:28, 27.46s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.17500000000000002, 'min_child_weight': 4.0, 'n_estimators': 179, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 28%|██▊       | 280/1000 [2:19:43<5:29:28, 27.46s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 281/1000 [2:19:44<4:12:41, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 281/1000 [2:19:43<4:12:40, 21.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.961678096006 and loss 0.241913277167 :\n",
      "\n",
      " 28%|██▊       | 281/1000 [2:20:06<4:12:40, 21.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.1545053022 :\n",
      "\n",
      " 28%|██▊       | 281/1000 [2:20:06<4:12:40, 21.09s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.2, 'min_child_weight': 3.0, 'n_estimators': 465, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 1.0, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 281/1000 [2:20:06<4:12:40, 21.09s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 282/1000 [2:20:06<4:17:11, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 282/1000 [2:20:06<4:17:12, 21.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.939895119 and loss 0.308681149676 :\n",
      "\n",
      " 28%|██▊       | 282/1000 [2:20:22<4:17:12, 21.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.13853967943 :\n",
      "\n",
      " 28%|██▊       | 282/1000 [2:20:22<4:17:12, 21.49s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.05, 'min_child_weight': 1.0, 'n_estimators': 213, 'subsample': 0.9, 'importance_type': 'gain', 'max_depth': 3, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 282/1000 [2:20:22<4:17:12, 21.49s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 283/1000 [2:20:23<3:59:14, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 283/1000 [2:20:22<3:59:13, 20.02s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.954820492134 and loss 0.259027009234 :\n",
      "\n",
      " 28%|██▊       | 283/1000 [2:20:38<3:59:13, 20.02s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.12962787499 :\n",
      "\n",
      " 28%|██▊       | 283/1000 [2:20:38<3:59:13, 20.02s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'min_child_weight': 6.0, 'n_estimators': 172, 'subsample': 1.0, 'importance_type': 'total_gain', 'max_depth': 4, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 283/1000 [2:20:38<3:59:13, 20.02s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 284/1000 [2:20:38<3:43:04, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 284/1000 [2:20:38<3:43:04, 18.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.47519160952 and loss 1.8057979199 :\n",
      "\n",
      " 28%|██▊       | 284/1000 [2:20:39<3:43:04, 18.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.80405662092 :\n",
      "\n",
      " 28%|██▊       | 284/1000 [2:20:39<3:43:04, 18.69s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 6.0, 'n_estimators': 25, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 1, 'gamma': 0.8, 'booster': 'gblinear'}\n",
      "\n",
      " 28%|██▊       | 284/1000 [2:20:39<3:43:04, 18.69s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  28%|██▊       | 285/1000 [2:20:40<2:41:52, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 285/1000 [2:20:39<2:41:51, 13.58s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987898346107 and loss 0.133522878412 :\n",
      "\n",
      " 28%|██▊       | 285/1000 [2:21:11<2:41:51, 13.58s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.16495937643 :\n",
      "\n",
      " 28%|██▊       | 285/1000 [2:21:11<2:41:51, 13.58s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.125, 'min_child_weight': 5.0, 'n_estimators': 389, 'subsample': 0.8500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 28%|██▊       | 285/1000 [2:21:11<2:41:51, 13.58s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▊       | 286/1000 [2:21:11<3:44:38, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▊       | 286/1000 [2:21:11<3:44:40, 18.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.947156111335 and loss 0.277880033525 :\n",
      "\n",
      " 29%|██▊       | 286/1000 [2:21:33<3:44:40, 18.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.12718505748 :\n",
      "\n",
      " 29%|██▊       | 286/1000 [2:21:33<3:44:40, 18.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 371, 'subsample': 0.9500000000000001, 'importance_type': 'gain', 'max_depth': 2, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 29%|██▊       | 286/1000 [2:21:33<3:44:40, 18.88s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▊       | 287/1000 [2:21:33<3:55:16, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▊       | 287/1000 [2:21:33<3:55:17, 19.80s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98830173457 and loss 0.12219733023 :\n",
      "\n",
      " 29%|██▊       | 287/1000 [2:22:11<3:55:17, 19.80s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.651162790698 and loss 1.20069455885 :\n",
      "\n",
      " 29%|██▊       | 287/1000 [2:22:11<3:55:17, 19.80s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.17500000000000002, 'min_child_weight': 4.0, 'n_estimators': 434, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 29%|██▊       | 287/1000 [2:22:11<3:55:17, 19.80s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 288/1000 [2:22:12<5:02:16, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 288/1000 [2:22:11<5:02:17, 25.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98830173457 and loss 0.144304203331 :\n",
      "\n",
      " 29%|██▉       | 288/1000 [2:23:00<5:02:17, 25.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.1485022307 :\n",
      "\n",
      " 29%|██▉       | 288/1000 [2:23:00<5:02:17, 25.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.125, 'min_child_weight': 5.0, 'n_estimators': 339, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 9, 'gamma': 0.9, 'booster': 'gbtree'}\n",
      "\n",
      " 29%|██▉       | 288/1000 [2:23:00<5:02:17, 25.47s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 289/1000 [2:23:00<6:24:32, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 289/1000 [2:23:00<6:24:32, 32.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.47519160952 and loss 1.78743256131 :\n",
      "\n",
      " 29%|██▉       | 289/1000 [2:23:02<6:24:32, 32.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.7852093646 :\n",
      "\n",
      " 29%|██▉       | 289/1000 [2:23:02<6:24:32, 32.45s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.2, 'min_child_weight': 4.0, 'n_estimators': 31, 'subsample': 0.9, 'importance_type': 'cover', 'max_depth': 8, 'gamma': 0.75, 'booster': 'gblinear'}\n",
      "\n",
      " 29%|██▉       | 289/1000 [2:23:02<6:24:32, 32.45s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 290/1000 [2:23:02<4:35:31, 23.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 290/1000 [2:23:02<4:35:29, 23.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.983864461476 and loss 0.157225322444 :\n",
      "\n",
      " 29%|██▉       | 290/1000 [2:23:38<4:35:29, 23.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.15072401462 :\n",
      "\n",
      " 29%|██▉       | 290/1000 [2:23:38<4:35:29, 23.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'min_child_weight': 6.0, 'n_estimators': 426, 'subsample': 1.0, 'importance_type': 'gain', 'max_depth': 4, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 29%|██▉       | 290/1000 [2:23:38<4:35:29, 23.28s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 291/1000 [2:23:38<5:19:11, 27.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 291/1000 [2:23:38<5:19:12, 27.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991932230738 and loss 0.111215402191 :\n",
      "\n",
      " 29%|██▉       | 291/1000 [2:24:17<5:19:12, 27.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.642441860465 and loss 1.16646821808 :\n",
      "\n",
      " 29%|██▉       | 291/1000 [2:24:17<5:19:12, 27.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.05, 'min_child_weight': 2.0, 'n_estimators': 414, 'subsample': 0.9, 'importance_type': 'total_gain', 'max_depth': 5, 'gamma': 0.5, 'booster': 'gbtree'}\n",
      "\n",
      " 29%|██▉       | 291/1000 [2:24:17<5:19:12, 27.01s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 292/1000 [2:24:17<6:01:12, 30.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 292/1000 [2:24:17<6:01:13, 30.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.958450988302 and loss 0.246643739282 :\n",
      "\n",
      " 29%|██▉       | 292/1000 [2:24:29<6:01:13, 30.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.15686136509 :\n",
      "\n",
      " 29%|██▉       | 292/1000 [2:24:29<6:01:13, 30.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.225, 'min_child_weight': 5.0, 'n_estimators': 200, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.8500000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 29%|██▉       | 292/1000 [2:24:29<6:01:13, 30.61s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 293/1000 [2:24:29<4:54:39, 25.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 293/1000 [2:24:29<4:54:38, 25.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.975796692215 and loss 0.184702880128 :\n",
      "\n",
      " 29%|██▉       | 293/1000 [2:24:42<4:54:38, 25.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.616279069767 and loss 1.17692966697 :\n",
      "\n",
      " 29%|██▉       | 293/1000 [2:24:42<4:54:38, 25.01s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 3.0, 'n_estimators': 180, 'subsample': 1.0, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 29%|██▉       | 293/1000 [2:24:42<4:54:38, 25.01s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 294/1000 [2:24:42<4:11:38, 21.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 294/1000 [2:24:42<4:11:37, 21.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.474384832594 and loss 1.76726697127 :\n",
      "\n",
      " 29%|██▉       | 294/1000 [2:24:52<4:11:37, 21.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.488372093023 and loss 1.75876186179 :\n",
      "\n",
      " 29%|██▉       | 294/1000 [2:24:52<4:11:37, 21.38s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.5, 'min_child_weight': 4.0, 'n_estimators': 316, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.8, 'booster': 'gblinear'}\n",
      "\n",
      " 29%|██▉       | 294/1000 [2:24:52<4:11:37, 21.38s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|██▉       | 295/1000 [2:24:53<3:33:35, 18.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|██▉       | 295/1000 [2:24:52<3:33:34, 18.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.703509479629 and loss 0.972445278786 :\n",
      "\n",
      " 30%|██▉       | 295/1000 [2:25:05<3:33:34, 18.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.613372093023 and loss 1.20089554691 :\n",
      "\n",
      " 30%|██▉       | 295/1000 [2:25:05<3:33:34, 18.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.025, 'min_child_weight': 6.0, 'n_estimators': 327, 'subsample': 0.8500000000000001, 'importance_type': 'gain', 'max_depth': 1, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 30%|██▉       | 295/1000 [2:25:05<3:33:34, 18.18s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|██▉       | 296/1000 [2:25:05<3:13:33, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|██▉       | 296/1000 [2:25:05<3:13:33, 16.50s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.987091569181 and loss 0.134180649067 :\n",
      "\n",
      " 30%|██▉       | 296/1000 [2:25:26<3:13:33, 16.50s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.645348837209 and loss 1.1956630011 :\n",
      "\n",
      " 30%|██▉       | 296/1000 [2:25:26<3:13:33, 16.50s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.2, 'min_child_weight': 5.0, 'n_estimators': 255, 'subsample': 1.0, 'importance_type': 'cover', 'max_depth': 4, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 30%|██▉       | 296/1000 [2:25:26<3:13:33, 16.50s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|██▉       | 297/1000 [2:25:26<3:28:53, 17.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|██▉       | 297/1000 [2:25:26<3:28:53, 17.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991528842275 and loss 0.11462506359 :\n",
      "\n",
      " 30%|██▉       | 297/1000 [2:25:56<3:28:53, 17.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.656976744186 and loss 1.18391653787 :\n",
      "\n",
      " 30%|██▉       | 297/1000 [2:25:56<3:28:53, 17.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.1, 'min_child_weight': 2.0, 'n_estimators': 252, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 5, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 30%|██▉       | 297/1000 [2:25:56<3:28:53, 17.83s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|██▉       | 298/1000 [2:25:57<4:13:39, 21.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|██▉       | 298/1000 [2:25:56<4:13:39, 21.68s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.693424768052 and loss 1.21540232038 :\n",
      "\n",
      " 30%|██▉       | 298/1000 [2:25:59<4:13:39, 21.68s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.578488372093 and loss 1.42427406573 :\n",
      "\n",
      " 30%|██▉       | 298/1000 [2:25:59<4:13:39, 21.68s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 27, 'subsample': 0.9500000000000001, 'importance_type': 'cover', 'max_depth': 2, 'gamma': 0.75, 'booster': 'dart'}\n",
      "\n",
      " 30%|██▉       | 298/1000 [2:25:59<4:13:39, 21.68s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|██▉       | 299/1000 [2:25:59<3:05:50, 15.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|██▉       | 299/1000 [2:25:59<3:05:48, 15.90s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995159338443 and loss 0.0962015219547 :\n",
      "\n",
      " 30%|██▉       | 299/1000 [2:27:02<3:05:48, 15.90s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.1957399149 :\n",
      "\n",
      " 30%|██▉       | 299/1000 [2:27:02<3:05:48, 15.90s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'min_child_weight': 1.0, 'n_estimators': 493, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 5, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 30%|██▉       | 299/1000 [2:27:02<3:05:48, 15.90s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|███       | 300/1000 [2:27:02<5:49:19, 29.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 300/1000 [2:27:02<5:49:21, 29.94s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.813634530052 and loss 0.976594333725 :\n",
      "\n",
      " 30%|███       | 300/1000 [2:27:12<5:49:21, 29.94s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.625 and loss 1.36728674269 :\n",
      "\n",
      " 30%|███       | 300/1000 [2:27:12<5:49:21, 29.94s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.025, 'min_child_weight': 2.0, 'n_estimators': 76, 'subsample': 0.8, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 30%|███       | 300/1000 [2:27:12<5:49:21, 29.94s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|███       | 301/1000 [2:27:12<4:40:17, 24.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 301/1000 [2:27:12<4:40:16, 24.06s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.475594997983 and loss 1.80915453162 :\n",
      "\n",
      " 30%|███       | 301/1000 [2:27:15<4:40:16, 24.06s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.80770662968 :\n",
      "\n",
      " 30%|███       | 301/1000 [2:27:15<4:40:16, 24.06s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'min_child_weight': 2.0, 'n_estimators': 77, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 8, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 30%|███       | 301/1000 [2:27:15<4:40:16, 24.06s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|███       | 302/1000 [2:27:16<3:27:25, 17.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 302/1000 [2:27:15<3:27:24, 17.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995562726906 and loss 0.0987115718818 :\n",
      "\n",
      " 30%|███       | 302/1000 [2:28:02<3:27:24, 17.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.17058650308 :\n",
      "\n",
      " 30%|███       | 302/1000 [2:28:02<3:27:24, 17.83s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.07500000000000001, 'min_child_weight': 1.0, 'n_estimators': 252, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 9, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 30%|███       | 302/1000 [2:28:02<3:27:24, 17.83s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|███       | 303/1000 [2:28:02<5:07:30, 26.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 303/1000 [2:28:02<5:07:30, 26.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.98951189996 and loss 0.12187221467 :\n",
      "\n",
      " 30%|███       | 303/1000 [2:28:59<5:07:30, 26.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.639534883721 and loss 1.19802934601 :\n",
      "\n",
      " 30%|███       | 303/1000 [2:28:59<5:07:30, 26.47s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.125, 'min_child_weight': 6.0, 'n_estimators': 351, 'subsample': 0.8500000000000001, 'importance_type': 'gain', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 30%|███       | 303/1000 [2:28:59<5:07:30, 26.47s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|███       | 304/1000 [2:28:59<6:53:44, 35.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 304/1000 [2:28:59<6:53:44, 35.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.936264622832 and loss 0.320368015298 :\n",
      "\n",
      " 30%|███       | 304/1000 [2:29:05<6:53:44, 35.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.630813953488 and loss 1.11535396552 :\n",
      "\n",
      " 30%|███       | 304/1000 [2:29:05<6:53:44, 35.67s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.17500000000000002, 'min_child_weight': 4.0, 'n_estimators': 43, 'subsample': 0.9, 'importance_type': 'total_gain', 'max_depth': 5, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 30%|███       | 304/1000 [2:29:05<6:53:44, 35.67s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  30%|███       | 305/1000 [2:29:05<5:10:08, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 305/1000 [2:29:05<5:10:07, 26.77s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.970956030658 and loss 0.208774091196 :\n",
      "\n",
      " 30%|███       | 305/1000 [2:30:28<5:10:07, 26.77s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.633720930233 and loss 1.15269619569 :\n",
      "\n",
      " 30%|███       | 305/1000 [2:30:28<5:10:07, 26.77s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.025, 'min_child_weight': 1.0, 'n_estimators': 429, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 30%|███       | 305/1000 [2:30:28<5:10:07, 26.77s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███       | 306/1000 [2:30:28<8:24:33, 43.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 306/1000 [2:30:28<8:24:34, 43.62s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.869302137959 and loss 0.507053285422 :\n",
      "\n",
      " 31%|███       | 306/1000 [2:30:41<8:24:34, 43.62s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.12885207952 :\n",
      "\n",
      " 31%|███       | 306/1000 [2:30:41<8:24:34, 43.62s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.05, 'min_child_weight': 2.0, 'n_estimators': 215, 'subsample': 0.8, 'importance_type': 'total_cover', 'max_depth': 2, 'gamma': 0.7000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 31%|███       | 306/1000 [2:30:41<8:24:34, 43.62s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███       | 307/1000 [2:30:42<6:39:14, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 307/1000 [2:30:41<6:39:13, 34.57s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.984671238403 and loss 0.148234412564 :\n",
      "\n",
      " 31%|███       | 307/1000 [2:31:14<6:39:13, 34.57s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.656976744186 and loss 1.17434826224 :\n",
      "\n",
      " 31%|███       | 307/1000 [2:31:14<6:39:13, 34.57s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 441, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 31%|███       | 307/1000 [2:31:14<6:39:13, 34.57s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███       | 308/1000 [2:31:14<6:30:43, 33.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 308/1000 [2:31:14<6:30:44, 33.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.961274707543 and loss 0.230113607948 :\n",
      "\n",
      " 31%|███       | 308/1000 [2:31:40<6:30:44, 33.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.14054026885 :\n",
      "\n",
      " 31%|███       | 308/1000 [2:31:40<6:30:44, 33.88s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 220, 'subsample': 0.8, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 31%|███       | 308/1000 [2:31:40<6:30:44, 33.88s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███       | 309/1000 [2:31:41<6:05:30, 31.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 309/1000 [2:31:40<6:05:30, 31.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.47519160952 and loss 1.78911513284 :\n",
      "\n",
      " 31%|███       | 309/1000 [2:31:46<6:05:30, 31.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.485465116279 and loss 1.78734896789 :\n",
      "\n",
      " 31%|███       | 309/1000 [2:31:46<6:05:30, 31.74s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.05, 'min_child_weight': 2.0, 'n_estimators': 137, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.7000000000000001, 'booster': 'gblinear'}\n",
      "\n",
      " 31%|███       | 309/1000 [2:31:46<6:05:30, 31.74s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███       | 310/1000 [2:31:46<4:33:21, 23.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 310/1000 [2:31:46<4:33:20, 23.77s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.991932230738 and loss 0.101443864436 :\n",
      "\n",
      " 31%|███       | 310/1000 [2:32:16<4:33:20, 23.77s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.616279069767 and loss 1.28944431834 :\n",
      "\n",
      " 31%|███       | 310/1000 [2:32:16<4:33:20, 23.77s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.225, 'min_child_weight': 5.0, 'n_estimators': 441, 'subsample': 0.75, 'importance_type': 'cover', 'max_depth': 3, 'gamma': 0.55, 'booster': 'gbtree'}\n",
      "\n",
      " 31%|███       | 310/1000 [2:32:16<4:33:20, 23.77s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███       | 311/1000 [2:32:17<4:56:41, 25.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 311/1000 [2:32:16<4:56:43, 25.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.969342476805 and loss 0.202490658963 :\n",
      "\n",
      " 31%|███       | 311/1000 [2:32:21<4:56:43, 25.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.622093023256 and loss 1.20916863501 :\n",
      "\n",
      " 31%|███       | 311/1000 [2:32:21<4:56:43, 25.84s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.35000000000000003, 'min_child_weight': 1.0, 'n_estimators': 48, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 31%|███       | 311/1000 [2:32:21<4:56:43, 25.84s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███       | 312/1000 [2:32:21<3:43:23, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 312/1000 [2:32:21<3:43:22, 19.48s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.955223880597 and loss 0.246719557258 :\n",
      "\n",
      " 31%|███       | 312/1000 [2:32:40<3:43:22, 19.48s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.636627906977 and loss 1.15289627309 :\n",
      "\n",
      " 31%|███       | 312/1000 [2:32:40<3:43:22, 19.48s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 204, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 31%|███       | 312/1000 [2:32:40<3:43:22, 19.48s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███▏      | 313/1000 [2:32:40<3:40:45, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███▏      | 313/1000 [2:32:40<3:40:45, 19.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.686970552642 and loss 2.05977506453 :\n",
      "\n",
      " 31%|███▏      | 313/1000 [2:32:42<3:40:45, 19.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.575581395349 and loss 2.14700446607 :\n",
      "\n",
      " 31%|███▏      | 313/1000 [2:32:42<3:40:45, 19.28s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.55, 'learning_rate': 0.025, 'min_child_weight': 2.0, 'n_estimators': 14, 'subsample': 0.8500000000000001, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.65, 'booster': 'gbtree'}\n",
      "\n",
      " 31%|███▏      | 313/1000 [2:32:42<3:40:45, 19.28s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███▏      | 314/1000 [2:32:42<2:41:42, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███▏      | 314/1000 [2:32:42<2:41:41, 14.14s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.901573215006 and loss 0.451539723303 :\n",
      "\n",
      " 31%|███▏      | 314/1000 [2:32:48<2:41:41, 14.14s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.616279069767 and loss 1.17883568415 :\n",
      "\n",
      " 31%|███▏      | 314/1000 [2:32:48<2:41:41, 14.14s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'min_child_weight': 1.0, 'n_estimators': 46, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 4, 'gamma': 0.7000000000000001, 'booster': 'dart'}\n",
      "\n",
      " 31%|███▏      | 314/1000 [2:32:48<2:41:41, 14.14s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  32%|███▏      | 315/1000 [2:32:48<2:12:33, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 315/1000 [2:32:48<2:12:33, 11.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.970956030658 and loss 0.20255240433 :\n",
      "\n",
      " 32%|███▏      | 315/1000 [2:32:58<2:12:33, 11.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.648255813953 and loss 1.14330736148 :\n",
      "\n",
      " 32%|███▏      | 315/1000 [2:32:58<2:12:33, 11.61s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.65, 'learning_rate': 0.15000000000000002, 'min_child_weight': 2.0, 'n_estimators': 141, 'subsample': 0.7000000000000001, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.75, 'booster': 'gbtree'}\n",
      "\n",
      " 32%|███▏      | 315/1000 [2:32:58<2:12:33, 11.61s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  32%|███▏      | 316/1000 [2:32:59<2:09:32, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 316/1000 [2:32:58<2:09:33, 11.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995562726906 and loss 0.0941570969146 :\n",
      "\n",
      " 32%|███▏      | 316/1000 [2:33:36<2:09:33, 11.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.627906976744 and loss 1.19821822171 :\n",
      "\n",
      " 32%|███▏      | 316/1000 [2:33:36<2:09:33, 11.36s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.75, 'learning_rate': 0.1, 'min_child_weight': 1.0, 'n_estimators': 308, 'subsample': 0.8, 'importance_type': 'total_cover', 'max_depth': 5, 'gamma': 0.6000000000000001, 'booster': 'gbtree'}\n",
      "\n",
      " 32%|███▏      | 316/1000 [2:33:36<2:09:33, 11.36s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  32%|███▏      | 317/1000 [2:33:36<3:38:22, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 317/1000 [2:33:36<3:38:23, 19.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.992739007664 and loss 0.105511827086 :\n",
      "\n",
      " 32%|███▏      | 317/1000 [2:33:57<3:38:23, 19.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this testing accuracy 0.616279069767 and loss 1.31813902099 :\n",
      "\n",
      " 32%|███▏      | 317/1000 [2:33:57<3:38:23, 19.18s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[A{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.375, 'min_child_weight': 2.0, 'n_estimators': 218, 'subsample': 0.9, 'importance_type': 'total_cover', 'max_depth': 3, 'gamma': 0.65, 'booster': 'dart'}\n",
      "\n",
      " 32%|███▏      | 317/1000 [2:33:57<3:38:23, 19.18s/it, best loss: -0.662790697674]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  32%|███▏      | 318/1000 [2:33:57<3:44:58, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 318/1000 [2:33:57<3:44:58, 19.79s/it, best loss: -0.662790697674]\u001b[A\n",
      "\u001b[AParameters with this training accuracy 0.995562726906 and loss 0.0828239081192 :\n",
      "\n",
      " 32%|███▏      | 318/1000 [2:34:47<3:44:58, 19.79s/it, best loss: -0.662790697674]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "trials = Trials()\n",
    "cores = 48\n",
    "start = time.time()\n",
    "evaluations = 1000\n",
    "pbar = tqdm(total=evaluations, desc=\"Hyperopt\")\n",
    "best_param = optimize(evals=evaluations,\n",
    "                      optimizer=tpe.suggest,\n",
    "                      trials=trials)\n",
    "print(\"------------------------------------\")\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_param)\n",
    "end = time.time()\n",
    "print('Time elapsed to optimize {0} executions: {1}'.format(evaluations, end - start))\n",
    "best_param['importance_type'] = importance_type_list[best_param['importance_type']]\n",
    "best_param['booster'] = booster_list[best_param['booster']]\n",
    "best_param['max_depth'] = max_depth_list[best_param['max_depth']]\n",
    "print('\\n Best score:')\n",
    "score(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to optimize 1000 executions: 36951.486124\n",
      "\n",
      " Best score:\n",
      "Parameters with this training accuracy 0.988705123033 and loss 0.125064155434 :\n",
      "Parameters with this testing accuracy 0.65988372093 and loss 1.16798332479 :\n",
      "{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'min_child_weight': 4.0, 'n_estimators': 263, 'subsample': 0.9, 'gamma': 0.65, 'max_depth': 4, 'importance_type': 'cover', 'booster': 'dart'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': -0.6598837209302325, 'status': 'ok'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = time.time()\n",
    "print('Time elapsed to optimize {0} executions: {1}'.format(evaluations, end - start))\n",
    "print('\\n Best score:')\n",
    "score(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best params and train the model\n",
    "xgb_opt = XGBClassifier(n_estimators = best_param['n_estimators'],\n",
    "                          learning_rate = best_param['learning_rate'],\n",
    "                            max_depth = best_param['max_depth'],\n",
    "                            min_child_weight = best_param['min_child_weight'],\n",
    "                            subsample = best_param['subsample'], \n",
    "                            gamma = best_param['gamma'],\n",
    "                            colsample_bytree = best_param['colsample_bytree'],\n",
    "                            importance_type = best_param['importance_type'],\n",
    "                            booster=best_param['booster'],\n",
    "                            objective = \"multi:softprob\",\n",
    "                            n_jobs=24,\n",
    "                            random_state=42,\n",
    "                            silent=True,)\n",
    "\n",
    "eval_set=[(X_train, y_train), (X_val, y_val)]\n",
    "\n",
    "fitted_model = xgb_opt.fit(X=X_train,y=y_train, eval_set=eval_set, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0332701e-02, 5.4047529e-02, 1.6118009e-02, ..., 7.3164374e-02,\n",
       "        2.1498175e-03, 2.9499431e-03],\n",
       "       [9.3397141e-01, 3.0173353e-04, 4.7247863e-04, ..., 3.2371530e-04,\n",
       "        9.3392329e-03, 4.6151257e-03],\n",
       "       [1.4282230e-03, 5.0156745e-03, 7.3491666e-03, ..., 3.2036579e-03,\n",
       "        4.7519775e-03, 1.1454795e-03],\n",
       "       ...,\n",
       "       [6.0856016e-04, 8.9634565e-04, 2.0177320e-03, ..., 6.1735231e-04,\n",
       "        1.1633107e-04, 2.8664328e-04],\n",
       "       [4.5767945e-01, 8.4569061e-04, 5.2112690e-04, ..., 5.4780295e-04,\n",
       "        4.4439502e-02, 6.6446973e-04],\n",
       "       [3.0148372e-01, 4.8518674e-03, 1.3824512e-03, ..., 1.9204329e-03,\n",
       "        3.8238868e-04, 4.3620295e-03]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = fitted_model.predict_proba(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6598837209302325"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = accuracy_score(y_test, fitted_model.predict(X_test))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline \n",
    "x_list =range(len(train_acc_list))\n",
    "\n",
    "plt.plot(x_list, train_acc_list, label='Training accuracy')\n",
    "plt.plot(x_list, test_acc_list, label='Testing accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_list, train_loss_list, label='Training loss')\n",
    "plt.plot(x_list, test_loss_list, label='Testing loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
