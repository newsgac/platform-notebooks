{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install imbalanced-learn --user\n",
    "# !{sys.executable} -m pip install hyperopt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/newsgac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from hyperopt import tpe, fmin, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "from newsgac import config\n",
    "from newsgac.genres import genre_codes\n",
    "from newsgac.learners import learners, LearnerSVC, LearnerNB, LearnerXGB, LearnerGB, LearnerMLP, LearnerRF, LearnerLGBM\n",
    "from newsgac.pipelines.get_sk_pipeline import get_sk_pipeline\n",
    "from newsgac.pipelines.utils import report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from newsgac import database\n",
    "from newsgac.data_sources import DataSource\n",
    "from newsgac.pipelines import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'N2BGS Training',\n",
       " u'N2BGS Testing',\n",
       " u'Linked NRC (2930)',\n",
       " u'BOW + 5 features (N2BGS train)',\n",
       " u'BOW + 5 features (N2BGS test)',\n",
       " u'nrc-1950-1994-a.txt',\n",
       " u'nrc-1950-1994-b.txt',\n",
       " u'nrc-1950-1994-c.txt',\n",
       " u'nrc-1950-1994-d.txt',\n",
       " u'nrc-1950-1994-e.txt',\n",
       " u'telegraaf-1950-1994-a.txt',\n",
       " u'telegraaf-1950-1994-b.txt',\n",
       " u'telegraaf-1950-1994-c.txt',\n",
       " u'telegraaf-1950-1994-d.txt',\n",
       " u'telegraaf-1950-1994-e.txt',\n",
       " u'volkskrant-1950-1995-a.txt',\n",
       " u'volkskrant-1950-1995-b.txt',\n",
       " u'volkskrant-1950-1995-c.txt',\n",
       " u'volkskrant-1950-1995-d.txt',\n",
       " u'volkskrant-1950-1995-e.txt',\n",
       " u'nrc-1965.txt',\n",
       " u'nrc-1985.txt',\n",
       " u'BOW + 9 features (N2BGS train)',\n",
       " u'BOW + 9 features (N2BGS test)',\n",
       " u'Linked NRC (2930/9 features)',\n",
       " u'BOW Train unique (9 features)',\n",
       " u'BOW Test unique (9 features)',\n",
       " u'Linked NRC (unique/9 features)',\n",
       " u'BOW Train unique (N3BGS/9 features)',\n",
       " u'N3BGS FROG Test',\n",
       " u'N3BGS FROG Train',\n",
       " u'BOW Test unique (N3BGS/9 features)',\n",
       " u'BOW Test unique (N3BGS/9 features/collapsed)',\n",
       " u'Linked NRC (2930 articles)',\n",
       " u'Combined N3BGS/Linked NRC (3884)']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.display_title for d in DataSource.objects.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSource: N3BGS FROG Train\n",
      "NLP Tool: Frog\n",
      "Classifier: Multi-Layer Perceptron\n",
      "Task status: Status.SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# n2bgs balanced frog experiments: 2:rf 3:svc 4:xgb 5:nb 6:mlp\n",
    "# n2bgs balanced bow experiments: 7:rf 8:svc 9:xgb 10:nb 11:mlp\n",
    "# n3bgs balanced frog: 32:rf 33:svc 34:xgb 43:nb 44:mlp \n",
    "# n3bgs balanced bow: 45:rf 46:svc 47:xgb 48 49 \n",
    "# unbalanced svc: 40\n",
    "# combined svc: 42\n",
    "p = Pipeline.objects.all()[44]\n",
    "print 'DataSource: ' + p.data_source.display_title\n",
    "print 'NLP Tool: ' + p.nlp_tool.name\n",
    "print 'Classifier: ' + p.learner.name\n",
    "print 'Task status: ' + str(p.task.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p.data_source.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.03733955659276546, 0.07424877707896575, 0.18518518518518517)\n"
     ]
    }
   ],
   "source": [
    "NBROFINTERESTINGGENRES = 8\n",
    "\n",
    "results = p.result.confusion_matrix.get()\n",
    "nbrOfArticles = len(p.data_source.articles)\n",
    "totalScore = 0\n",
    "maxDeviation = 0.0\n",
    "totalDeviation = 0.0\n",
    "for genre in range(0,NBROFINTERESTINGGENRES):\n",
    "    correct = results[genre][genre]\n",
    "    gold = sum(results[genre])\n",
    "    guessed = sum([x[genre] for x in results])\n",
    "    fp = abs(guessed-correct)\n",
    "    fn = abs(gold-correct)\n",
    "    score = abs(fp-fn)\n",
    "    totalScore += score\n",
    "    deviation = float(abs(guessed-gold))/float(gold)\n",
    "    maxDeviation = max(maxDeviation,deviation)\n",
    "    totalDeviation += deviation\n",
    "print(float(totalScore)/float(nbrOfArticles),totalDeviation/NBROFINTERESTINGGENRES,maxDeviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CleanOCR', <newsgac.nlp_tools.transformers.CleanOCR at 0x7fb69b2afcd0>),\n",
       " ('FeatureExtraction', FeatureUnion(n_jobs=None,\n",
       "         transformer_list=[('Basic', <newsgac.nlp_tools.transformers.ExtractBasicFeatures object at 0x7fb69b2af890>), ('Quote', <newsgac.nlp_tools.transformers.ExtractQuotes object at 0x7fb69b2aff10>), ('Sentiment', Pipeline(memory=None,\n",
       "       steps=[('RemoveQuotes', <newsgac.nlp_tools.transformers.RemoveQuot...10990>), ('Frog', <newsgac.nlp_tools.models.frog.FrogFeatureExtractor object at 0x7fb696810f90>)]))],\n",
       "         transformer_weights=None)),\n",
       " ('RobustScaler',\n",
       "  RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=False,\n",
       "         with_scaling=True))]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skp = p.get_sk_pipeline()\n",
    "skp_opt = deepcopy(skp)\n",
    "skp_opt.steps.pop()\n",
    "skp_opt.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CleanOCR', <newsgac.nlp_tools.transformers.CleanOCR at 0x7fb69b2afcd0>),\n",
       " ('FeatureExtraction', FeatureUnion(n_jobs=None,\n",
       "         transformer_list=[('Basic', <newsgac.nlp_tools.transformers.ExtractBasicFeatures object at 0x7fb69b2af890>), ('Quote', <newsgac.nlp_tools.transformers.ExtractQuotes object at 0x7fb69b2aff10>), ('Sentiment', Pipeline(memory=None,\n",
       "       steps=[('RemoveQuotes', <newsgac.nlp_tools.transformers.RemoveQuot...10990>), ('Frog', <newsgac.nlp_tools.models.frog.FrogFeatureExtractor object at 0x7fb696810f90>)]))],\n",
       "         transformer_weights=None))]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skp_opt.steps.pop()\n",
    "skp_opt.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.array([article.raw_text for article in p.data_source.articles])\n",
    "labels = np.array([article.label for article in p.data_source.articles])\n",
    "\n",
    "X = skp_opt.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test dataset for optimization accuracy\n",
    "texts_test = np.array([article.raw_text for article in DataSource.objects.all()[1].articles])\n",
    "labels_test = np.array([article.label for article in DataSource.objects.all()[1].articles])\n",
    "\n",
    "X_test = skp_opt.transform(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = labels\n",
    "y_test = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste these values in corresponding variables\n",
    "# {'solver': 'lbfgs', 'activation': 'relu', 'max_iter': 312, 'batch_size': 26, 'alpha': 0.3951743267863599, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (300, 100)}\n",
    "mlp_opt = MLPClassifier(\n",
    "            hidden_layer_sizes = (300, 100),\n",
    "            activation = 'relu',\n",
    "            solver = 'lbfgs',\n",
    "            alpha = 0.3951743267863599,\n",
    "            learning_rate = 'adaptive',\n",
    "            batch_size = 26,\n",
    "            max_iter = 312,\n",
    "            shuffle = True,\n",
    "            random_state = 42,\n",
    "            warm_start = False,\n",
    "            early_stopping = True,\n",
    "            validation_fraction = 0.1,\n",
    "    )\n",
    "\n",
    "fitted_model = mlp_opt.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.57775551e-02, 4.58807271e-02, 3.76642038e-02, ...,\n",
       "        1.20391703e-02, 6.88251059e-03, 1.10685582e-01],\n",
       "       [1.67570580e-01, 2.45996899e-02, 7.73804966e-03, ...,\n",
       "        1.11621285e-03, 6.84309013e-02, 1.57817689e-02],\n",
       "       [8.59694800e-03, 2.52998104e-02, 4.59234410e-02, ...,\n",
       "        4.90843109e-02, 9.45176125e-05, 2.44475717e-01],\n",
       "       ...,\n",
       "       [1.16618429e-01, 3.94325453e-02, 2.52911836e-02, ...,\n",
       "        5.33519373e-03, 2.29729863e-02, 6.14336690e-02],\n",
       "       [7.40719464e-06, 2.41628047e-01, 1.69362424e-01, ...,\n",
       "        9.41950222e-02, 2.84384265e-03, 9.97169922e-02],\n",
       "       [2.96781634e-01, 2.63387419e-02, 5.20116969e-04, ...,\n",
       "        2.17563074e-04, 1.33761866e-01, 2.58157427e-02]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = fitted_model.predict_proba(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26373626373626374"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = accuracy_score(y_test, fitted_model.predict(X_test))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
