{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install imbalanced-learn --user\n",
    "# !{sys.executable} -m pip install hyperopt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/newsgac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from hyperopt import tpe, fmin, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "from newsgac import config\n",
    "from newsgac.genres import genre_codes\n",
    "from newsgac.learners import learners, LearnerSVC, LearnerNB, LearnerXGB, LearnerGB, LearnerMLP, LearnerRF, LearnerLGBM\n",
    "from newsgac.pipelines.get_sk_pipeline import get_sk_pipeline\n",
    "from newsgac.pipelines.utils import report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from newsgac import database\n",
    "from newsgac.data_sources import DataSource\n",
    "from newsgac.pipelines import Pipeline\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "# from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'N2BGS Training',\n",
       " u'N2BGS Testing',\n",
       " u'Linked NRC (2930)',\n",
       " u'BOW + 5 features (N2BGS train)',\n",
       " u'BOW + 5 features (N2BGS test)',\n",
       " u'nrc-1950-1994-a.txt',\n",
       " u'nrc-1950-1994-b.txt',\n",
       " u'nrc-1950-1994-c.txt',\n",
       " u'nrc-1950-1994-d.txt',\n",
       " u'nrc-1950-1994-e.txt',\n",
       " u'telegraaf-1950-1994-a.txt',\n",
       " u'telegraaf-1950-1994-b.txt',\n",
       " u'telegraaf-1950-1994-c.txt',\n",
       " u'telegraaf-1950-1994-d.txt',\n",
       " u'telegraaf-1950-1994-e.txt',\n",
       " u'volkskrant-1950-1995-a.txt',\n",
       " u'volkskrant-1950-1995-b.txt',\n",
       " u'volkskrant-1950-1995-c.txt',\n",
       " u'volkskrant-1950-1995-d.txt',\n",
       " u'volkskrant-1950-1995-e.txt',\n",
       " u'nrc-1965.txt',\n",
       " u'nrc-1985.txt',\n",
       " u'BOW + 9 features (N2BGS train)',\n",
       " u'BOW + 9 features (N2BGS test)',\n",
       " u'Linked NRC (2930/9 features)',\n",
       " u'BOW Train unique (9 features)',\n",
       " u'BOW Test unique (9 features)',\n",
       " u'Linked NRC (unique/9 features)',\n",
       " u'BOW Train unique (N3BGS/9 features)',\n",
       " u'N3BGS FROG Test',\n",
       " u'N3BGS FROG Train',\n",
       " u'BOW Test unique (N3BGS/9 features)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.display_title for d in DataSource.objects.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'dummy frog',\n",
       " u'dummy bow',\n",
       " u'RF FROG',\n",
       " u'SVC FROG',\n",
       " u'XGB FROG',\n",
       " u'NB FROG',\n",
       " u'MLP FROG',\n",
       " u'RF BOW',\n",
       " u'SVC BOW',\n",
       " u'XGB BOW',\n",
       " u'NB BOW',\n",
       " u'MLP BOW',\n",
       " u'SVC LIN BOW',\n",
       " u'Erik MLP BOW (with stop-words)',\n",
       " u'Erik MLP BOW (5 features) ',\n",
       " u'Erik MLP BOW (9 features) ',\n",
       " u'Erik SVC BOW (9 features)',\n",
       " u'Erik RF BOW (9 features)',\n",
       " u'Erik XGB BOW (9 features)',\n",
       " u'Erik NB BOW (9 features)',\n",
       " u'Erik MLP unique 9 features',\n",
       " u'Erik NB unique (9 features)',\n",
       " u'Erik XGB unique (9 features)',\n",
       " u'Erik SVC unique (9 features)',\n",
       " u'Erik RF unique (9 features)',\n",
       " u'N3BGS MLP unique 9 features',\n",
       " u'N3BGS NB unique 9 features ',\n",
       " u'N3BGS SVC unique 9 features ',\n",
       " u'N3BGS RF unique 9 features',\n",
       " u'N3BGS XGB unique 9 features ',\n",
       " u'dummy n3bgs bow',\n",
       " u'dummy n3bgs frog']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.display_title for d in Pipeline.objects.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: dummy n3bgs frog\n",
      "DataSource: N3BGS FROG Train\n",
      "NLP Tool: Frog\n",
      "Classifier: Support Vector\n",
      "Task status: Status.SUCCESS\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline.objects.all()[31]\n",
    "print 'Pipeline: ' + p.display_title\n",
    "print 'DataSource: ' + p.data_source.display_title\n",
    "print 'NLP Tool: ' + p.nlp_tool.name\n",
    "print 'Classifier: ' + p.learner.name\n",
    "print 'Task status: ' + str(p.task.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p.data_source.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data source: N3BGS FROG Test\n"
     ]
    }
   ],
   "source": [
    "test_data_source = DataSource.objects.all()[29]\n",
    "print 'Testing data source: ' + test_data_source.display_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CleanOCR', <newsgac.nlp_tools.transformers.CleanOCR at 0x7fb1b21a5990>),\n",
       " ('FeatureExtraction', FeatureUnion(n_jobs=None,\n",
       "         transformer_list=[('Basic', <newsgac.nlp_tools.transformers.ExtractBasicFeatures object at 0x7fb1b21a5590>), ('Quote', <newsgac.nlp_tools.transformers.ExtractQuotes object at 0x7fb1b21a55d0>), ('Sentiment', Pipeline(memory=None,\n",
       "       steps=[('RemoveQuotes', <newsgac.nlp_tools.transformers.RemoveQuot...a5a10>), ('Frog', <newsgac.nlp_tools.models.frog.FrogFeatureExtractor object at 0x7fb1d3b4de10>)]))],\n",
       "         transformer_weights=None)),\n",
       " ('RobustScaler',\n",
       "  RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=False,\n",
       "         with_scaling=True))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skp = p.get_sk_pipeline()\n",
    "skp_opt = deepcopy(skp)\n",
    "skp_opt.steps.pop()\n",
    "skp_opt.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RobustScaler',\n",
       " RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=False,\n",
       "        with_scaling=True))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For NB change scaler to minMax\n",
    "skp_opt.steps.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CleanOCR', <newsgac.nlp_tools.transformers.CleanOCR at 0x7fb1b21a5990>),\n",
       " ('FeatureExtraction', FeatureUnion(n_jobs=None,\n",
       "         transformer_list=[('Basic', <newsgac.nlp_tools.transformers.ExtractBasicFeatures object at 0x7fb1b21a5590>), ('Quote', <newsgac.nlp_tools.transformers.ExtractQuotes object at 0x7fb1b21a55d0>), ('Sentiment', Pipeline(memory=None,\n",
       "       steps=[('RemoveQuotes', <newsgac.nlp_tools.transformers.RemoveQuot...a5a10>), ('Frog', <newsgac.nlp_tools.models.frog.FrogFeatureExtractor object at 0x7fb1d3b4de10>)]))],\n",
       "         transformer_weights=None)),\n",
       " ('MinMaxScaler', MinMaxScaler(copy=True, feature_range=(0, 1)))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skp_opt.steps.append(('MinMaxScaler', MinMaxScaler(feature_range=(0, 1))))\n",
    "skp_opt.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = numpy.array([article.raw_text for article in p.data_source.articles])\n",
    "labels = numpy.array([article.label for article in p.data_source.articles])\n",
    "\n",
    "X = skp_opt.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test dataset for optimization accuracy\n",
    "texts_test = numpy.array([article.raw_text for article in test_data_source.articles])\n",
    "labels_test = numpy.array([article.label for article in test_data_source.articles])\n",
    "\n",
    "X_test = skp_opt.transform(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = labels\n",
    "y_test = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(evals, trials, optimizer=tpe.suggest):\n",
    "    space = {\n",
    "        'alpha': hp.uniform('alpha', 0.0, 5.0),\n",
    "    }\n",
    "    best = fmin(score, space, algo=optimizer, max_evals=evals, trials=trials)\n",
    "    pbar.close()\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "def score(params):\n",
    "    \n",
    "    model = MultinomialNB(alpha=params['alpha'])\n",
    "\n",
    "    model.fit(X_train, y_train)   \n",
    "\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    train_loss = log_loss(y_train, model.predict_proba(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    test_loss = log_loss(y_test, model.predict_proba(X_test))\n",
    "    \n",
    "    train_acc_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "    print('Parameters with this training accuracy {} and loss {} :'.format(train_acc, train_loss))\n",
    "    print('Parameters with this testing accuracy {} and loss {} :'.format(test_acc, test_loss))\n",
    "    print(params)\n",
    "    pbar.update()\n",
    "#     return {'loss': test_loss, 'status': STATUS_OK}\n",
    "    return {'loss': -test_acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   3%|▎         | 27/1000 [00:00<00:07, 138.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.351225204201 and loss 2.60200443022 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63585188496 :\n",
      "{'alpha': 4.234841084429139}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.58472843474 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62184069909 :\n",
      "{'alpha': 3.298055416489141}\n",
      "Parameters with this training accuracy 0.354725787631 and loss 2.60049297306 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63462837112 :\n",
      "{'alpha': 4.143952857567568}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48291842718 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53815986223 :\n",
      "{'alpha': 0.45526637170250683}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56587730846 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60648324174 :\n",
      "{'alpha': 2.487536794363725}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.5612787551 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60272589003 :\n",
      "{'alpha': 2.316751670288737}\n",
      "Parameters with this training accuracy 0.354725787631 and loss 2.5899695896 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.62609760851 :\n",
      "{'alpha': 3.5600069423084886}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46255860802 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52126002281 :\n",
      "{'alpha': 0.19130424253137823}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51548968025 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56509995363 :\n",
      "{'alpha': 1.0352475124664506}\n",
      "Parameters with this training accuracy 0.341890315053 and loss 2.6120558588 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6439778699 :\n",
      "{'alpha': 4.890405451582296}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57586445 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61462856931 :\n",
      "{'alpha': 2.8931576645490074}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52123860174 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56984255026 :\n",
      "{'alpha': 1.1617986567613996}\n",
      "Parameters with this training accuracy 0.366394399067 and loss 2.55187235159 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59502700626 :\n",
      "{'alpha': 1.9953259534374883}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47881296012 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53475675466 :\n",
      "{'alpha': 0.3965294460704294}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.5542005373 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59693418305 :\n",
      "{'alpha': 2.0715797704901044}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54498751718 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58938111612 :\n",
      "{'alpha': 1.781619415308315}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53677068942 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58263158662 :\n",
      "{'alpha': 1.5479070478735806}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57561822416 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61442799874 :\n",
      "{'alpha': 2.8825434106555976}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54248438432 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58732624745 :\n",
      "{'alpha': 1.7080641603333562}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50883101483 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55960159768 :\n",
      "{'alpha': 0.898573246055745}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51383976811 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5637380533 :\n",
      "{'alpha': 1.0004185086291506}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51973695465 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56860419048 :\n",
      "{'alpha': 1.1279464839440332}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52675053588 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5743853053 :\n",
      "{'alpha': 1.291099403331132}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44522304669 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50675420602 :\n",
      "{'alpha': 0.018310646583541867}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5023774916 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55426777499 :\n",
      "{'alpha': 0.7755755848981585}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53508089335 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58124208455 :\n",
      "{'alpha': 1.5025177449102483}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52705060431 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.574632483 :\n",
      "{'alpha': 1.2983726870871308}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   5%|▌         | 51/1000 [00:00<00:07, 124.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.379229871645 and loss 2.49071311645 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54461647485 :\n",
      "{'alpha': 0.5749735964474878}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49854560826 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55109866464 :\n",
      "{'alpha': 0.7066972879321246}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46099604769 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51995956667 :\n",
      "{'alpha': 0.17378411423470286}\n",
      "Parameters with this training accuracy 0.381563593932 and loss 2.48081863832 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53641952456 :\n",
      "{'alpha': 0.424862624506775}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49494559775 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54812000706 :\n",
      "{'alpha': 0.644677699920006}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.59638325322 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63129939324 :\n",
      "{'alpha': 3.9060665838902304}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57523558853 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61411628676 :\n",
      "{'alpha': 2.866113408378359}\n",
      "Parameters with this training accuracy 0.343057176196 and loss 2.61090711734 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64305008241 :\n",
      "{'alpha': 4.810686942574112}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56635401143 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60687249678 :\n",
      "{'alpha': 2.5057903918915647}\n",
      "Parameters with this training accuracy 0.390898483081 and loss 2.44803274495 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50912352811 :\n",
      "{'alpha': 0.043080432356528475}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53182168341 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57856072755 :\n",
      "{'alpha': 1.4174077356649495}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55363413315 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59647029939 :\n",
      "{'alpha': 2.052835753563469}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.58275948218 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62024006186 :\n",
      "{'alpha': 3.204136858529842}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.56338464147 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60444708404 :\n",
      "{'alpha': 2.3937871902478056}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52321841973 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57147475865 :\n",
      "{'alpha': 1.2073170935526214}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46902649455 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52663620414 :\n",
      "{'alpha': 0.2678850634609755}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54699987352 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59103226393 :\n",
      "{'alpha': 1.8423199024620542}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.56073789756 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60228368918 :\n",
      "{'alpha': 2.2972789836055094}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48868516012 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54293719804 :\n",
      "{'alpha': 0.5427684204884241}\n",
      "Parameters with this training accuracy 0.34772462077 and loss 2.60714714763 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64001172062 :\n",
      "{'alpha': 4.5586894935423}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.4920627351 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54573383352 :\n",
      "{'alpha': 0.5968309333765166}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59609864685 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63106873479 :\n",
      "{'alpha': 3.8900757683636753}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.56823506597 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60840803138 :\n",
      "{'alpha': 2.57886053784054}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.58670556737 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62344719356 :\n",
      "{'alpha': 3.394787024035597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   7%|▋         | 74/1000 [00:00<00:07, 118.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.51200012097 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.562219139 :\n",
      "{'alpha': 0.9623412655941994}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53942744188 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58481522009 :\n",
      "{'alpha': 1.6210698324878385}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.55772894888 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59982252671 :\n",
      "{'alpha': 2.1912156000543854}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.57109663866 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61074258758 :\n",
      "{'alpha': 2.693292121257853}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50168551968 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55369559831 :\n",
      "{'alpha': 0.7629139368043439}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54884860878 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5925484946 :\n",
      "{'alpha': 1.8993511551752622}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52516438541 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5730785082 :\n",
      "{'alpha': 1.2530611218793957}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47477518174 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53140790752 :\n",
      "{'alpha': 0.3415464163637855}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.58027737741 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61822113535 :\n",
      "{'alpha': 3.089054868573327}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53127384469 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57810984984 :\n",
      "{'alpha': 1.4034093363377704}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51744156306 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56671066146 :\n",
      "{'alpha': 1.0772970303507323}\n",
      "Parameters with this training accuracy 0.392065344224 and loss 2.4507853982 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.5114347457 :\n",
      "{'alpha': 0.06862090295473267}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50407381437 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55567021729 :\n",
      "{'alpha': 0.8070391930737181}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53974239665 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58507400592 :\n",
      "{'alpha': 1.629892034710008}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51814681556 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56729251804 :\n",
      "{'alpha': 1.092719527901147}\n",
      "Parameters with this training accuracy 0.362893815636 and loss 2.55657837884 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59888094431 :\n",
      "{'alpha': 2.151652884664597}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49836977808 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55095321142 :\n",
      "{'alpha': 0.7036083968406709}\n",
      "Parameters with this training accuracy 0.381563593932 and loss 2.48059105175 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53623086991 :\n",
      "{'alpha': 0.4216130417791868}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5102221959 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56075079706 :\n",
      "{'alpha': 0.9262853941705136}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52313835286 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57140876049 :\n",
      "{'alpha': 1.205456429358208}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52410368797 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57220441281 :\n",
      "{'alpha': 1.2280023979433898}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53228695011 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57894360953 :\n",
      "{'alpha': 1.4293649843942742}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.5439575187 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58853570907 :\n",
      "{'alpha': 1.7510945051652254}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:   8%|▊         | 85/1000 [00:00<00:08, 108.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.369894982497 and loss 2.54986400449 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59338099194 :\n",
      "{'alpha': 1.9312021976555522}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48491204876 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53981179877 :\n",
      "{'alpha': 0.48484561405742055}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.46029292459 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51937412574 :\n",
      "{'alpha': 0.16602391507241387}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50666098412 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55780858048 :\n",
      "{'alpha': 0.8562073891827096}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49748537392 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55022155387 :\n",
      "{'alpha': 0.6881654857165697}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.45967457156 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51885912237 :\n",
      "{'alpha': 0.15926257179443604}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.56177348985 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60313032968 :\n",
      "{'alpha': 2.33467473719025}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52932384996 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57650459317 :\n",
      "{'alpha': 1.3542846089214087}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52846660529 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57579871104 :\n",
      "{'alpha': 1.3330306119822701}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53904778661 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58450324935 :\n",
      "{'alpha': 1.6104776521900233}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48766808744 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54209485322 :\n",
      "{'alpha': 0.5269014213856874}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57235079371 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61176523422 :\n",
      "{'alpha': 2.744727454244765}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53570164226 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58175257604 :\n",
      "{'alpha': 1.5190897447647953}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54491791391 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58932399293 :\n",
      "{'alpha': 1.7795451669421425}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.4737860408 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53058722089 :\n",
      "{'alpha': 0.32848946827294556}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59172685999 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.62752364498 :\n",
      "{'alpha': 3.651920855607069}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49456459231 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54780468985 :\n",
      "{'alpha': 0.6382626015425847}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51429612782 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56411478431 :\n",
      "{'alpha': 1.0099873064479716}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.44379165654 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50554165633 :\n",
      "{'alpha': 0.006227141316821894}\n",
      "Parameters with this training accuracy 0.351225204201 and loss 2.60322252346 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63683761282 :\n",
      "{'alpha': 4.309473662810992}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47258924567 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52959406212 :\n",
      "{'alpha': 0.3129054661662387}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49215580384 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54581087954 :\n",
      "{'alpha': 0.5983508365063634}\n",
      "Parameters with this training accuracy 0.364060676779 and loss 2.55714132328 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59934166921 :\n",
      "{'alpha': 2.1709423612876724}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  11%|█         | 110/1000 [00:00<00:08, 108.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.366394399067 and loss 2.55143537988 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59466893592 :\n",
      "{'alpha': 1.981245255725819}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50046582333 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55268693868 :\n",
      "{'alpha': 0.7408373277730815}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56623321041 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60677386027 :\n",
      "{'alpha': 2.5011547565433467}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52418325047 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57226998408 :\n",
      "{'alpha': 1.229871628872117}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.57947716209 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61756997678 :\n",
      "{'alpha': 3.0527190929253787}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45352932183 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5137316785 :\n",
      "{'alpha': 0.09528551688990372}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46748930294 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52535931134 :\n",
      "{'alpha': 0.24908747555835975}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50738726488 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5584087387 :\n",
      "{'alpha': 0.8702710537831615}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52055976905 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56928277757 :\n",
      "{'alpha': 1.1464243750536227}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5190465347 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56803471952 :\n",
      "{'alpha': 1.1125736561934298}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48409746536 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53913687307 :\n",
      "{'alpha': 0.47267507596922886}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54142048482 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58645252971 :\n",
      "{'alpha': 1.6774396097110205}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51224382065 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5624203747 :\n",
      "{'alpha': 0.9673400776681339}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49317638869 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5466557076 :\n",
      "{'alpha': 0.6151257543207305}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.5689610949 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60900050652 :\n",
      "{'alpha': 2.607514951030221}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52813823116 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5755282873 :\n",
      "{'alpha': 1.324943716283704}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55511753457 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59768506883 :\n",
      "{'alpha': 2.102192885880375}\n",
      "Parameters with this training accuracy 0.373395565928 and loss 2.5343618837 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58065070482 :\n",
      "{'alpha': 1.483468809921809}\n",
      "Parameters with this training accuracy 0.360560093349 and loss 2.56082196567 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60235242646 :\n",
      "{'alpha': 2.3002974392826667}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54798039147 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59183651058 :\n",
      "{'alpha': 1.872414653309125}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.58584505303 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62274809071 :\n",
      "{'alpha': 3.3523827577678054}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50126356633 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55334667009 :\n",
      "{'alpha': 0.755241840052173}\n",
      "Parameters with this training accuracy 0.383897316219 and loss 2.4779384299 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53403160266 :\n",
      "{'alpha': 0.3843892830202632}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  14%|█▎        | 136/1000 [00:01<00:07, 116.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.357059509918 and loss 2.58877370085 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6251267846 :\n",
      "{'alpha': 3.4986558193967436}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53850782234 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58405950608 :\n",
      "{'alpha': 1.5954922542250154}\n",
      "Parameters with this training accuracy 0.341890315053 and loss 2.61322171011 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64491924713 :\n",
      "{'alpha': 4.972667894183772}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.46537060325 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5235985818 :\n",
      "{'alpha': 0.22379125596922322}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52842995566 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57576853004 :\n",
      "{'alpha': 1.3321265443181405}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57627111574 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61495980362 :\n",
      "{'alpha': 2.9107597679177877}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.44373276683 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50549167075 :\n",
      "{'alpha': 0.005738171202434916}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50649150689 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55766852546 :\n",
      "{'alpha': 0.8529422432390185}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54512665108 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5894953002 :\n",
      "{'alpha': 1.7857707669267242}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51637343362 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56582929463 :\n",
      "{'alpha': 1.0541715768986928}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52208889346 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57054361885 :\n",
      "{'alpha': 1.1812232160236638}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55363547169 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59647139572 :\n",
      "{'alpha': 2.052879902616641}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53404298655 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58038838692 :\n",
      "{'alpha': 1.4750700954178542}\n",
      "Parameters with this training accuracy 0.346557759627 and loss 2.60943786191 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64186309892 :\n",
      "{'alpha': 4.710613864102581}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.452611973 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51296441218 :\n",
      "{'alpha': 0.08623898780899647}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49813536236 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55075928937 :\n",
      "{'alpha': 0.6994999497333921}\n",
      "Parameters with this training accuracy 0.351225204201 and loss 2.60259670093 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63633120755 :\n",
      "{'alpha': 4.270973143061294}\n",
      "Parameters with this training accuracy 0.368728121354 and loss 2.55070533379 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59407062809 :\n",
      "{'alpha': 1.9578811340876374}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.56265584013 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60385151774 :\n",
      "{'alpha': 2.366905785331096}\n",
      "Parameters with this training accuracy 0.354725787631 and loss 2.59806808286 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63266453873 :\n",
      "{'alpha': 4.001993993149048}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.55870766902 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6006232669 :\n",
      "{'alpha': 2.2252978994324915}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47995633996 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53570470554 :\n",
      "{'alpha': 0.41259725209942255}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51391363735 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5637990351 :\n",
      "{'alpha': 1.0019640336939586}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57290763079 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61221917924 :\n",
      "{'alpha': 2.7678210348681134}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  16%|█▌        | 161/1000 [00:01<00:07, 117.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.372228704784 and loss 2.54213027947 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58703546459 :\n",
      "{'alpha': 1.6978294292838836}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48915729404 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54332818904 :\n",
      "{'alpha': 0.5501983656020696}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48610229466 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54079786607 :\n",
      "{'alpha': 0.5028409139547075}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50819566291 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55907668461 :\n",
      "{'alpha': 0.8860613345629791}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52766927294 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5751420605 :\n",
      "{'alpha': 1.313446742797923}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53046094389 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57744073437 :\n",
      "{'alpha': 1.3827981417921877}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53093472026 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57783072232 :\n",
      "{'alpha': 1.3947876295720465}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53628373189 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58223121594 :\n",
      "{'alpha': 1.5347368757272304}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50342620177 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55513483632 :\n",
      "{'alpha': 0.7949556193495055}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.5460425898 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59024690163 :\n",
      "{'alpha': 1.8132675874776465}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51813078207 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56727929062 :\n",
      "{'alpha': 1.092367541680959}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47365496609 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53047845864 :\n",
      "{'alpha': 0.32677128366585445}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.45893340238 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51824164083 :\n",
      "{'alpha': 0.15123626628158793}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49785409209 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55052659949 :\n",
      "{'alpha': 0.6945848269948219}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.4685355831 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52622846984 :\n",
      "{'alpha': 0.2618411407523099}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.4934324099 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54686762368 :\n",
      "{'alpha': 0.6193649882413136}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44502924472 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50659028613 :\n",
      "{'alpha': 0.01665272343942048}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56434788796 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60523407045 :\n",
      "{'alpha': 2.4296804028311163}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51047349168 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56095835845 :\n",
      "{'alpha': 0.9313377850197357}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52459296664 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5726076362 :\n",
      "{'alpha': 1.2395241303974105}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48712380854 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54164403892 :\n",
      "{'alpha': 0.5184876323069464}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53651511981 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58242146535 :\n",
      "{'alpha': 1.5409858032946866}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48128226304 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5368038229 :\n",
      "{'alpha': 0.431510023344225}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  19%|█▊        | 186/1000 [00:01<00:07, 113.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.388564760793 and loss 2.45913346223 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51840833535 :\n",
      "{'alpha': 0.15339439059062243}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52304164795 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57132904657 :\n",
      "{'alpha': 1.2032113603535428}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50458824799 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55609546758 :\n",
      "{'alpha': 0.8167013065355286}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49175847586 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54548194994 :\n",
      "{'alpha': 0.5918734976913945}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49912202278 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55157547473 :\n",
      "{'alpha': 0.7168670546782535}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51411665204 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56396662777 :\n",
      "{'alpha': 1.0062182385599439}\n",
      "Parameters with this training accuracy 0.354725787631 and loss 2.56934392953 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60931287478 :\n",
      "{'alpha': 2.6227272069476464}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.4750127066 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53160496155 :\n",
      "{'alpha': 0.34470577302725086}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51944084416 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5683599611 :\n",
      "{'alpha': 1.1213386387741258}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51897400905 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56797489528 :\n",
      "{'alpha': 1.1109657490626963}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54234738698 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58721375102 :\n",
      "{'alpha': 1.7040995498705125}\n",
      "Parameters with this training accuracy 0.364060676779 and loss 2.55548647053 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59798712659 :\n",
      "{'alpha': 2.1146033759545277}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.58292809505 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62037716468 :\n",
      "{'alpha': 3.2120872997697756}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59305184998 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.62859847811 :\n",
      "{'alpha': 3.7226455474366684}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.45982918129 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51898790421 :\n",
      "{'alpha': 0.16094759351724086}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51212014751 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56231825215 :\n",
      "{'alpha': 0.9648015532587644}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53280862623 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57937287076 :\n",
      "{'alpha': 1.4428474974455328}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54978135842 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59331323982 :\n",
      "{'alpha': 1.9285955926873415}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50584348348 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55713297346 :\n",
      "{'alpha': 0.8405150562141527}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48022662395 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53592877124 :\n",
      "{'alpha': 0.4164280826694281}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.5784612869 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61674314006 :\n",
      "{'alpha': 3.007116588052456}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.49629497462 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54923663054 :\n",
      "{'alpha': 0.6676248330688535}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52955445192 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57669445849 :\n",
      "{'alpha': 1.360037403449502}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  21%|██        | 211/1000 [00:01<00:07, 110.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.361726954492 and loss 2.55844842548 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60041118527 :\n",
      "{'alpha': 2.2162314648920622}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46803557014 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52581312931 :\n",
      "{'alpha': 0.25572455443153413}\n",
      "Parameters with this training accuracy 0.390898483081 and loss 2.44697314748 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50823143256 :\n",
      "{'alpha': 0.03358094076616425}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52585920063 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57365099865 :\n",
      "{'alpha': 1.2696397806950537}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53944052603 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58482597116 :\n",
      "{'alpha': 1.6214356973858295}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55251166388 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59555081545 :\n",
      "{'alpha': 2.016057381411173}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53732177741 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58308463587 :\n",
      "{'alpha': 1.5629005135066731}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5006945869 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55287613214 :\n",
      "{'alpha': 0.7449546408591331}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51614693393 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56564237934 :\n",
      "{'alpha': 1.0493034764822398}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.48993729349 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54397408915 :\n",
      "{'alpha': 0.5625631501508468}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50984248685 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56043715682 :\n",
      "{'alpha': 0.9186783653331919}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56599119491 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60657624071 :\n",
      "{'alpha': 2.4918880587810377}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.4932574111 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54672277282 :\n",
      "{'alpha': 0.6164659795729065}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.4952343299 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54835895048 :\n",
      "{'alpha': 0.6495579265986533}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48409546864 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5391352186 :\n",
      "{'alpha': 0.47264538740046513}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46594452243 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5240756311 :\n",
      "{'alpha': 0.2305737824679311}\n",
      "Parameters with this training accuracy 0.346557759627 and loss 2.60603723587 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63911434323 :\n",
      "{'alpha': 4.486820952876672}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54590073001 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59013050439 :\n",
      "{'alpha': 1.8089897512564925}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51943230248 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56835291582 :\n",
      "{'alpha': 1.1211483547678005}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.5476606625 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59157428023 :\n",
      "{'alpha': 1.8625635261755884}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52373643078 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57190172656 :\n",
      "{'alpha': 1.2193958733908066}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54228078972 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58715906295 :\n",
      "{'alpha': 1.7021745336798255}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  22%|██▏       | 223/1000 [00:01<00:07, 101.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.361726954492 and loss 2.56043323179 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60203457097 :\n",
      "{'alpha': 2.2863654223879}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47334607817 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53022214228 :\n",
      "{'alpha': 0.32273335593917996}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57459856226 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61359726999 :\n",
      "{'alpha': 2.83893330237791}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55252089035 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59555837442 :\n",
      "{'alpha': 2.0163577162984025}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52789553386 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57532840974 :\n",
      "{'alpha': 1.3189861192810723}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52717982907 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57473892611 :\n",
      "{'alpha': 1.301512560995543}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53369312297 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58010057736 :\n",
      "{'alpha': 1.4658909109252782}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50675657426 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55788757423 :\n",
      "{'alpha': 0.8580517923909714}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50136308561 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55342896775 :\n",
      "{'alpha': 0.7570480145719983}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48885245096 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54307573995 :\n",
      "{'alpha': 0.5453963838679995}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51050149604 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5609814886 :\n",
      "{'alpha': 0.9319017113833237}\n",
      "Parameters with this training accuracy 0.393232205368 and loss 2.45164799931 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.51215747404 :\n",
      "{'alpha': 0.0768752430973415}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.44318452094 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5050258959 :\n",
      "{'alpha': 0.0012180515329678343}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.5704440827 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61021036102 :\n",
      "{'alpha': 2.6668422136368637}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51460705648 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56437144509 :\n",
      "{'alpha': 1.0165350337616557}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51953863024 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56844061554 :\n",
      "{'alpha': 1.1235183388840375}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53702563083 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58284118031 :\n",
      "{'alpha': 1.5548314844785858}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54077576004 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58592295711 :\n",
      "{'alpha': 1.6590630128875952}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47721915393 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53343511996 :\n",
      "{'alpha': 0.37450084685181206}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52242934628 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57082429477 :\n",
      "{'alpha': 1.1890531856606503}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  25%|██▍       | 246/1000 [00:02<00:07, 106.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.364060676779 and loss 2.55551912205 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59801385798 :\n",
      "{'alpha': 2.115704338627396}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.58858596534 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.62497435466 :\n",
      "{'alpha': 3.4891113734303967}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54412809342 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58867572759 :\n",
      "{'alpha': 1.7561245177540634}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54839295801 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59217485463 :\n",
      "{'alpha': 1.8851805505054382}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53098405674 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57787133147 :\n",
      "{'alpha': 1.396039866219351}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52596469091 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57373791069 :\n",
      "{'alpha': 1.272168257370945}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56457300448 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60541796676 :\n",
      "{'alpha': 2.4381292428224626}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.58350726664 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62084805762 :\n",
      "{'alpha': 3.23952731319932}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.49660177967 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5494904907 :\n",
      "{'alpha': 0.6728920582157472}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57769057701 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61611570573 :\n",
      "{'alpha': 2.97290666260813}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50380652774 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55544925695 :\n",
      "{'alpha': 0.8020412208413956}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.55983800638 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60154781506 :\n",
      "{'alpha': 2.2651580616678504}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59923933038 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63361322995 :\n",
      "{'alpha': 4.069978016886607}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48632123342 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54097923269 :\n",
      "{'alpha': 0.5061786306865168}\n",
      "Parameters with this training accuracy 0.373395565928 and loss 2.53440172442 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58068347575 :\n",
      "{'alpha': 1.48452023439195}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.458082484 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51753245377 :\n",
      "{'alpha': 0.14212623567024613}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.4677672127 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52559019561 :\n",
      "{'alpha': 0.2524581369959364}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55221879521 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59531086849 :\n",
      "{'alpha': 2.006540990982712}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.56746753703 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60778157277 :\n",
      "{'alpha': 2.548843244198964}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53109020241 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5779586993 :\n",
      "{'alpha': 1.3987363913988615}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44472344263 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50633148275 :\n",
      "{'alpha': 0.014050429774558948}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48151143395 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53699377433 :\n",
      "{'alpha': 0.43480953518127624}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  27%|██▋       | 268/1000 [00:02<00:07, 103.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.357059509918 and loss 2.5808661879 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61870018377 :\n",
      "{'alpha': 3.1160273799128615}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51301429068 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56305654493 :\n",
      "{'alpha': 0.9832348596520541}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52337133479 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57160080213 :\n",
      "{'alpha': 1.210875351011513}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53904448739 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58450053821 :\n",
      "{'alpha': 1.6103858080463445}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50618059766 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55741158361 :\n",
      "{'alpha': 0.846968535371238}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49614706537 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54911424254 :\n",
      "{'alpha': 0.6650921434733781}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49945084147 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55184745886 :\n",
      "{'alpha': 0.7226985038887738}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51535835727 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56499156727 :\n",
      "{'alpha': 1.0324515238923462}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51816479471 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56730735056 :\n",
      "{'alpha': 1.0931143035049538}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52555972678 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57340425708 :\n",
      "{'alpha': 1.262478183253576}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48874972007 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54299066367 :\n",
      "{'alpha': 0.543781981157935}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49094298257 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54480679455 :\n",
      "{'alpha': 0.5786721872614272}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54506854842 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58944761708 :\n",
      "{'alpha': 1.7840363379604975}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51001327321 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56057822869 :\n",
      "{'alpha': 0.9220958337953722}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54952257232 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59310108214 :\n",
      "{'alpha': 1.9204499155590313}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.4721488967 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52922858657 :\n",
      "{'alpha': 0.3072301545365839}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53017153507 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57720249063 :\n",
      "{'alpha': 1.375506003593597}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48121302489 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53674643285 :\n",
      "{'alpha': 0.43051494265084195}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46206829078 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52085203308 :\n",
      "{'alpha': 0.18576577101098846}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52137827432 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56995771778 :\n",
      "{'alpha': 1.1649766253886107}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  29%|██▉       | 290/1000 [00:02<00:06, 102.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.373395565928 and loss 2.53447203305 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58074130737 :\n",
      "{'alpha': 1.486376895452996}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50684403341 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55795984781 :\n",
      "{'alpha': 0.8597410581020275}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54325004933 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58795491696 :\n",
      "{'alpha': 1.7303378377499374}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.513672619 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56360006298 :\n",
      "{'alpha': 0.9969260927153196}\n",
      "Parameters with this training accuracy 0.364060676779 and loss 2.55582157491 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59826146236 :\n",
      "{'alpha': 2.1259228689532685}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.4747752793 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53140798846 :\n",
      "{'alpha': 0.34154771218493796}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50314376124 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55490132908 :\n",
      "{'alpha': 0.7897134175916207}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.49547430715 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54855754023 :\n",
      "{'alpha': 0.6536264295117502}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52588864888 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57367526084 :\n",
      "{'alpha': 1.2703453165040586}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51710196828 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5664304611 :\n",
      "{'alpha': 1.069914418661667}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.5402607792 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58549990238 :\n",
      "{'alpha': 1.6444821908824698}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54600498919 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59021605036 :\n",
      "{'alpha': 1.8121330403838094}\n",
      "Parameters with this training accuracy 0.393232205368 and loss 2.45441868508 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51447499601 :\n",
      "{'alpha': 0.10418171961111211}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50208848995 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55402881174 :\n",
      "{'alpha': 0.770275337074751}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.56296864483 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60410715056 :\n",
      "{'alpha': 2.3784144999371053}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.48940459581 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54353298023 :\n",
      "{'alpha': 0.5541065051383764}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48573252568 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54049154294 :\n",
      "{'alpha': 0.49722330262473635}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46628026495 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52435467002 :\n",
      "{'alpha': 0.23456555802603574}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.511101237 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56147682122 :\n",
      "{'alpha': 0.9440216570662412}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59375164929 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6291660163 :\n",
      "{'alpha': 3.76050284421848}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52158935251 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57013175787 :\n",
      "{'alpha': 1.1697888093018138}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53634507279 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58228165191 :\n",
      "{'alpha': 1.5363918540058608}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  31%|███▏      | 313/1000 [00:02<00:06, 105.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.5321095789 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57879764955 :\n",
      "{'alpha': 1.424799112619863}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.5395750699 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58493652234 :\n",
      "{'alpha': 1.625201067137324}\n",
      "Parameters with this training accuracy 0.36756126021 and loss 2.55122362474 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59449540293 :\n",
      "{'alpha': 1.9744477200130932}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53010379192 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57714672199 :\n",
      "{'alpha': 1.3738025627110226}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5206394874 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56934851749 :\n",
      "{'alpha': 1.1482237436009992}\n",
      "Parameters with this training accuracy 0.364060676779 and loss 2.5557109433 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59817089538 :\n",
      "{'alpha': 2.1221808765735233}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5267001346 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57434378653 :\n",
      "{'alpha': 1.2898801633858188}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50109218296 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55320494192 :\n",
      "{'alpha': 0.7521361966734763}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.44358431014 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50536562246 :\n",
      "{'alpha': 0.004508454389466898}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54758252189 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59151018917 :\n",
      "{'alpha': 1.8601615202258495}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51545992758 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56507539769 :\n",
      "{'alpha': 1.0346136873440228}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.56002235459 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6016985766 :\n",
      "{'alpha': 2.2717100968552852}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57297422269 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61227346205 :\n",
      "{'alpha': 2.7705934514705186}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53343039181 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57988443259 :\n",
      "{'alpha': 1.4590218140567721}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52059667872 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56931321532 :\n",
      "{'alpha': 1.1472572829652132}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51875676422 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56779569228 :\n",
      "{'alpha': 1.1061572601015075}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48164478753 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53710430376 :\n",
      "{'alpha': 0.4367336829677896}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54213746639 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58704136655 :\n",
      "{'alpha': 1.6980367381557622}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50961160066 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56024643625 :\n",
      "{'alpha': 0.9140687580860516}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47703361442 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53328124548 :\n",
      "{'alpha': 0.37196416602496546}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49432379912 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54760540417 :\n",
      "{'alpha': 0.6342227811389738}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46080122625 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51979736957 :\n",
      "{'alpha': 0.17162624591986497}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  34%|███▎      | 336/1000 [00:03<00:06, 106.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.378063010502 and loss 2.49410121943 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54742118753 :\n",
      "{'alpha': 0.6304984818278346}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50641269488 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55760339459 :\n",
      "{'alpha': 0.851425984931989}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47009215868 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52752115844 :\n",
      "{'alpha': 0.28113745237857085}\n",
      "Parameters with this training accuracy 0.345390898483 and loss 2.61041449758 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64265214594 :\n",
      "{'alpha': 4.77690021084684}\n",
      "Parameters with this training accuracy 0.362893815636 and loss 2.55761460531 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59972896406 :\n",
      "{'alpha': 2.187259612412112}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45241183366 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51279693563 :\n",
      "{'alpha': 0.08428284738821568}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52971267445 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57682472563 :\n",
      "{'alpha': 1.3639932822589804}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53847226307 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58403028166 :\n",
      "{'alpha': 1.5945086486965716}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52466005706 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57266292389 :\n",
      "{'alpha': 1.2411089807065308}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54919747921 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59283454671 :\n",
      "{'alpha': 1.9102519789805164}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48696138255 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54150949964 :\n",
      "{'alpha': 0.5159871462437462}\n",
      "Parameters with this training accuracy 0.364060676779 and loss 2.55339761022 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59627656917 :\n",
      "{'alpha': 2.045045466552586}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.5358951354 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58191168767 :\n",
      "{'alpha': 1.5242794740552377}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.56710909152 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60748896755 :\n",
      "{'alpha': 2.534920732220758}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51864290944 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56770177212 :\n",
      "{'alpha': 1.1036419073582546}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50944884649 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56011199155 :\n",
      "{'alpha': 0.9108266149731702}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.5447655301 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58919892893 :\n",
      "{'alpha': 1.7750098118694753}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54275225597 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58754620258 :\n",
      "{'alpha': 1.7158343237791307}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5131997077 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56320963125 :\n",
      "{'alpha': 0.9870806873680387}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50239675264 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55428370082 :\n",
      "{'alpha': 0.7759294488475371}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52635249398 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57405740214 :\n",
      "{'alpha': 1.2814894428384194}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.4973527403 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55011182103 :\n",
      "{'alpha': 0.6858629668678724}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49898425768 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55146151842 :\n",
      "{'alpha': 0.7144303527112384}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  36%|███▌      | 358/1000 [00:03<00:06, 103.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.381563593932 and loss 2.47849174717 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53449041807 :\n",
      "{'alpha': 0.39205538587406746}\n",
      "Parameters with this training accuracy 0.390898483081 and loss 2.44723543023 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50845239929 :\n",
      "{'alpha': 0.03591480062808361}\n",
      "Parameters with this training accuracy 0.373395565928 and loss 2.534723822 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58094840698 :\n",
      "{'alpha': 1.4930381997681783}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.46472329887 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52306044026 :\n",
      "{'alpha': 0.21620346734737966}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.5628075634 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60397551275 :\n",
      "{'alpha': 2.3724825770166413}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47253601649 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52954988514 :\n",
      "{'alpha': 0.3122177644178652}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49207227859 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54574173404 :\n",
      "{'alpha': 0.5969867126047973}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48524230178 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54008541272 :\n",
      "{'alpha': 0.489813382608724}\n",
      "Parameters with this training accuracy 0.341890315053 and loss 2.61334447311 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64501835991 :\n",
      "{'alpha': 4.981410818461797}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50755800595 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55854982112 :\n",
      "{'alpha': 0.8735940887534392}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52138522365 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56996344781 :\n",
      "{'alpha': 1.1651348745481016}\n",
      "Parameters with this training accuracy 0.350058343057 and loss 2.60412647317 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63756894649 :\n",
      "{'alpha': 4.365675421394358}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52897400819 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57621653631 :\n",
      "{'alpha': 1.3455858631369781}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.4577521177 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51725703136 :\n",
      "{'alpha': 0.1386194763385573}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.57061174628 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61034711629 :\n",
      "{'alpha': 2.673617833712671}\n",
      "Parameters with this training accuracy 0.368728121354 and loss 2.55007826007 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59355662967 :\n",
      "{'alpha': 1.9379714288104766}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51393239991 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56381452419 :\n",
      "{'alpha': 1.0023567975543002}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53220144945 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5788732511 :\n",
      "{'alpha': 1.4271628840165116}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53907731384 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58452751341 :\n",
      "{'alpha': 1.6112997909015594}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55356926959 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59641717229 :\n",
      "{'alpha': 2.0506972001876624}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52334628877 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57158015764 :\n",
      "{'alpha': 1.2102921211155035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  38%|███▊      | 380/1000 [00:03<00:06, 97.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.371061843641 and loss 2.54701213279 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59104232042 :\n",
      "{'alpha': 1.8426940563955498}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50411592033 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55570502473 :\n",
      "{'alpha': 0.8078279120524737}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53674649398 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58261169437 :\n",
      "{'alpha': 1.5472509276255844}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54246090663 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.5873069688 :\n",
      "{'alpha': 1.7073842864489726}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5210256209 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56966693089 :\n",
      "{'alpha': 1.1569623468927253}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51219743081 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56238206871 :\n",
      "{'alpha': 0.9663874607859556}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.5582256455 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60022892302 :\n",
      "{'alpha': 2.208462596800928}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.48982904884 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54388445755 :\n",
      "{'alpha': 0.5608405021563474}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47762616397 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53377265354 :\n",
      "{'alpha': 0.3800856562089418}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52730737751 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57484398593 :\n",
      "{'alpha': 1.3046162169053057}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49790447838 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55056828373 :\n",
      "{'alpha': 0.6954641516472762}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52855805665 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5758740204 :\n",
      "{'alpha': 1.3352881605830589}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51547661156 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56508916759 :\n",
      "{'alpha': 1.0349690821911652}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47004244188 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52747987678 :\n",
      "{'alpha': 0.2805151447117839}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50785373001 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55879416856 :\n",
      "{'alpha': 0.8793648025664331}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.44388179366 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50561814833 :\n",
      "{'alpha': 0.006976840146486585}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.4824847036 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53780042213 :\n",
      "{'alpha': 0.4489235935039778}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.58541630819 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62239971198 :\n",
      "{'alpha': 3.3314303608671882}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  39%|███▉      | 390/1000 [00:03<00:06, 96.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.375729288215 and loss 2.5022741649 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5541823395 :\n",
      "{'alpha': 0.7736785881359174}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53288422257 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57943507154 :\n",
      "{'alpha': 1.4448079101106095}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51646931815 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56590841983 :\n",
      "{'alpha': 1.0562361497652812}\n",
      "Parameters with this training accuracy 0.393232205368 and loss 2.45463971399 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51465965181 :\n",
      "{'alpha': 0.10641177973537341}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54691795255 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59096506206 :\n",
      "{'alpha': 1.839821038042043}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57476238498 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61373075243 :\n",
      "{'alpha': 2.845902575941042}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53790449868 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.5835636342 :\n",
      "{'alpha': 1.5788579326926278}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.5662227233 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60676529719 :\n",
      "{'alpha': 2.5007526438168606}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51786496782 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56705999228 :\n",
      "{'alpha': 1.0865413392274923}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49485932166 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54804860683 :\n",
      "{'alpha': 0.6432225806586002}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.46561152475 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52379884826 :\n",
      "{'alpha': 0.2266321462033452}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49294932579 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54646775601 :\n",
      "{'alpha': 0.6113764864907895}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.58822730207 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.624683122 :\n",
      "{'alpha': 3.4709417680149883}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52487211711 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5728376734 :\n",
      "{'alpha': 1.246126309077185}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48427361284 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53928282609 :\n",
      "{'alpha': 0.47529691854467454}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50605017829 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55730379917 :\n",
      "{'alpha': 0.8444689550397455}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51178680175 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56204298417 :\n",
      "{'alpha': 0.9579768962128496}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.56150755601 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60291293813 :\n",
      "{'alpha': 2.325027358839912}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  41%|████      | 411/1000 [00:03<00:06, 95.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.366394399067 and loss 2.55180821267 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59497445082 :\n",
      "{'alpha': 1.993254656155353}\n",
      "Parameters with this training accuracy 0.381563593932 and loss 2.47854228662 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53453232407 :\n",
      "{'alpha': 0.39275817501248433}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46055179339 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51958968733 :\n",
      "{'alpha': 0.16887207946492477}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52038094356 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56913530551 :\n",
      "{'alpha': 1.1423938894562853}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48888480682 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54310253515 :\n",
      "{'alpha': 0.5459052531586233}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48921780107 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54337829558 :\n",
      "{'alpha': 0.55115352414763}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52891295908 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57616626701 :\n",
      "{'alpha': 1.3440714263486981}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50214336408 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5540741855 :\n",
      "{'alpha': 0.7712803816151874}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5102152394 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56074505113 :\n",
      "{'alpha': 0.926145735113849}\n",
      "Parameters with this training accuracy 0.373395565928 and loss 2.53454468009 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58080106157 :\n",
      "{'alpha': 1.4882968737190783}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5003001485 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55254991797 :\n",
      "{'alpha': 0.7378621865083282}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.5446010426 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58906392643 :\n",
      "{'alpha': 1.7701231967022835}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50773303399 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55869444244 :\n",
      "{'alpha': 0.8770072272805665}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54070022957 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58586091206 :\n",
      "{'alpha': 1.6569190819394801}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49168814563 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54542372524 :\n",
      "{'alpha': 0.5907300586969162}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51546229483 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56507735147 :\n",
      "{'alpha': 1.0346641093382833}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.4713713861 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52858320549 :\n",
      "{'alpha': 0.2972861259755086}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52417657959 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57226448633 :\n",
      "{'alpha': 1.229714839573527}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49728255456 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55005375301 :\n",
      "{'alpha': 0.6846459566600928}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  43%|████▎     | 433/1000 [00:04<00:06, 94.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.380396732789 and loss 2.48252939198 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53783745765 :\n",
      "{'alpha': 0.44957560150738773}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53128854405 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57812194821 :\n",
      "{'alpha': 1.4037837968887783}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52866166377 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57595933835 :\n",
      "{'alpha': 1.3378486154884617}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47515011234 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53171895195 :\n",
      "{'alpha': 0.34653767776835764}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53575144464 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58179352972 :\n",
      "{'alpha': 1.520424410326604}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52571012894 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57352817764 :\n",
      "{'alpha': 1.2660718552460741}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50212172451 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55405629243 :\n",
      "{'alpha': 0.7708839682225654}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51973427069 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56860197683 :\n",
      "{'alpha': 1.1278864907449655}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54179957986 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58676388128 :\n",
      "{'alpha': 1.688308867275299}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.49550349252 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5485816918 :\n",
      "{'alpha': 0.6541219952072811}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51042622734 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56091932035 :\n",
      "{'alpha': 0.93038642334434}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50576342323 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55706680533 :\n",
      "{'alpha': 0.8389860558405022}\n",
      "Parameters with this training accuracy 0.390898483081 and loss 2.44832749447 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50937141838 :\n",
      "{'alpha': 0.045756178968248906}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47628492341 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53266028739 :\n",
      "{'alpha': 0.36178653332575017}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51476310521 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56450025329 :\n",
      "{'alpha': 1.019829871668017}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52518655993 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57309677992 :\n",
      "{'alpha': 1.2535882057899128}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.4620236505 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5208148846 :\n",
      "{'alpha': 0.18526338356999844}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53106262237 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57793599851 :\n",
      "{'alpha': 1.3980354347832016}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54949585595 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59307917883 :\n",
      "{'alpha': 1.9196103803485813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  45%|████▌     | 454/1000 [00:04<00:05, 93.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.365227537923 and loss 2.55440737391 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59710356615 :\n",
      "{'alpha': 2.0784558951426813}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53594434405 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58195215151 :\n",
      "{'alpha': 1.5256011444808637}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.5440315022 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58859644006 :\n",
      "{'alpha': 1.7532749567664028}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53978702913 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58511067725 :\n",
      "{'alpha': 1.6311448212271196}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54654676686 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59066055326 :\n",
      "{'alpha': 1.8285284101215993}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49084410539 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5447249289 :\n",
      "{'alpha': 0.5770800239754473}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48498545217 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53987261425 :\n",
      "{'alpha': 0.48594809542255635}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45379091589 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51395036831 :\n",
      "{'alpha': 0.0978893961992251}\n",
      "Parameters with this training accuracy 0.362893815636 and loss 2.55730259794 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59947364803 :\n",
      "{'alpha': 2.176492291649762}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52229582624 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57071422022 :\n",
      "{'alpha': 1.1859788085590213}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59698803375 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63178948397 :\n",
      "{'alpha': 3.9402502333887117}\n",
      "Parameters with this training accuracy 0.351225204201 and loss 2.60122173002 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63521834814 :\n",
      "{'alpha': 4.187540291258113}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44441065684 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50606656712 :\n",
      "{'alpha': 0.01140632362313243}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52149430016 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57005338523 :\n",
      "{'alpha': 1.1676203752403056}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52087261398 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56954076081 :\n",
      "{'alpha': 1.1534950821191365}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5164174018 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56586557791 :\n",
      "{'alpha': 1.0551180166205718}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53360078637 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58002461479 :\n",
      "{'alpha': 1.4634744279525569}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.47115365637 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5284024596 :\n",
      "{'alpha': 0.29451895870348443}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52950965025 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57665757184 :\n",
      "{'alpha': 1.3589185631526888}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  46%|████▋     | 464/1000 [00:04<00:06, 86.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.376896149358 and loss 2.50324718156 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55498683263 :\n",
      "{'alpha': 0.7916309866473172}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53781214259 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58348772116 :\n",
      "{'alpha': 1.5763217123847868}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5095443284 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56019086571 :\n",
      "{'alpha': 0.9127279386724361}\n",
      "Parameters with this training accuracy 0.368728121354 and loss 2.54997448677 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59347156177 :\n",
      "{'alpha': 1.9346906769852397}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.49687509321 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54971663134 :\n",
      "{'alpha': 0.6775999318724945}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52726278504 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57480725604 :\n",
      "{'alpha': 1.303530631333861}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54098388701 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58609391927 :\n",
      "{'alpha': 1.6649803488667667}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46660021075 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52462055695 :\n",
      "{'alpha': 0.23838603226605531}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.56382683428 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60480838538 :\n",
      "{'alpha': 2.410212696619957}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48358933089 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53871582388 :\n",
      "{'alpha': 0.4651424545848921}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48860934875 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.542874414 :\n",
      "{'alpha': 0.5415791932914384}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44514826579 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50669096418 :\n",
      "{'alpha': 0.01767011900882809}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.58009206006 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.6180703489 :\n",
      "{'alpha': 3.0806073113707964}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49846786707 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55103435463 :\n",
      "{'alpha': 0.7053308064338749}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5125594809 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56268102131 :\n",
      "{'alpha': 0.973835432457754}\n",
      "Parameters with this training accuracy 0.373395565928 and loss 2.5234616708 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57167526191 :\n",
      "{'alpha': 1.2129803173824851}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50720925174 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55826164393 :\n",
      "{'alpha': 0.8668133152840176}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5336153176 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58003656929 :\n",
      "{'alpha': 1.463854546893165}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  48%|████▊     | 485/1000 [00:04<00:05, 89.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.385064177363 and loss 2.47741357543 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53359635621 :\n",
      "{'alpha': 0.37716514629963716}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51034271159 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56085033966 :\n",
      "{'alpha': 0.928706615216287}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55272102571 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59572233519 :\n",
      "{'alpha': 2.0228804379085914}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5183977828 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56749955831 :\n",
      "{'alpha': 1.0982373703037345}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5316240113 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57839804665 :\n",
      "{'alpha': 1.4123467436704575}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49599433571 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5489878637 :\n",
      "{'alpha': 0.6624814199286905}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49485859884 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54804800863 :\n",
      "{'alpha': 0.6432103956533571}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48828541543 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54260613894 :\n",
      "{'alpha': 0.5365096146145178}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51362892495 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56356399069 :\n",
      "{'alpha': 0.9960142341387994}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49962494513 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5519914653 :\n",
      "{'alpha': 0.7257950248084079}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51821589871 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56734951036 :\n",
      "{'alpha': 1.0942368526856738}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.56904583129 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60906964851 :\n",
      "{'alpha': 2.6108758808072587}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53836648558 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58394334701 :\n",
      "{'alpha': 1.5915851068025837}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52987089485 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57695498708 :\n",
      "{'alpha': 1.3679562232562077}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54358513799 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58823001702 :\n",
      "{'alpha': 1.7401479429844189}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52097011138 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56962115791 :\n",
      "{'alpha': 1.1557037621245863}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52540500375 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57327677292 :\n",
      "{'alpha': 1.2587876489819618}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  50%|█████     | 505/1000 [00:04<00:05, 89.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.361726954492 and loss 2.55945302896 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6012329553 :\n",
      "{'alpha': 2.251521795020207}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.45827230288 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51769068211 :\n",
      "{'alpha': 0.14414875401515093}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.44307689505 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50493436599 :\n",
      "{'alpha': 0.00033760088509038333}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50581829295 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55711215408 :\n",
      "{'alpha': 0.840033814857648}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.47085495047 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52815447985 :\n",
      "{'alpha': 0.2907350804271862}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.4774898489 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53365960957 :\n",
      "{'alpha': 0.37821210775261577}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48907439481 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54325953872 :\n",
      "{'alpha': 0.5488908198486342}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50423033933 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55579960973 :\n",
      "{'alpha': 0.8099730859561286}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51404085311 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56390405485 :\n",
      "{'alpha': 1.0046287198446793}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54569476593 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58996150239 :\n",
      "{'alpha': 1.8027913523662429}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52843616577 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57577364409 :\n",
      "{'alpha': 1.3322797079671287}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59121876966 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.62711138944 :\n",
      "{'alpha': 3.6251266365034827}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54965389254 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5932087425 :\n",
      "{'alpha': 1.9245803348114172}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53549509368 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5815827218 :\n",
      "{'alpha': 1.513562505534189}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54187280437 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58682401777 :\n",
      "{'alpha': 1.6904138099707051}\n",
      "Parameters with this training accuracy 0.34772462077 and loss 2.60685161006 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63977279641 :\n",
      "{'alpha': 4.539443605398447}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.517586205 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56683000121 :\n",
      "{'alpha': 1.0804500706951654}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59492227334 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6301151793 :\n",
      "{'alpha': 3.8246232355502117}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  52%|█████▎    | 525/1000 [00:05<00:05, 87.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.375729288215 and loss 2.50295274823 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55474340465 :\n",
      "{'alpha': 0.7861776636945834}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48414841349 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5391790882 :\n",
      "{'alpha': 0.4734328434923656}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46669732734 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52470126008 :\n",
      "{'alpha': 0.239548893203814}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.45790514033 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51738461043 :\n",
      "{'alpha': 0.1402416761550792}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50913264625 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55985078243 :\n",
      "{'alpha': 0.9045447709041428}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48798311509 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54235577106 :\n",
      "{'alpha': 0.5317958870484311}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47884979976 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53478729984 :\n",
      "{'alpha': 0.39704368838898607}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.5545872382 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59725085423 :\n",
      "{'alpha': 2.0844490091453682}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49366040386 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54705633565 :\n",
      "{'alpha': 0.6231507003902171}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45404663683 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51416410493 :\n",
      "{'alpha': 0.10044514584134862}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50113338649 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55323901609 :\n",
      "{'alpha': 0.7528822938803527}\n",
      "Parameters with this training accuracy 0.364060676779 and loss 2.55595801282 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59837315196 :\n",
      "{'alpha': 2.130544486765687}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49297954187 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54649276768 :\n",
      "{'alpha': 0.611874848075372}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52318195268 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57144469941 :\n",
      "{'alpha': 1.2064694313981994}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51361056172 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56354883058 :\n",
      "{'alpha': 0.9956311430072784}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50101914842 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55314454395 :\n",
      "{'alpha': 0.7508145755445571}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48206722271 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53745442496 :\n",
      "{'alpha': 0.4428492867614392}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46197680055 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52077589663 :\n",
      "{'alpha': 0.18473646103582497}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  54%|█████▍    | 544/1000 [00:05<00:05, 90.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.359393232205 and loss 2.5763795558 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61504812364 :\n",
      "{'alpha': 2.9154686140028367}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53307124356 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57958894867 :\n",
      "{'alpha': 1.4496651214772314}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50797548515 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55889476812 :\n",
      "{'alpha': 0.881746329088007}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.44314147916 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50498929506 :\n",
      "{'alpha': 0.0008656667254602901}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53703126333 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58284581081 :\n",
      "{'alpha': 1.5549846966417658}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.4725702435 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52957829152 :\n",
      "{'alpha': 0.31265991216051237}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.4668941914 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52486484638 :\n",
      "{'alpha': 0.24191068060778442}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52442094823 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57246587672 :\n",
      "{'alpha': 1.2354661002634164}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54871633788 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59244003466 :\n",
      "{'alpha': 1.89522980523143}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53929786371 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58470874581 :\n",
      "{'alpha': 1.6174494767525676}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52839128004 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57573668042 :\n",
      "{'alpha': 1.3311729076537158}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57293597848 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61224228715 :\n",
      "{'alpha': 2.7690009532811226}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54580777184 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59005422936 :\n",
      "{'alpha': 1.8061903808030824}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51717848083 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56649359309 :\n",
      "{'alpha': 1.0715752933758969}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.56237214088 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60361965361 :\n",
      "{'alpha': 2.3565053205000326}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51141120784 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56173281277 :\n",
      "{'alpha': 0.9503179935445629}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48326138844 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53844407149 :\n",
      "{'alpha': 0.4603051043653671}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50535356154 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55672805227 :\n",
      "{'alpha': 0.8311801546943318}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52234931744 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57075831892 :\n",
      "{'alpha': 1.1872099178748172}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  56%|█████▋    | 563/1000 [00:05<00:05, 86.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.380396732789 and loss 2.48900800667 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54320456106 :\n",
      "{'alpha': 0.5478446104655947}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47317693304 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53008177929 :\n",
      "{'alpha': 0.320528813693935}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.49532494376 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54843393733 :\n",
      "{'alpha': 0.6510928486384533}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51437550743 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56418031056 :\n",
      "{'alpha': 1.0116567480637164}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49418572207 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54749112613 :\n",
      "{'alpha': 0.6319112918821039}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.45744487356 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51700084212 :\n",
      "{'alpha': 0.13537330562079708}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54109061743 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58618158808 :\n",
      "{'alpha': 1.6680203475080555}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52012886598 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56892741712 :\n",
      "{'alpha': 1.1367262041808661}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5316711678 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57843685625 :\n",
      "{'alpha': 1.4135530561340133}\n",
      "Parameters with this training accuracy 0.36756126021 and loss 2.55119304368 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.5944703411 :\n",
      "{'alpha': 1.9734674342087748}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49811073079 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55073891242 :\n",
      "{'alpha': 0.6990688877138781}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47738202949 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53357019506 :\n",
      "{'alpha': 0.37673241880013214}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53508662514 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58124679856 :\n",
      "{'alpha': 1.5026702283414424}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52236838036 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57077403449 :\n",
      "{'alpha': 1.1876488340786902}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52545351949 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57331674789 :\n",
      "{'alpha': 1.2599441761047923}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54381439964 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.5884182238 :\n",
      "{'alpha': 1.746881774848209}\n",
      "Parameters with this training accuracy 0.390898483081 and loss 2.44757372705 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50873726136 :\n",
      "{'alpha': 0.0389421642609058}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50720717221 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55825992556 :\n",
      "{'alpha': 0.8667729634453368}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  58%|█████▊    | 582/1000 [00:05<00:04, 88.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.380396732789 and loss 2.48147003372 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53695945959 :\n",
      "{'alpha': 0.4342127999259092}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5046319244 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55613157085 :\n",
      "{'alpha': 0.8175242379462442}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46428252209 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52269393794 :\n",
      "{'alpha': 0.21107416258044887}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.56048951896 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6020805971 :\n",
      "{'alpha': 2.288378711857242}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49490190525 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54808384818 :\n",
      "{'alpha': 0.6439406084554334}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55409599136 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59684856488 :\n",
      "{'alpha': 2.0681106011481463}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52856270871 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57587785129 :\n",
      "{'alpha': 1.33540306281808}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56486406702 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.6056557187 :\n",
      "{'alpha': 2.4490872556469214}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50057635014 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55277834791 :\n",
      "{'alpha': 0.742825262294499}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.58299056681 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62042796037 :\n",
      "{'alpha': 3.2150373215574346}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51654859577 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56597383987 :\n",
      "{'alpha': 1.0579448324941596}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53840734033 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58397692426 :\n",
      "{'alpha': 1.5927138544969086}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51854338776 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56761967407 :\n",
      "{'alpha': 1.1014458564537628}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54711601566 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59112753616 :\n",
      "{'alpha': 1.8458667117201393}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5248498055 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57281928769 :\n",
      "{'alpha': 1.2455978508802419}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53069607444 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57763428602 :\n",
      "{'alpha': 1.388740334782858}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48727093574 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5417659039 :\n",
      "{'alpha': 0.5207567179250379}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52662978688 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57428583594 :\n",
      "{'alpha': 1.2881795693612268}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51137128997 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56169984697 :\n",
      "{'alpha': 0.9495059181565346}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  60%|██████    | 601/1000 [00:05<00:04, 89.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.50858794491 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55940078437 :\n",
      "{'alpha': 0.8937758807005963}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.47145816434 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52865524137 :\n",
      "{'alpha': 0.2983911381872463}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53774818139 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58343514673 :\n",
      "{'alpha': 1.57456682609453}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53243419625 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57906477551 :\n",
      "{'alpha': 1.433162391442638}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.4826670264 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53795152095 :\n",
      "{'alpha': 0.45158588727760013}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51555951715 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56515759204 :\n",
      "{'alpha': 1.0367360932436547}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50013218325 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55241100017 :\n",
      "{'alpha': 0.734851643722775}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51117008716 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56153368259 :\n",
      "{'alpha': 0.9454182847480388}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52079001091 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56947264466 :\n",
      "{'alpha': 1.1516257163295585}\n",
      "Parameters with this training accuracy 0.373395565928 and loss 2.53486414731 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58106382174 :\n",
      "{'alpha': 1.4967589518102062}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48938818387 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54351938963 :\n",
      "{'alpha': 0.5538467958952749}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50204975651 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55399678404 :\n",
      "{'alpha': 0.7695662939457188}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52735004179 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57487912733 :\n",
      "{'alpha': 1.3056553752647209}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.44368857426 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50545415447 :\n",
      "{'alpha': 0.005371668122030382}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54199748096 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58692640767 :\n",
      "{'alpha': 1.6940019084587064}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50421702478 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55578860326 :\n",
      "{'alpha': 0.809723316174873}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.525745794 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57355756259 :\n",
      "{'alpha': 1.2669249252064114}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5137538095 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56366709042 :\n",
      "{'alpha': 0.9986216656323477}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52193273983 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57041487726 :\n",
      "{'alpha': 1.1776419502396318}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  61%|██████    | 611/1000 [00:06<00:04, 91.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.378063010502 and loss 2.49165409213 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54539553301 :\n",
      "{'alpha': 0.5901767467379696}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50931317271 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55999991453 :\n",
      "{'alpha': 0.9081284797902329}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.55817082703 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60018407305 :\n",
      "{'alpha': 2.2065541038690792}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.46438510311 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5227792376 :\n",
      "{'alpha': 0.2122651820240034}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51713250128 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56645565456 :\n",
      "{'alpha': 1.070577033321274}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.49556543793 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54863295279 :\n",
      "{'alpha': 0.6551743752052076}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49718186942 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54997045054 :\n",
      "{'alpha': 0.6829017988029229}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48220258702 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53756661327 :\n",
      "{'alpha': 0.4448155059556891}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49861116796 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55115289727 :\n",
      "{'alpha': 0.7078505953912783}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5027887378 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5546078022 :\n",
      "{'alpha': 0.7831478577331519}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54782828531 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59171176091 :\n",
      "{'alpha': 1.8677235544173119}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53337971974 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57984274418 :\n",
      "{'alpha': 1.4576993600218435}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51298326395 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56303092784 :\n",
      "{'alpha': 0.9825921043016537}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47652871343 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53286249228 :\n",
      "{'alpha': 0.36509032846270545}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50732570248 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55835786922 :\n",
      "{'alpha': 0.869074474022446}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45400935886 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51413294989 :\n",
      "{'alpha': 0.10007194350898863}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52857037847 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5758841672 :\n",
      "{'alpha': 1.335592513296128}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47675976083 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53305412147 :\n",
      "{'alpha': 0.3682305795155577}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.5382292122 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58383052415 :\n",
      "{'alpha': 1.5877963484652697}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  63%|██████▎   | 631/1000 [00:06<00:03, 92.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.52372978208 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57189624665 :\n",
      "{'alpha': 1.2192403929305666}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51923109792 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56818695698 :\n",
      "{'alpha': 1.1166713983669088}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53137525776 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57819331763 :\n",
      "{'alpha': 1.4059940708821164}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51819124247 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56732916949 :\n",
      "{'alpha': 1.0936951735507041}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52276832617 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57110373998 :\n",
      "{'alpha': 1.1968792666713428}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54426308687 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58878653499 :\n",
      "{'alpha': 1.7601123332821265}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54128865898 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58634425486 :\n",
      "{'alpha': 1.67367106815896}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53650172032 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58241044841 :\n",
      "{'alpha': 1.5406234814843602}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53399366693 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58034781617 :\n",
      "{'alpha': 1.4737739036306179}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51141949585 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56173965732 :\n",
      "{'alpha': 0.9504866478181534}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54632338582 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5904772863 :\n",
      "{'alpha': 1.8217559091427935}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55279864661 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59578592398 :\n",
      "{'alpha': 2.025414358748659}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49164569149 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54538857826 :\n",
      "{'alpha': 0.5900402839255708}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50929764077 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5599870838 :\n",
      "{'alpha': 0.9078198608479844}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50333943175 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55506310024 :\n",
      "{'alpha': 0.7933433457571744}\n",
      "Parameters with this training accuracy 0.343057176196 and loss 2.61156263055 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64357953896 :\n",
      "{'alpha': 4.856016363590901}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.47113068744 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52838339175 :\n",
      "{'alpha': 0.29422748804763216}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  65%|██████▌   | 651/1000 [00:06<00:04, 86.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.380396732789 and loss 2.48765657853 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54208532092 :\n",
      "{'alpha': 0.5267229534310172}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.59937261285 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63372117 :\n",
      "{'alpha': 4.077782929787329}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50107127183 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55318764893 :\n",
      "{'alpha': 0.7517576800304956}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51603674557 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56555144573 :\n",
      "{'alpha': 1.046939720293751}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49248564078 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54608392527 :\n",
      "{'alpha': 0.6037505935324864}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48196247879 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53736761319 :\n",
      "{'alpha': 0.4413300231362248}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52774592976 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57520519619 :\n",
      "{'alpha': 1.3153218825954627}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52896147613 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57620621716 :\n",
      "{'alpha': 1.3452748965664398}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52908419694 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57630726689 :\n",
      "{'alpha': 1.348321958408757}\n",
      "Parameters with this training accuracy 0.36756126021 and loss 2.55111965788 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59441019912 :\n",
      "{'alpha': 1.9711164615022436}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53889648587 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58437891534 :\n",
      "{'alpha': 1.6062692956187496}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54283875088 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58761722264 :\n",
      "{'alpha': 1.7183484227811001}\n",
      "Parameters with this training accuracy 0.362893815636 and loss 2.55617846487 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59855360875 :\n",
      "{'alpha': 2.138027754222767}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.5351713471 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58131647593 :\n",
      "{'alpha': 1.504925258934138}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49886498046 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55136285336 :\n",
      "{'alpha': 0.712323746598102}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52102581472 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56966709072 :\n",
      "{'alpha': 1.156966743019234}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54935663886 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59296504009 :\n",
      "{'alpha': 1.9152398624697833}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  67%|██████▋   | 670/1000 [00:06<00:03, 83.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.52410805864 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57220801491 :\n",
      "{'alpha': 1.228105038288884}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54475921028 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58919374205 :\n",
      "{'alpha': 1.7748218898463413}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.46438396826 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52277829396 :\n",
      "{'alpha': 0.21225199689083413}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50487166901 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55632974204 :\n",
      "{'alpha': 0.822048664381454}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51219895753 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56238332939 :\n",
      "{'alpha': 0.9664188041018034}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48466863913 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53961012767 :\n",
      "{'alpha': 0.4811965697130637}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.4713095086 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52853183934 :\n",
      "{'alpha': 0.2964989357175114}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48680912203 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54138337827 :\n",
      "{'alpha': 0.5136474808918059}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44482405391 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50641665215 :\n",
      "{'alpha': 0.014904735760966847}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53299806479 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57952873932 :\n",
      "{'alpha': 1.4477633276766317}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.45815802461 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51759542441 :\n",
      "{'alpha': 0.1429304525140529}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5074627776 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55847113485 :\n",
      "{'alpha': 0.8717399225507069}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51866017173 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5677160121 :\n",
      "{'alpha': 1.1040230691071635}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47669254222 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53299837147 :\n",
      "{'alpha': 0.36731606807650924}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5149756074 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56467565524 :\n",
      "{'alpha': 1.0243260160302028}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49458566287 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54782212804 :\n",
      "{'alpha': 0.6386166383299715}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5263205786 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57403110952 :\n",
      "{'alpha': 1.2807207818549382}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  68%|██████▊   | 679/1000 [00:06<00:04, 78.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.372228704784 and loss 2.53959000103 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58494879066 :\n",
      "{'alpha': 1.6256192914648881}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.46443468283 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5228204639 :\n",
      "{'alpha': 0.21284141823322644}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52184624728 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57034356659 :\n",
      "{'alpha': 1.1756610263106346}\n",
      "Parameters with this training accuracy 0.392065344224 and loss 2.45581093611 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51563766017 :\n",
      "{'alpha': 0.11835553111376207}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50657602927 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55773837467 :\n",
      "{'alpha': 0.8545698672224245}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53122726392 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57807151109 :\n",
      "{'alpha': 1.4022231220018964}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.56872781937 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60881015405 :\n",
      "{'alpha': 2.5982804418296546}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49131417196 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54511411376 :\n",
      "{'alpha': 0.5846655704686594}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53584009287 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58186642621 :\n",
      "{'alpha': 1.5228019955160765}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47946192052 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53529481092 :\n",
      "{'alpha': 0.40562193658840806}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.4987623 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55127791588 :\n",
      "{'alpha': 0.7105125602567306}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51990898824 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5687460768 :\n",
      "{'alpha': 1.1317956512720775}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51574372146 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5653096182 :\n",
      "{'alpha': 1.0406680587745447}\n",
      "Parameters with this training accuracy 0.392065344224 and loss 2.45073826904 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.5113952397 :\n",
      "{'alpha': 0.0681733296573408}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51132531283 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56166187694 :\n",
      "{'alpha': 0.9485710285226076}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.49631446815 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54925276037 :\n",
      "{'alpha': 0.6679589466126077}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  70%|██████▉   | 698/1000 [00:07<00:03, 77.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.386231038506 and loss 2.46843783156 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52614727537 :\n",
      "{'alpha': 0.2606422371778955}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48671019484 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54130143313 :\n",
      "{'alpha': 0.5121295877897722}\n",
      "Parameters with this training accuracy 0.383897316219 and loss 2.47573545614 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53220451994 :\n",
      "{'alpha': 0.354376493106337}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.48981004366 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54386872027 :\n",
      "{'alpha': 0.5605382702180837}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.45899490436 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5182928874 :\n",
      "{'alpha': 0.15189905330193987}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52990463345 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57698276325 :\n",
      "{'alpha': 1.3688021944345943}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54151576574 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58653078655 :\n",
      "{'alpha': 1.68016699815416}\n",
      "Parameters with this training accuracy 0.348891481914 and loss 2.60836268389 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.64099424458 :\n",
      "{'alpha': 4.638693886397948}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47003932893 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52747729197 :\n",
      "{'alpha': 0.2804761928760069}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50671587529 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55785394156 :\n",
      "{'alpha': 0.8572662655777227}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51697194337 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56632317326 :\n",
      "{'alpha': 1.0670952263766753}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48186173002 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53728411153 :\n",
      "{'alpha': 0.43987050235879066}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.501575293 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5536044497 :\n",
      "{'alpha': 0.7609062026725609}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52482365173 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57279773577 :\n",
      "{'alpha': 1.2449785595481693}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52651324352 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57418982897 :\n",
      "{'alpha': 1.2853652173556291}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  72%|███████▏  | 716/1000 [00:07<00:03, 77.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.358226371062 and loss 2.57820087645 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61653115377 :\n",
      "{'alpha': 2.995520493331423}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51117697195 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5615393685 :\n",
      "{'alpha': 0.945558002510671}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53249784339 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57911714841 :\n",
      "{'alpha': 1.4348057926225553}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49608586711 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54906360323 :\n",
      "{'alpha': 0.6640454858782516}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49919930619 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55163940108 :\n",
      "{'alpha': 0.7182356738104059}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49281498482 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54635655285 :\n",
      "{'alpha': 0.6091628710584162}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50345904233 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55516198666 :\n",
      "{'alpha': 0.7955662441063424}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51460469264 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56436949387 :\n",
      "{'alpha': 1.0164851679653382}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50701520484 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5581012962 :\n",
      "{'alpha': 0.8630520616531445}\n",
      "Parameters with this training accuracy 0.390898483081 and loss 2.44617330772 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50755694127 :\n",
      "{'alpha': 0.026536105394137643}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52081440403 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56949275981 :\n",
      "{'alpha': 1.152177568316785}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.58640334134 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.62320167482 :\n",
      "{'alpha': 3.379840212846502}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51018466314 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5607197957 :\n",
      "{'alpha': 0.9255320149535585}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48453628334 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53950046511 :\n",
      "{'alpha': 0.47921678253333305}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51675072247 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56614063151 :\n",
      "{'alpha': 1.062308222554009}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  73%|███████▎  | 734/1000 [00:07<00:03, 77.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.52393993301 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57206945157 :\n",
      "{'alpha': 1.2241604500106622}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53855713831 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58410003611 :\n",
      "{'alpha': 1.5968570488090519}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48853391204 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54281193971 :\n",
      "{'alpha': 0.5403968885038626}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47882832697 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53476949593 :\n",
      "{'alpha': 0.3967439230416787}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54717604565 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5911767782 :\n",
      "{'alpha': 1.8477018183668086}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49332460731 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54677839314 :\n",
      "{'alpha': 0.6175784513325204}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54253427597 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58736721553 :\n",
      "{'alpha': 1.7095095489613068}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.4430862853 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50494235316 :\n",
      "{'alpha': 0.0004143280633542856}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52037426554 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56912979825 :\n",
      "{'alpha': 1.1422435332532113}\n",
      "Parameters with this training accuracy 0.350058343057 and loss 2.60410114777 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.63754845921 :\n",
      "{'alpha': 4.3640912571085}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50498890463 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55642664592 :\n",
      "{'alpha': 0.8242655996319426}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46207877256 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52086075566 :\n",
      "{'alpha': 0.18588377924139515}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.56507213638 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.6058256678 :\n",
      "{'alpha': 2.456944409556434}\n",
      "Parameters with this training accuracy 0.366394399067 and loss 2.55178255869 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59495342973 :\n",
      "{'alpha': 1.9924266255194312}\n",
      "Parameters with this training accuracy 0.383897316219 and loss 2.47582035385 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53227494265 :\n",
      "{'alpha': 0.35551813848578157}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52489674131 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57285796472 :\n",
      "{'alpha': 1.2467096968792968}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53180702476 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57854866394 :\n",
      "{'alpha': 1.417032039783312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  75%|███████▌  | 751/1000 [00:07<00:03, 77.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.371061843641 and loss 2.53764883478 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58335348502 :\n",
      "{'alpha': 1.5718436301339518}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51203663487 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56224929091 :\n",
      "{'alpha': 0.963089369784712}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.57119318086 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61082132025 :\n",
      "{'alpha': 2.6972233126074867}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49972063328 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55207061059 :\n",
      "{'alpha': 0.7274995073814678}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.5611562029 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60262569747 :\n",
      "{'alpha': 2.3123283106151566}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.44390943342 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5056416 :\n",
      "{'alpha': 0.007207037211273248}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.4706040931 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52794621177 :\n",
      "{'alpha': 0.2875684196355447}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54661136686 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59071355087 :\n",
      "{'alpha': 1.8304902428165444}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49500277994 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54816732943 :\n",
      "{'alpha': 0.6456429221329387}\n",
      "Parameters with this training accuracy 0.362893815636 and loss 2.55753236442 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.5996616681 :\n",
      "{'alpha': 2.184417616677174}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55471261525 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.5973535198 :\n",
      "{'alpha': 2.0886341331645486}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50532728181 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5567063313 :\n",
      "{'alpha': 0.8306808874329209}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48314578524 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53834827335 :\n",
      "{'alpha': 0.4586043809944652}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53569198206 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58174463218 :\n",
      "{'alpha': 1.5188309468782886}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.52821393442 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57559063218 :\n",
      "{'alpha': 1.3268053956244397}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48719423973 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54170237709 :\n",
      "{'alpha': 0.5195733763481618}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5147701452 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56450606428 :\n",
      "{'alpha': 1.0199786520479164}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  76%|███████▌  | 759/1000 [00:07<00:03, 75.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.51000244479 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56056928437 :\n",
      "{'alpha': 0.9218789591782808}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54022723559 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58547234481 :\n",
      "{'alpha': 1.6435354533634767}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5169210602 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56628118728 :\n",
      "{'alpha': 1.0659931061490708}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45381283463 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51396869009 :\n",
      "{'alpha': 0.09810805849925536}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50021705288 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55248119303 :\n",
      "{'alpha': 0.7363720930425147}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46343097308 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52198573932 :\n",
      "{'alpha': 0.2012506674827912}\n",
      "Parameters with this training accuracy 0.366394399067 and loss 2.55160937509 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59481151825 :\n",
      "{'alpha': 1.9868433152121163}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54359541177 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58823845123 :\n",
      "{'alpha': 1.7404493205278015}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47343929417 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53029949469 :\n",
      "{'alpha': 0.323950276886102}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.52832801221 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57568457844 :\n",
      "{'alpha': 1.3296137947790416}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49846091622 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55102860463 :\n",
      "{'alpha': 0.7052086882866907}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.46442837072 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52281521532 :\n",
      "{'alpha': 0.2127680349880967}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54742456188 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59138062659 :\n",
      "{'alpha': 1.855312572417377}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.5814923317 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61920952814 :\n",
      "{'alpha': 3.144932044549858}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48132873173 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53684233955 :\n",
      "{'alpha': 0.4321783283537577}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45336394634 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5135934027 :\n",
      "{'alpha': 0.09364490713604995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  78%|███████▊  | 776/1000 [00:08<00:03, 71.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.53341901911 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5798750762 :\n",
      "{'alpha': 1.4587249396357378}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53535200521 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58146504948 :\n",
      "{'alpha': 1.5097411024927028}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.55890443251 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60078422597 :\n",
      "{'alpha': 2.2321979661651796}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49402800997 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54736059517 :\n",
      "{'alpha': 0.6292755952179047}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52275092323 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5710893939 :\n",
      "{'alpha': 1.1964767517830714}\n",
      "Parameters with this training accuracy 0.354725787631 and loss 2.59053267319 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.62655462146 :\n",
      "{'alpha': 3.5892283029732726}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52421746128 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57229817857 :\n",
      "{'alpha': 1.2306758905111856}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52028467356 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56905591267 :\n",
      "{'alpha': 1.1402274608463645}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51163772261 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56191987428 :\n",
      "{'alpha': 0.954933069350822}\n",
      "Parameters with this training accuracy 0.357059509918 and loss 2.5663395852 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.60686071762 :\n",
      "{'alpha': 2.5052364398484444}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50295580334 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55474593056 :\n",
      "{'alpha': 0.7862341550724579}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52999553518 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57705759958 :\n",
      "{'alpha': 1.3710831049223202}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51511939579 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56479433672 :\n",
      "{'alpha': 1.0273744272583873}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  79%|███████▉  | 793/1000 [00:08<00:02, 74.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.379229871645 and loss 2.49532354107 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54843277655 :\n",
      "{'alpha': 0.6510690760625156}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48341771277 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53857361234 :\n",
      "{'alpha': 0.4626086301307602}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.506035573 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55729172858 :\n",
      "{'alpha': 0.8441892639764983}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48753814865 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54198723028 :\n",
      "{'alpha': 0.524887867509835}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5271716014 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57473214901 :\n",
      "{'alpha': 1.3013125098108467}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.47276014703 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52973589701 :\n",
      "{'alpha': 0.31511656323868675}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.48944543812 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54356680129 :\n",
      "{'alpha': 0.554753025950354}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47932243612 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53517916764 :\n",
      "{'alpha': 0.40366160669623136}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52463697021 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57264389862 :\n",
      "{'alpha': 1.2405634735052302}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52669045361 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57433581163 :\n",
      "{'alpha': 1.2896460535341134}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53650000137 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5824090351 :\n",
      "{'alpha': 1.5405770049760608}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.53981315385 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58513214192 :\n",
      "{'alpha': 1.6318784128334396}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54432859807 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58884030771 :\n",
      "{'alpha': 1.7620498345400026}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53130886924 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5781386769 :\n",
      "{'alpha': 1.4043016767326535}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51640647251 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5658565589 :\n",
      "{'alpha': 1.0548827135933005}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53392752214 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58029340425 :\n",
      "{'alpha': 1.4720366662876216}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  81%|████████  | 811/1000 [00:08<00:02, 75.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.372228704784 and loss 2.54105276792 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58615049856 :\n",
      "{'alpha': 1.666941853457737}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54847922805 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59224560027 :\n",
      "{'alpha': 1.887857745402532}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.49033279581 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54430157423 :\n",
      "{'alpha': 0.5688758107164307}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5042336669 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55580236046 :\n",
      "{'alpha': 0.8100355142227631}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51098681881 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56138232528 :\n",
      "{'alpha': 0.9417030809329601}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52210958241 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57056067569 :\n",
      "{'alpha': 1.181698175740427}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51887680312 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56789471191 :\n",
      "{'alpha': 1.1088127391052125}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50703700541 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55811931099 :\n",
      "{'alpha': 0.8634742153144832}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52039226636 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56914464321 :\n",
      "{'alpha': 1.1426488488293256}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.44304280732 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50490536954 :\n",
      "{'alpha': 5.9219233043084074e-05}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46748506033 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52535578651 :\n",
      "{'alpha': 0.24903611331865355}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51321799239 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56322472746 :\n",
      "{'alpha': 0.987460375388336}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50831606471 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55917616132 :\n",
      "{'alpha': 0.8884254958864595}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53391203788 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58028066651 :\n",
      "{'alpha': 1.4716301743857967}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.4578150281 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5173094827 :\n",
      "{'alpha': 0.13928595388847353}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47661469588 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53293380632 :\n",
      "{'alpha': 0.3662579078466273}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  82%|████████▏ | 819/1000 [00:08<00:02, 70.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.386231038506 and loss 2.46734589386 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5252401626 :\n",
      "{'alpha': 0.24735290282271155}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49246514753 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54606696083 :\n",
      "{'alpha': 0.6034144981811772}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52846101452 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57579410705 :\n",
      "{'alpha': 1.3328926753960055}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54434055171 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58885011938 :\n",
      "{'alpha': 1.7624035233442261}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51322410897 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56322977742 :\n",
      "{'alpha': 0.9875874058458269}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53649533262 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58240519649 :\n",
      "{'alpha': 1.5404507778259522}\n",
      "Parameters with this training accuracy 0.368728121354 and loss 2.55009240078 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59356822132 :\n",
      "{'alpha': 1.9384187900842975}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49958090216 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5519550363 :\n",
      "{'alpha': 0.7250111171842222}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49828235827 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5508808934 :\n",
      "{'alpha': 0.7020749609511004}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52967515346 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57679383435 :\n",
      "{'alpha': 1.3630545396428744}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5299961476 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57705810375 :\n",
      "{'alpha': 1.3710984795835104}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52442433199 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5724686653 :\n",
      "{'alpha': 1.2355458492312348}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52042985022 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56917563781 :\n",
      "{'alpha': 1.143495371208111}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52375136181 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5719140328 :\n",
      "{'alpha': 1.2197450794004914}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51573278199 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56530058984 :\n",
      "{'alpha': 1.0404343201362831}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50935798044 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56003692941 :\n",
      "{'alpha': 0.9090191104793756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  84%|████████▎ | 837/1000 [00:09<00:02, 72.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.371061843641 and loss 2.53757937331 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58329638753 :\n",
      "{'alpha': 1.5699414584894638}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48492369114 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53982144463 :\n",
      "{'alpha': 0.4850204127140941}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50380473666 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55544777628 :\n",
      "{'alpha': 0.8020077807848172}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47956849885 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53538317111 :\n",
      "{'alpha': 0.40712203177730977}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49813158204 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55075616203 :\n",
      "{'alpha': 0.6994337847065119}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50267135116 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55451074618 :\n",
      "{'alpha': 0.7809828084806909}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48880217795 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54303410663 :\n",
      "{'alpha': 0.54460610798529}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51717165773 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56648796324 :\n",
      "{'alpha': 1.0714271244972187}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5106830342 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56113142745 :\n",
      "{'alpha': 0.9355616901721097}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52209273048 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57054678225 :\n",
      "{'alpha': 1.1813112946446371}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53300037732 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57953064202 :\n",
      "{'alpha': 1.4478234024067627}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51861721327 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5676805748 :\n",
      "{'alpha': 1.1030746580245618}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5177680127 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56698000139 :\n",
      "{'alpha': 1.0844205916462155}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52632790521 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57403714535 :\n",
      "{'alpha': 1.2808972136791306}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52673927747 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57437603105 :\n",
      "{'alpha': 1.2908269945983646}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  86%|████████▌ | 855/1000 [00:09<00:01, 77.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.52713118202 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57469885558 :\n",
      "{'alpha': 1.300330006333869}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54187041056 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58682205184 :\n",
      "{'alpha': 1.6903449683788363}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49264877433 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5462189668 :\n",
      "{'alpha': 0.6064288744519402}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50918823333 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55989670306 :\n",
      "{'alpha': 0.9056474750391519}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.57255475407 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.6119315143 :\n",
      "{'alpha': 2.753167805908996}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48542847647 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54023965345 :\n",
      "{'alpha': 0.4926224352286436}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49842707449 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55100060946 :\n",
      "{'alpha': 0.7046142680004434}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51926323809 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56821346741 :\n",
      "{'alpha': 1.1173858595908073}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53166669505 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5784331752 :\n",
      "{'alpha': 1.413438610549326}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50654860933 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55771571495 :\n",
      "{'alpha': 0.8540416784382173}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.49631882155 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54925636256 :\n",
      "{'alpha': 0.6680335729256767}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53646804718 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58238276251 :\n",
      "{'alpha': 1.5397132056906733}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.4733613454 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5302348114 :\n",
      "{'alpha': 0.3229325702855205}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.49545714858 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54854334109 :\n",
      "{'alpha': 0.6533351556891878}\n",
      "Parameters with this training accuracy 0.381563593932 and loss 2.48098589062 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53655816252 :\n",
      "{'alpha': 0.4272564022123806}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50159286766 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55361898261 :\n",
      "{'alpha': 0.7612261492177084}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  87%|████████▋ | 871/1000 [00:09<00:01, 75.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.376896149358 and loss 2.50531096525 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55669284514 :\n",
      "{'alpha': 0.8303709770288681}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45334102574 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51357423657 :\n",
      "{'alpha': 0.09341786070392255}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.45758659692 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51711902053 :\n",
      "{'alpha': 0.13686886123967645}\n",
      "Parameters with this training accuracy 0.379229871645 and loss 2.49550218394 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54858060892 :\n",
      "{'alpha': 0.654099772016277}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51392957772 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56381219438 :\n",
      "{'alpha': 1.0022977142435459}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52249804764 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57088093151 :\n",
      "{'alpha': 1.1906368830287455}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54009465814 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.5853634246 :\n",
      "{'alpha': 1.6397971504153683}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5146343118 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56439394283 :\n",
      "{'alpha': 1.0171100889296394}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50269472804 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55453007445 :\n",
      "{'alpha': 0.7814137355314752}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.52997609645 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57704159643 :\n",
      "{'alpha': 1.3705951491750832}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53023974579 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57725864345 :\n",
      "{'alpha': 1.377222526867536}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54485620406 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58927334712 :\n",
      "{'alpha': 1.7777075497060906}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5116912042 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5619640398 :\n",
      "{'alpha': 0.956024441722392}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49077571735 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5446683063 :\n",
      "{'alpha': 0.5759798790475988}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48935243096 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54348978286 :\n",
      "{'alpha': 0.5532811995004852}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  89%|████████▊ | 887/1000 [00:09<00:01, 75.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.380396732789 and loss 2.48195737674 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53736338457 :\n",
      "{'alpha': 0.44125606874534584}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50869657901 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55949053376 :\n",
      "{'alpha': 0.8959183155825623}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.47155203336 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52873316208 :\n",
      "{'alpha': 0.29958781164377546}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.44314609534 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.5049932207 :\n",
      "{'alpha': 0.0009034420567735069}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50324144241 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55498208777 :\n",
      "{'alpha': 0.7915245151255477}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50109975649 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55321120503 :\n",
      "{'alpha': 0.7522733089438493}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53877147238 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58427618033 :\n",
      "{'alpha': 1.6027976174519671}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51972484354 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56859420158 :\n",
      "{'alpha': 1.12767578534888}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49186015828 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54556612955 :\n",
      "{'alpha': 0.5935283131694508}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.5337535889 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58015032012 :\n",
      "{'alpha': 1.467474706180756}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46735972619 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52525165512 :\n",
      "{'alpha': 0.2475200669556511}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.5530815037 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.596017637 :\n",
      "{'alpha': 2.0346677872566445}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53202115204 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57872488058 :\n",
      "{'alpha': 1.4225262793688342}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47546867084 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53198321544 :\n",
      "{'alpha': 0.3507967233508851}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46686878915 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52484373857 :\n",
      "{'alpha': 0.24160558503877283}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  90%|█████████ | 904/1000 [00:09<00:01, 74.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.369894982497 and loss 2.54938924348 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59299177169 :\n",
      "{'alpha': 1.9162627996136425}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.56066692945 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60222566185 :\n",
      "{'alpha': 2.294733246932714}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51333416833 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56332064367 :\n",
      "{'alpha': 0.9898746410694313}\n",
      "Parameters with this training accuracy 0.362893815636 and loss 2.55669496635 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59897636698 :\n",
      "{'alpha': 2.1556372197698392}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48369290525 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53880164948 :\n",
      "{'alpha': 0.46667416211321044}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48655856925 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54117583412 :\n",
      "{'alpha': 0.5098065376660246}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47533163716 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53186953934 :\n",
      "{'alpha': 0.3489625621124868}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52486813952 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57283439571 :\n",
      "{'alpha': 1.2460320888695087}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52553335171 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57338252558 :\n",
      "{'alpha': 1.2618486142593783}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53788882955 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.5835507549 :\n",
      "{'alpha': 1.5784274484983802}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54263556304 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58745038511 :\n",
      "{'alpha': 1.7124464529430188}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52231338323 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57072869443 :\n",
      "{'alpha': 1.186382803668422}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51459852596 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56436440361 :\n",
      "{'alpha': 1.016355086266811}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53001886125 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57707680293 :\n",
      "{'alpha': 1.371668783536382}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54556327337 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58985360323 :\n",
      "{'alpha': 1.7988418834949105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  91%|█████████ | 912/1000 [00:10<00:01, 69.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.372228704784 and loss 2.53491943357 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58110929268 :\n",
      "{'alpha': 1.4982265154972212}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51969030751 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56856571712 :\n",
      "{'alpha': 1.126904064632449}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54200170295 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58692987491 :\n",
      "{'alpha': 1.6941235045699803}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49930236841 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55172464991 :\n",
      "{'alpha': 0.720062691877335}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49782054716 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55049884786 :\n",
      "{'alpha': 0.6939996931002954}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50835812714 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55921091317 :\n",
      "{'alpha': 0.8892521757912784}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46130636281 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52021789106 :\n",
      "{'alpha': 0.1772333552247919}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50781145766 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55875924086 :\n",
      "{'alpha': 0.8785387236340679}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49112526609 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54495771432 :\n",
      "{'alpha': 0.5816121895995652}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52723089658 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57478098998 :\n",
      "{'alpha': 1.3027546560019154}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52032187959 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56908659623 :\n",
      "{'alpha': 1.1410644538822075}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50390537612 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55553097375 :\n",
      "{'alpha': 0.8038878129449074}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49185081888 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5455583978 :\n",
      "{'alpha': 0.5933762391381663}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54749984166 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59144237345 :\n",
      "{'alpha': 1.8576223469329163}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.47953223771 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53535310847 :\n",
      "{'alpha': 0.4066114374807525}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  93%|█████████▎| 929/1000 [00:10<00:01, 70.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.392065344224 and loss 2.4555481319 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51541827703 :\n",
      "{'alpha': 0.1156569994366442}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.4856017992 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5403832437 :\n",
      "{'alpha': 0.4952431290374878}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53584952505 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58187418233 :\n",
      "{'alpha': 1.5230551127387213}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51040828761 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56090450291 :\n",
      "{'alpha': 0.9300254559220191}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47659977335 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5329214296 :\n",
      "{'alpha': 0.3660551822974383}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51425165743 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56407807456 :\n",
      "{'alpha': 1.0090526978959249}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.55459629901 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59725827381 :\n",
      "{'alpha': 2.0847512539672852}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49421970385 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54751925097 :\n",
      "{'alpha': 0.6324798255283844}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49973584233 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55208319017 :\n",
      "{'alpha': 0.727770595971861}\n",
      "Parameters with this training accuracy 0.390898483081 and loss 2.44799302686 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50909011598 :\n",
      "{'alpha': 0.04272096963035654}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46390457871 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5223796415 :\n",
      "{'alpha': 0.2067002279920393}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51635424852 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56581346269 :\n",
      "{'alpha': 1.0537587539644684}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46832821197 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52605622087 :\n",
      "{'alpha': 0.25929958055448976}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48696205904 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54151005998 :\n",
      "{'alpha': 0.5159975506276961}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.51580896704 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56536346516 :\n",
      "{'alpha': 1.042062730803106}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  95%|█████████▍| 946/1000 [00:10<00:00, 72.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.376896149358 and loss 2.50557004879 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55690698251 :\n",
      "{'alpha': 0.835298682567212}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52556495593 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57340856558 :\n",
      "{'alpha': 1.2626030246324107}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.5759885925 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.61472968853 :\n",
      "{'alpha': 2.8985215618106195}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.50856144611 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55937889186 :\n",
      "{'alpha': 0.8932536818526521}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49921870673 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55165544849 :\n",
      "{'alpha': 0.718579429322969}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.50198915417 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55394667319 :\n",
      "{'alpha': 0.7684575516364812}\n",
      "Parameters with this training accuracy 0.358226371062 and loss 2.56372013134 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60472120552 :\n",
      "{'alpha': 2.4062411291820514}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53861978585 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58415152199 :\n",
      "{'alpha': 1.5985919017479966}\n",
      "Parameters with this training accuracy 0.341890315053 and loss 2.61346295853 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.6451140168 :\n",
      "{'alpha': 4.989863828785378}\n",
      "Parameters with this training accuracy 0.355892648775 and loss 2.59391262749 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.62929655623 :\n",
      "{'alpha': 3.7692612179840053}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53147805457 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57827792261 :\n",
      "{'alpha': 1.4086171180264682}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51179051486 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56204605043 :\n",
      "{'alpha': 0.9580527741097971}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51821373263 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56734772339 :\n",
      "{'alpha': 1.0941892593779439}\n",
      "Parameters with this training accuracy 0.373395565928 and loss 2.53449728678 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58076207937 :\n",
      "{'alpha': 1.4870441423037397}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54526141343 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.58960589326 :\n",
      "{'alpha': 1.7897980736337944}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48295356801 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53818898369 :\n",
      "{'alpha': 0.4557817094017742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  96%|█████████▋| 963/1000 [00:10<00:00, 76.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.376896149358 and loss 2.50679510198 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55791941247 :\n",
      "{'alpha': 0.8587957458900908}\n",
      "Parameters with this training accuracy 0.383897316219 and loss 2.47614830293 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53254696811 :\n",
      "{'alpha': 0.35993940346594616}\n",
      "Parameters with this training accuracy 0.380396732789 and loss 2.48796525894 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.54234098216 :\n",
      "{'alpha': 0.5315179798314167}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49941147441 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.55181489675 :\n",
      "{'alpha': 0.7219991932910164}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.49572522185 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54876517528 :\n",
      "{'alpha': 0.657892376163104}\n",
      "Parameters with this training accuracy 0.386231038506 and loss 2.46936808078 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5269198879 :\n",
      "{'alpha': 0.27211320504948155}\n",
      "Parameters with this training accuracy 0.394399066511 and loss 2.45384365593 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51399445295 :\n",
      "{'alpha': 0.09841565994591872}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49335515117 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54680367506 :\n",
      "{'alpha': 0.6180844077173528}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51103717091 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56142391037 :\n",
      "{'alpha': 0.9427230494130512}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51787281288 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56706646463 :\n",
      "{'alpha': 1.0867130395143136}\n",
      "Parameters with this training accuracy 0.378063010502 and loss 2.49196736975 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.54565488544 :\n",
      "{'alpha': 0.5952752222417509}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44521201624 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50674487831 :\n",
      "{'alpha': 0.018216103693001973}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52588117845 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57366910602 :\n",
      "{'alpha': 1.27016631393204}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54055545312 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58574198157 :\n",
      "{'alpha': 1.6528148121250603}\n",
      "Parameters with this training accuracy 0.368728121354 and loss 2.55075228909 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59410911329 :\n",
      "{'alpha': 1.959377865437865}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.50594272769 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55721499575 :\n",
      "{'alpha': 0.8424123596051947}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt:  98%|█████████▊| 980/1000 [00:10<00:00, 78.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.375729288215 and loss 2.53133735771 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57816212427 :\n",
      "{'alpha': 1.4050277558605022}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54027097652 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58550827989 :\n",
      "{'alpha': 1.6447700731080825}\n",
      "Parameters with this training accuracy 0.369894982497 and loss 2.54798943233 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59184392529 :\n",
      "{'alpha': 1.8726937438026798}\n",
      "Parameters with this training accuracy 0.366394399067 and loss 2.55192487395 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59507004249 :\n",
      "{'alpha': 1.9970232681586872}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52254219915 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57091732923 :\n",
      "{'alpha': 1.191655308638472}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54290015729 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58766764197 :\n",
      "{'alpha': 1.7201348135791155}\n",
      "Parameters with this training accuracy 0.361726954492 and loss 2.55791269337 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59997287184 :\n",
      "{'alpha': 2.1975839571947064}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53577663257 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58181424219 :\n",
      "{'alpha': 1.5210997168888647}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.54729990697 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.59127837837 :\n",
      "{'alpha': 1.8514922919262948}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5288227606 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57609199437 :\n",
      "{'alpha': 1.3418358046525662}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52713834154 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.5747047529 :\n",
      "{'alpha': 1.3005040053013346}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.53147880959 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.57827854401 :\n",
      "{'alpha': 1.4086363952268712}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52021454381 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56899807661 :\n",
      "{'alpha': 1.138650765819821}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5130340328 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56307284486 :\n",
      "{'alpha': 0.983643958189984}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.56254843977 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.60376374258 :\n",
      "{'alpha': 2.3629642928793695}\n",
      "Parameters with this training accuracy 0.381563593932 and loss 2.48044250882 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53610773441 :\n",
      "{'alpha': 0.419496873998603}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.44398544108 :\n",
      "Parameters with this testing accuracy 0.294736842105 and loss 2.50570608127 :\n",
      "{'alpha': 0.007840809215516775}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt: 100%|█████████▉| 997/1000 [00:11<00:00, 79.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.374562427071 and loss 2.52227594102 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57069782653 :\n",
      "{'alpha': 1.1855213365188464}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52200739934 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57047643107 :\n",
      "{'alpha': 1.1793534215555672}\n",
      "Parameters with this training accuracy 0.38739789965 and loss 2.47120475552 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.52844487966 :\n",
      "{'alpha': 0.2951677006969986}\n",
      "Parameters with this training accuracy 0.388564760793 and loss 2.46304478129 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5216644947 :\n",
      "{'alpha': 0.19683281770721917}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.51792363585 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.56710839457 :\n",
      "{'alpha': 1.0878257415149246}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.51209017559 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.5622935027 :\n",
      "{'alpha': 0.9641868806789127}\n",
      "Parameters with this training accuracy 0.359393232205 and loss 2.58380207757 :\n",
      "Parameters with this testing accuracy 0.273684210526 and loss 2.6210877261 :\n",
      "{'alpha': 3.2535731863300805}\n",
      "Parameters with this training accuracy 0.371061843641 and loss 2.53777732353 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58345910089 :\n",
      "{'alpha': 1.5753662316890487}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52293818511 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.57124376059 :\n",
      "{'alpha': 1.2008121173071848}\n",
      "Parameters with this training accuracy 0.376896149358 and loss 2.5038467822 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55548253496 :\n",
      "{'alpha': 0.8027929666674536}\n",
      "Parameters with this training accuracy 0.381563593932 and loss 2.48390676464 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53897885806 :\n",
      "{'alpha': 0.4698427867809346}\n",
      "Parameters with this training accuracy 0.385064177363 and loss 2.47725274025 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.53346297385 :\n",
      "{'alpha': 0.3749606522140244}\n",
      "Parameters with this training accuracy 0.365227537923 and loss 2.5550925226 :\n",
      "Parameters with this testing accuracy 0.284210526316 and loss 2.59766458989 :\n",
      "{'alpha': 2.1013534765268824}\n",
      "Parameters with this training accuracy 0.375729288215 and loss 2.5025085551 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.55437614301 :\n",
      "{'alpha': 0.7779850150485925}\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.53405671367 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.58039967891 :\n",
      "{'alpha': 1.475430994117608}\n",
      "Parameters with this training accuracy 0.372228704784 and loss 2.54257131092 :\n",
      "Parameters with this testing accuracy 0.305263157895 and loss 2.58739762616 :\n",
      "{'alpha': 1.7105830102470527}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt: 100%|██████████| 1000/1000 [00:11<00:00, 89.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters with this training accuracy 0.38739789965 and loss 2.45803271591 :\n",
      "Parameters with this testing accuracy 0.315789473684 and loss 2.51749096576 :\n",
      "{'alpha': 0.14159687920802722}\n",
      "------------------------------------\n",
      "('The best hyperparameters are: ', '\\n')\n",
      "{'alpha': 1.1617986567613996}\n",
      "Time elapsed to optimize 1000 executions: 11.2216258049\n",
      "\n",
      " Best score:\n",
      "Parameters with this training accuracy 0.374562427071 and loss 2.52123860174 :\n",
      "Parameters with this testing accuracy 0.326315789474 and loss 2.56984255026 :\n",
      "{'alpha': 1.1617986567613996}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': -0.3263157894736842, 'status': 'ok'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "trials = Trials()\n",
    "cores = 48\n",
    "start = time.time()\n",
    "evaluations = 1000\n",
    "pbar = tqdm(total=evaluations, desc=\"Hyperopt\")\n",
    "best_param = optimize(evals=evaluations,\n",
    "                      optimizer=tpe.suggest,\n",
    "                      trials=trials)\n",
    "print(\"------------------------------------\")\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_param)\n",
    "end = time.time()\n",
    "print('Time elapsed to optimize {0} executions: {1}'.format(evaluations, end - start))\n",
    "print('\\n Best score:')\n",
    "score(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best params and train the model\n",
    "nb_opt = MultinomialNB(alpha=best_param['alpha'])\n",
    "\n",
    "fitted_model = nb_opt.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06899012, 0.07541887, 0.06950849, ..., 0.06940148, 0.05099859,\n",
       "        0.06085017],\n",
       "       [0.06563856, 0.06004452, 0.06901421, ..., 0.05840706, 0.05427233,\n",
       "        0.06481683],\n",
       "       [0.07129024, 0.06214119, 0.06941476, ..., 0.05795263, 0.04466088,\n",
       "        0.06822891],\n",
       "       ...,\n",
       "       [0.07491715, 0.04976768, 0.06036857, ..., 0.04997647, 0.06596886,\n",
       "        0.0588598 ],\n",
       "       [0.07305712, 0.04796289, 0.05981537, ..., 0.04723125, 0.06740287,\n",
       "        0.06001657],\n",
       "       [0.052176  , 0.08563592, 0.07124004, ..., 0.07369115, 0.03873482,\n",
       "        0.06897876]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = fitted_model.predict_proba(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3263157894736842"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = accuracy_score(y_test, fitted_model.predict(X_test))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline \n",
    "x_list =range(len(train_acc_list))\n",
    "\n",
    "plt.plot(x_list, train_acc_list, label='Training accuracy')\n",
    "plt.plot(x_list, test_acc_list, label='Testing accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_list, train_loss_list, label='Training loss')\n",
    "plt.plot(x_list, test_loss_list, label='Testing loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
