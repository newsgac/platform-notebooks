{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsgac import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsgac.data_sources.models import DataSource\n",
    "from newsgac.pipelines import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline.objects.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline.objects.all()[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_results(pipeline_id):\n",
    "    # TODO: refactor\n",
    "    pipeline = Pipeline.objects.get({'_id': ObjectId(pipeline_id)})\n",
    "    sk_pipeline = pipeline.sk_pipeline.get()\n",
    "    classifier = sk_pipeline.named_steps['Classifier']\n",
    "    results_eval = pipeline.result\n",
    "    results_model = pipeline.result\n",
    "    p, script, div = ResultVisualiser.retrieveHeatMapfromResult(normalisation_flag=True, result=results_eval, title=\"Evaluation\", ds_param=0.7)\n",
    "    # p_mod, script_mod, div_mod = ResultVisualiser.retrieveHeatMapfromResult(normalisation_flag=True, result=results_model, title=\"Model\", ds_param=0.7)\n",
    "    script_f = ''\n",
    "    div_f = ''\n",
    "    # TODO: check for nb\n",
    "    # TODO: _svc because it's crashing atm\n",
    "    if pipeline.learner._tag in ['_svc']:\n",
    "        if classifier.kernel == 'linear':\n",
    "            coefficients = classifier.coef_\n",
    "            vectorized_pipeline = sk_pipeline.named_steps['FeatureExtraction'].transformer_list[0][0] == 'TFIDF'\n",
    "            names = sk_pipeline.named_steps['FeatureExtraction'].get_feature_names()\n",
    "            # get vectorizer for bow\n",
    "            if isinstance(coefficients, csr_matrix):\n",
    "                coefficients = coefficients.toarray()\n",
    "            p_f, script_f, div_f = ResultVisualiser.retrievePlotForFeatureWeights(coefficients=coefficients, names=names, vectorized_pipeline=vectorized_pipeline )\n",
    "    elif pipeline.learner.tag in ['xgb']:\n",
    "        from pandas import DataFrame\n",
    "        from collections import OrderedDict\n",
    "\n",
    "        feature_weights = classifier.get_booster().get_fscore()\n",
    "        sorted_fw = OrderedDict(sorted(feature_weights.items(), key=lambda t: t[0]))\n",
    "        sorted_keys = sorted(sk_pipeline.named_steps['FeatureExtraction'].get_feature_names())\n",
    "        print sorted_fw\n",
    "\n",
    "        feat_importances = []\n",
    "        for (ft, score) in sorted_fw.items():\n",
    "            index = int(ft.split(\"f\")[1])\n",
    "            feat_importances.append({'Feature': sorted_keys[index], 'Importance': score})\n",
    "        feat_importances = DataFrame(feat_importances)\n",
    "        feat_importances = feat_importances.sort_values(\n",
    "            by='Importance', ascending=True).reset_index(drop=True)\n",
    "        # Divide the importances by the sum of all importances\n",
    "        # to get relative importances. By using relative importances\n",
    "        # the sum of all importances will equal to 1, i.e.,\n",
    "        # np.sum(feat_importances['importance']) == 1\n",
    "        feat_importances['Importance'] /= feat_importances['Importance'].sum()\n",
    "        feat_importances = feat_importances.round(3)\n",
    "\n",
    "        p_f, script_f, div_f = ResultVisualiser.visualize_df_feature_importance(feat_importances, pipeline.display_title)\n",
    "    elif pipeline.learner.tag in ['rf']:\n",
    "        from pandas import DataFrame\n",
    "        feature_weights = classifier.feature_importances_\n",
    "        sorted_keys = sorted(sk_pipeline.named_steps['FeatureExtraction'].get_feature_names())\n",
    "\n",
    "        feat_importances = []\n",
    "        for (ft, key) in zip(feature_weights, sorted_keys):\n",
    "            feat_importances.append({'Feature': key, 'Importance': ft})\n",
    "        feat_importances = DataFrame(feat_importances)\n",
    "        feat_importances = feat_importances.sort_values(\n",
    "            by='Importance', ascending=True).reset_index(drop=True)\n",
    "        # Divide the importances by the sum of all importances\n",
    "        # to get relative importances. By using relative importances\n",
    "        # the sum of all importances will equal to 1, i.e.,\n",
    "        # np.sum(feat_importances['importance']) == 1\n",
    "        feat_importances['Importance'] /= feat_importances['Importance'].sum()\n",
    "        feat_importances = feat_importances.round(3)\n",
    "\n",
    "        p_f, script_f, div_f = ResultVisualiser.visualize_df_feature_importance(feat_importances,\n",
    "                                                                                pipeline.display_title)\n",
    "\n",
    "    plots = []\n",
    "    plots.append(p)\n",
    "    overview_layout = gridplot(plots, ncols=2)\n",
    "    script, div = components(overview_layout)\n",
    "\n",
    "    return render_template('pipelines/results.html',\n",
    "                           pipeline=pipeline,\n",
    "                           results_eval=results_eval,\n",
    "                           results_model=results_model,\n",
    "                           plot_script=script,\n",
    "                           plot_div=div,\n",
    "                           plot_feature_script=script_f,\n",
    "                           plot_feature_div=div_f,\n",
    "                           mimetype='text/html',\n",
    "                           mermaid=get_mermaid(pipeline.get_sk_pipeline())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DataSource object>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
