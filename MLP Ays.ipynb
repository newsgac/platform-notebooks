{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install matplotlib --user\n",
    "# !{sys.executable} -m pip install hyperopt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from hyperopt import tpe, fmin, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Data science imports\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "# Visualisation imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File IO: Read the data file\n",
    "file = open('train_data.txt', mode = 'r')\n",
    "lines = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for completeness\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: Clean unwanted characters \n",
    "data = []\n",
    "i = 0\n",
    "while i < len(lines)-1:\n",
    "    row = {}\n",
    "    row['id'] = lines[i+1].split(\" \")[1].strip()\n",
    "    row['durationOfStay'] = lines[i+2].split(\" \")[1].strip()\n",
    "    row['gender'] = lines[i+3].split(\" \")[1].strip()\n",
    "    row['Age'] = lines[i+4].split(\" \")[1].strip()\n",
    "    row['kids'] = lines[i+5].split(\" \")[1].strip()\n",
    "    row['destinationCode'] = lines[i+6].split(\" \")[1].strip()\n",
    "    row['AcomType'] = lines[i+7].split(\" \")[1].strip()\n",
    "    data.append(row)\n",
    "    i = i + 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data\n",
    "def structure_data_to_df(data, test_data=False):\n",
    "    if test_data:\n",
    "        df = pd.DataFrame(data, columns=['id','durationOfStay','gender','Age','kids','destinationCode'])\n",
    "        df['id'] = df['id'].astype(str)\n",
    "    else:\n",
    "        df = pd.DataFrame(data, columns=['durationOfStay','gender','Age','kids','destinationCode','AcomType'])\n",
    "        df['AcomType'] = df['AcomType'].astype(str)\n",
    "        \n",
    "    df['gender'] = df['gender'].astype(str)\n",
    "    df['kids'] = df['kids'].astype(str)\n",
    "    df['destinationCode'] = df['destinationCode'].astype(str)\n",
    "    df = df.replace('<NA>', np.nan)\n",
    "    df = df.replace('NA', np.nan)\n",
    "    df = df.replace('nan', np.nan)\n",
    "    df[['durationOfStay', 'Age']] = df[['durationOfStay', 'Age']].apply(pd.to_numeric)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = structure_data_to_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility variables\n",
    "categorical_cols = ['gender']\n",
    "missing_categorical_cols = ['kids', 'destinationCode']\n",
    "numerical_cols = ['durationOfStay']\n",
    "missing_numerical_cols = ['Age']\n",
    "\n",
    "# transform utility function\n",
    "def build_imputer_and_transformer(missing_categorical_cols, categorical_cols, \n",
    "                                  missing_numerical_cols, numerical_cols, constant=True):\n",
    "    transformations = []\n",
    "    \n",
    "    for col in missing_categorical_cols:\n",
    "        if constant:\n",
    "            transformations.append(([col], [SimpleImputer(strategy='constant', fill_value='N/A'), LabelBinarizer()]))\n",
    "        else:\n",
    "            transformations.append(([col], [SimpleImputer(strategy='most_frequent'), LabelBinarizer()]))\n",
    "        \n",
    "    for col in categorical_cols:\n",
    "        transformations.append((col, LabelBinarizer()))\n",
    "        \n",
    "    transformations.append((missing_numerical_cols, [SimpleImputer(strategy='mean'), StandardScaler()]))\n",
    "    transformations.append((numerical_cols, StandardScaler()))\n",
    "   \n",
    "    transformer = DataFrameMapper(transformations)\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['AcomType'].copy()\n",
    "X = df.drop(['AcomType'], axis=1)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=0)\n",
    "    \n",
    "transformer = build_imputer_and_transformer(missing_categorical_cols, categorical_cols,\n",
    "                                             missing_numerical_cols, numerical_cols, constant=True)\n",
    "    \n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes_list =[(20, 30), (30, 10), (10, 20), (5,10)]\n",
    "# hidden_layer_sizes_list =[(200, 100), (100, 200), (150, 300), (300, 100), (100, 200, 100), (200,100,200)]\n",
    "activation_list = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solver_list = ['lbfgs','sgd', 'adam']\n",
    "learning_rate_list = ['constant','adaptive', 'invscaling']\n",
    "batch_size_list = np.arange(20, 200, dtype=int)\n",
    "max_iter_list = np.arange(20, 500, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(evals, trials, optimizer=tpe.suggest):\n",
    "    space = {\n",
    "        'hidden_layer_sizes': hp.choice('hidden_layer_sizes', hidden_layer_sizes_list),\n",
    "        'activation': hp.choice('activation', activation_list),\n",
    "        'solver': hp.choice('solver', solver_list),\n",
    "        'alpha': hp.lognormal('alpha', 0, 1), # [0.0001, 0.05],\n",
    "#         'alpha': hp.loguniform('alpha', np.log(0.1), np.log(10)),\n",
    "        'learning_rate': hp.choice('learning_rate', learning_rate_list),\n",
    "        'batch_size': hp.choice('batch_size', batch_size_list),\n",
    "        'max_iter': hp.choice('max_iter', max_iter_list),\n",
    "    }\n",
    "    best = fmin(score, space, algo=optimizer, max_evals=evals, trials=trials)\n",
    "    pbar.close()\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "     \n",
    "    model = MLPClassifier(\n",
    "            hidden_layer_sizes = params['hidden_layer_sizes'],\n",
    "            activation = params['activation'],\n",
    "            solver = params['solver'],\n",
    "            alpha = params['alpha'],\n",
    "            learning_rate = params['learning_rate'],\n",
    "            batch_size = params['batch_size'],\n",
    "            max_iter = params['max_iter'],\n",
    "            shuffle = True,\n",
    "            random_state = 42,\n",
    "            warm_start = False,\n",
    "            early_stopping = True,\n",
    "            validation_fraction = 0.1,\n",
    "    )\n",
    "\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='balanced_accuracy', n_jobs=40)  \n",
    "    \n",
    "    scores_mean = 1-scores.mean()\n",
    "\n",
    "    \n",
    "    print('Parameters with this training score {} :'.format(scores_mean))\n",
    "    print(params)\n",
    "    pbar.update()\n",
    "#     return {'loss': test_loss, 'status': STATUS_OK}\n",
    "    return {'loss': scores_mean, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "trials = Trials()\n",
    "cores = 48\n",
    "start = time.time()\n",
    "evaluations = 1000\n",
    "pbar = tqdm(total=evaluations, desc=\"Hyperopt\")\n",
    "best_param = optimize(evals=evaluations,\n",
    "                      optimizer=tpe.suggest,\n",
    "                      trials=trials)\n",
    "print(\"------------------------------------\")\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_param)\n",
    "end = time.time()\n",
    "print('Time elapsed to optimize {0} executions: {1}'.format(evaluations, end - start))\n",
    "best_param['hidden_layer_sizes'] = hidden_layer_sizes_list[best_param['hidden_layer_sizes']]\n",
    "best_param['activation'] = activation_list[best_param['activation']]\n",
    "best_param['solver'] = solver_list[best_param['solver']]\n",
    "best_param['learning_rate'] = learning_rate_list[best_param['learning_rate']]\n",
    "best_param['batch_size'] = batch_size_list[best_param['batch_size']]\n",
    "best_param['max_iter'] = max_iter_list[best_param['max_iter']]\n",
    "print('\\n Best score:')\n",
    "score(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best params and train the model\n",
    "mlp_opt = MLPClassifier(\n",
    "            hidden_layer_sizes = best_param['hidden_layer_sizes'],\n",
    "            activation = best_param['activation'],\n",
    "            solver = best_param['solver'],\n",
    "            alpha = best_param['alpha'],\n",
    "            learning_rate = best_param['learning_rate'],\n",
    "            batch_size = best_param['batch_size'],\n",
    "            max_iter = best_param['max_iter'],\n",
    "            shuffle = True,\n",
    "            random_state = 42,\n",
    "            warm_start = False,\n",
    "            early_stopping = True,\n",
    "            validation_fraction = 0.1,\n",
    "    )\n",
    "\n",
    "fitted_model = mlp_opt.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = fitted_model.predict_proba(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = accuracy_score(y_test, fitted_model.predict(X_test))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
