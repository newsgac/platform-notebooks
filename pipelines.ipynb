{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "Pipelines are pipelines created from the UI. They can be converted to a [scikit-learn pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). They represent a combination of data source, pre-processing steps, feature extraction and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsgac import database\n",
    "from newsgac.pipelines.models import Pipeline\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': <pymodm.fields.ObjectIdField at 0x7f5a3d6e6ad0>,\n",
       " 'created': <pymodm.fields.DateTimeField at 0x7f5a3d6e6450>,\n",
       " 'data_source': <pymodm.fields.ReferenceField at 0x7f5a3d6e64d0>,\n",
       " 'display_title': <pymodm.fields.CharField at 0x7f5a3d6e6410>,\n",
       " 'grid_search_result': <newsgac.common.fields.ObjectField at 0x7f5a3d6e6890>,\n",
       " 'learner': <pymodm.fields.EmbeddedDocumentField at 0x7f5a3d6e6710>,\n",
       " 'lemmatization': <pymodm.fields.BooleanField at 0x7f5a3d6e6590>,\n",
       " 'nlp_tool': <pymodm.fields.EmbeddedDocumentField at 0x7f5a3d6e6690>,\n",
       " 'quote_removal': <pymodm.fields.BooleanField at 0x7f5a3d6e65d0>,\n",
       " 'result': <pymodm.fields.EmbeddedDocumentField at 0x7f5a3d6e67d0>,\n",
       " 'sk_pipeline': <newsgac.common.fields.ObjectField at 0x7f5a3d6e6790>,\n",
       " 'sw_removal': <pymodm.fields.BooleanField at 0x7f5a3d6e6550>,\n",
       " 'task': <pymodm.fields.EmbeddedDocumentField at 0x7f5a3d6e6950>,\n",
       " 'task_id': <pymodm.fields.CharField at 0x7f5a3d6e6850>,\n",
       " 'updated': <pymodm.fields.DateTimeField at 0x7f5a3d6e6490>,\n",
       " 'user': <pymodm.fields.ReferenceField at 0x7f5a3d6e63d0>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline._mongometa.fields_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSource: NGBS Training\n",
      "NLP Tool: Frog\n",
      "Classifier: Random Forest\n",
      "Task status: Status.SUCCESS\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline.objects.first()\n",
    "print 'DataSource: ' + p.data_source.display_title\n",
    "print 'NLP Tool: ' + p.nlp_tool.name\n",
    "print 'Classifier: ' + p.learner.name\n",
    "print 'Task status: ' + str(p.task.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a scikit-learn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('CleanOCR', <newsgac.nlp_tools.transformers.CleanOCR object at 0x7f5a3d6f7850>), ('FeatureExtraction', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('Basic', <newsgac.nlp_tools.transformers.ExtractBasicFeatures object at 0x7f5a3d6f7890>), ('Quote', <newsgac.nlp_tools.transformers.Extra...stimators=50, n_jobs=8,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skp = p.get_sk_pipeline()\n",
    "skp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CleanOCR', 'FeatureExtraction', 'Classifier', 'RobustScaler']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skp.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = skp.named_steps['FeatureExtraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Basic',\n",
       "  <newsgac.nlp_tools.transformers.ExtractBasicFeatures at 0x7f1b9e04e8d0>),\n",
       " ('Quote', <newsgac.nlp_tools.transformers.ExtractQuotes at 0x7f1b474a4b10>),\n",
       " ('Sentiment',\n",
       "  NoneStepsPipeline(feature_names_from='SentimentFeatures', memory=None,\n",
       "           steps=[('RemoveQuotes', <newsgac.nlp_tools.transformers.RemoveQuotes object at 0x7f1b474a4950>), ('SentimentFeatures', <newsgac.nlp_tools.transformers.ExtractSentimentFeatures object at 0x7f1b474a4ed0>)])),\n",
       " ('Frog', NoneStepsPipeline(feature_names_from='Frog', memory=None,\n",
       "           steps=[('RemoveQuotes', <newsgac.nlp_tools.transformers.RemoveQuotes object at 0x7f1b474a4a10>), ('Frog', <newsgac.nlp_tools.models.frog.FrogFeatureExtractor object at 0x7f1b474a40d0>)]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.transformer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Basic',\n",
       " <newsgac.nlp_tools.transformers.ExtractBasicFeatures at 0x7f1b9e04e8d0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.transformer_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/newsgac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# todo: Remove above, has been moved to the Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('question_marks_perc', 0.0),\n",
       " ('exclamation_marks_perc', 0.16666666666666666),\n",
       " ('currency_symbols_perc', 0.0),\n",
       " ('digits_perc', 0.0),\n",
       " ('sentences', 1.0),\n",
       " ('avg_sentence_length', 6.0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_feature_extractor = fe.transformer_list[0][1]\n",
    "features = basic_feature_extractor.transform(['Dit is een test tekst!'])[0]\n",
    "feature_names = basic_feature_extractor.get_feature_names()\n",
    "zip(feature_names, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
